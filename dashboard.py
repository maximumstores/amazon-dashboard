import streamlit as st
import pandas as pd
import os
import re
import psycopg2
import requests
import threading
import queue
import time
import plotly.express as px
import plotly.graph_objects as go
from sklearn.linear_model import LinearRegression
import numpy as np
import datetime as dt
from dotenv import load_dotenv
from sqlalchemy import create_engine, text

load_dotenv()

st.set_page_config(page_title="Amazon FBA Ultimate BI", layout="wide", page_icon="ğŸ“¦")

translations = {
    "UA": {
        "title": "ğŸ“¦ Amazon FBA: Business Intelligence Hub",
        "update_btn": "ğŸ”„ ĞĞ½Ğ¾Ğ²Ğ¸Ñ‚Ğ¸ Ğ´Ğ°Ğ½Ñ–",
        "sidebar_title": "ğŸ” Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸",
        "date_label": "ğŸ“… Ğ”Ğ°Ñ‚Ğ°:",
        "store_label": "ğŸª ĞœĞ°Ğ³Ğ°Ğ·Ğ¸Ğ½:",
        "all_stores": "Ğ’ÑÑ–",
        "total_sku": "Ğ’ÑÑŒĞ¾Ğ³Ğ¾ SKU",
        "total_avail": "Ğ¨Ñ‚ÑƒĞº Ğ½Ğ° ÑĞºĞ»Ğ°Ğ´Ñ–",
        "total_value": "ğŸ’° Ğ’Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ ÑĞºĞ»Ğ°Ğ´Ñƒ",
        "velocity_30": "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ñ– (30 Ğ´Ğ½Ñ–Ğ²)",
        "chart_value_treemap": "ğŸ’° Ğ”Ğµ Ğ·Ğ°Ğ¼Ğ¾Ñ€Ğ¾Ğ¶ĞµĞ½Ñ– Ğ³Ñ€Ğ¾ÑˆÑ–?",
        "chart_velocity": "ğŸš€ Ğ¨Ğ²Ğ¸Ğ´ĞºÑ–ÑÑ‚ÑŒ vs Ğ—Ğ°Ğ»Ğ¸ÑˆĞºĞ¸",
        "chart_age": "â³ Ğ’Ñ–Ğº Ñ–Ğ½Ğ²ĞµĞ½Ñ‚Ğ°Ñ€Ñ",
        "top_money_sku": "ğŸ† Ğ¢Ğ¾Ğ¿ SKU Ğ·Ğ° Ğ²Ğ°Ñ€Ñ‚Ñ–ÑÑ‚Ñ",
        "top_qty_sku": "ğŸ† Ğ¢Ğ¾Ğ¿ SKU Ğ·Ğ° ĞºÑ–Ğ»ÑŒĞºÑ–ÑÑ‚Ñ",
        "avg_price": "Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ Ñ†Ñ–Ğ½Ğ°",
        "ai_header": "ğŸ§  AI ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ·Ğ°Ğ»Ğ¸ÑˆĞºÑ–Ğ²",
        "ai_select": "ĞĞ±ĞµÑ€Ñ–Ñ‚ÑŒ SKU:",
        "ai_days": "Ğ“Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ñƒ:",
        "ai_result_date": "ğŸ“… Ğ”Ğ°Ñ‚Ğ° Sold-out:",
        "ai_result_days": "Ğ”Ğ½Ñ–Ğ² Ğ·Ğ°Ğ»Ğ¸ÑˆĞ¸Ğ»Ğ¾ÑÑŒ:",
        "ai_ok": "âœ… Ğ—Ğ°Ğ¿Ğ°ÑÑ–Ğ² Ğ²Ğ¸ÑÑ‚Ğ°Ñ‡Ğ¸Ñ‚ÑŒ",
        "ai_error": "ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ½ÑŒĞ¾ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ñƒ",
        "footer_date": "ğŸ“… Ğ”Ğ°Ğ½Ñ– Ğ¾Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾:",
        "download_excel": "ğŸ“¥ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ Excel",
        "settlements_title": "ğŸ¦ Ğ¤Ñ–Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ– Ğ²Ğ¸Ğ¿Ğ»Ğ°Ñ‚Ğ¸ (Settlements)",
        "net_payout": "Ğ§Ğ¸ÑÑ‚Ğ° Ğ²Ğ¸Ğ¿Ğ»Ğ°Ñ‚Ğ°",
        "gross_sales": "Ğ’Ğ°Ğ»Ğ¾Ğ²Ñ– Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ñ–",
        "total_fees": "Ğ’ÑÑŒĞ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ñ–ÑÑ–Ğ¹",
        "total_refunds": "ĞŸĞ¾Ğ²ĞµÑ€Ğ½ĞµĞ½Ğ½Ñ ĞºĞ¾ÑˆÑ‚Ñ–Ğ²",
        "chart_payout_trend": "ğŸ“‰ Ğ”Ğ¸Ğ½Ğ°Ğ¼Ñ–ĞºĞ° Ğ²Ğ¸Ğ¿Ğ»Ğ°Ñ‚",
        "chart_fee_breakdown": "ğŸ’¸ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ²Ğ¸Ñ‚Ñ€Ğ°Ñ‚",
        "currency_select": "ğŸ’± Ğ’Ğ°Ğ»ÑÑ‚Ğ°:",
        "sales_traffic_title": "ğŸ“ˆ Sales & Traffic",
        "st_sessions": "Ğ¡ĞµÑÑ–Ñ—",
        "st_page_views": "ĞŸĞµÑ€ĞµĞ³Ğ»ÑĞ´Ğ¸",
        "st_units": "Ğ—Ğ°Ğ¼Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾ ÑˆÑ‚ÑƒĞº",
        "st_conversion": "ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑÑ–Ñ",
        "st_revenue": "Ğ”Ğ¾Ñ…Ñ–Ğ´",
        "st_buy_box": "Buy Box %",
        "reviews_title": "â­ Ğ’Ñ–Ğ´Ğ³ÑƒĞºĞ¸ Ğ¿Ğ¾ĞºÑƒĞ¿Ñ†Ñ–Ğ²",
        "total_reviews": "Ğ’ÑÑŒĞ¾Ğ³Ğ¾ Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²",
        "avg_review_rating": "Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³",
        "verified_pct": "Ğ’ĞµÑ€Ğ¸Ñ„Ñ–ĞºĞ¾Ğ²Ğ°Ğ½Ñ– (%)",
        "star_dist": "Ğ Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ¿Ğ¾ Ğ·Ñ–Ñ€ĞºĞ°Ñ…",
        "worst_asin": "ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ– ASIN (1-2â˜…)",
        "ov_title": "ğŸ“Š ĞĞ³Ğ»ÑĞ´ Ğ±Ñ–Ğ·Ğ½ĞµÑÑƒ",
        "ov_top_sku": "### ğŸ“Š Ğ¢Ğ¾Ğ¿ 15 SKU Ğ·Ğ° Ğ·Ğ°Ğ»Ğ¸ÑˆĞºĞ°Ğ¼Ğ¸",
        "st_daily_trends": "### ğŸ“ˆ Ğ©Ğ¾Ğ´ĞµĞ½Ğ½Ğ° Ğ´Ğ¸Ğ½Ğ°Ğ¼Ñ–ĞºĞ°",
        "st_sessions_views": "#### ğŸ‘ Ğ¡ĞµÑÑ–Ñ— Ñ‚Ğ° Ğ¿ĞµÑ€ĞµĞ³Ğ»ÑĞ´Ğ¸",
        "st_revenue_units": "#### ğŸ’° Ğ”Ğ¾Ñ…Ñ–Ğ´ Ñ‚Ğ° Ğ·Ğ°Ğ¼Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ",
        "st_top_asins": "### ğŸ† Ğ¢Ğ¾Ğ¿ ASINĞ¸",
        "st_top_revenue": "#### ğŸ’° Ğ¢Ğ¾Ğ¿ 15 Ğ·Ğ° Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ¼",
        "st_top_sessions": "#### ğŸ‘ Ğ¢Ğ¾Ğ¿ 15 Ğ·Ğ° ÑĞµÑÑ–ÑĞ¼Ğ¸",
        "st_full_data": "### ğŸ“‹ Ğ’ÑÑ– Ğ´Ğ°Ğ½Ñ– Ğ¿Ğ¾ ASINĞ°Ñ…",
        "st_download": "ğŸ“¥ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ CSV",
        "st_filters": "ğŸ“ˆ Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ Sales & Traffic",
        "st_date_range": "ğŸ“… Ğ”Ñ–Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚:",
        "ret_title": "### ğŸ“¦ ĞĞ³Ğ»ÑĞ´ Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ",
        "ret_total": "ğŸ“¦ Ğ’ÑÑŒĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ",
        "ret_unique_sku": "ğŸ“¦ Ğ£Ğ½Ñ–ĞºĞ°Ğ»ÑŒĞ½Ğ¸Ñ… SKU",
        "ret_rate": "ğŸ“Š Ğ Ñ–Ğ²ĞµĞ½ÑŒ Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ",
        "ret_value": "ğŸ’° Ğ’Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ",
        "ret_avg": "ğŸ’µ Ğ¡ĞµÑ€. Ğ²Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ",
        "ret_by_sku": "#### ğŸ’µ Ğ’Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ Ğ¿Ğ¾ SKU (Ğ¢Ğ¾Ğ¿ 10)",
        "ret_daily": "#### ğŸ“Š Ğ©Ğ¾Ğ´ĞµĞ½Ğ½Ğ° Ğ²Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ",
        "ret_by_reason": "#### ğŸ’¸ ĞŸĞ¾ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°Ñ…",
        "ret_top_sku": "#### ğŸ† Ğ¢Ğ¾Ğ¿ 15 SKU Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ",
        "ret_reasons": "#### ğŸ“Š ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ¸ Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ",
        "ret_filters": "ğŸ“¦ Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ",
        "ret_date": "ğŸ“… Ğ”Ğ°Ñ‚Ğ° Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½Ğ½Ñ:",
        "ret_download": "ğŸ“¥ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ CSV Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ",
        "ord_title": "### ğŸ›’ ĞĞ½Ğ°Ğ»Ñ–Ñ‚Ğ¸ĞºĞ° Ğ·Ğ°Ğ¼Ğ¾Ğ²Ğ»ĞµĞ½ÑŒ",
        "ins_neg_trend": "Ğ¢Ñ€ĞµĞ½Ğ´ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ñƒ",
        "ins_verified": "Ğ’ĞµÑ€Ğ¸Ñ„Ñ–ĞºĞ°Ñ†Ñ–Ñ",
        "ins_pos_rate": "Ğ Ñ–Ğ²ĞµĞ½ÑŒ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ñƒ",
        "rev_auto_insights": "ğŸ§  ĞĞ²Ñ‚Ğ¾Ñ–Ğ½ÑĞ°Ğ¹Ñ‚Ğ¸",
        "rev_worst_asin": "ğŸ”´ ĞĞĞ™Ğ“Ğ†Ğ Ğ¨Ğ˜Ğ™ ASIN",
        "rev_best_asin": "ğŸŸ¢ ĞĞĞ™ĞšĞ ĞĞ©Ğ˜Ğ™ ASIN",
        "rev_worst_country": "ğŸ”´ ĞĞĞ™Ğ“Ğ†Ğ Ğ¨Ğ ĞšĞ ĞĞ‡ĞĞ",
        "rev_best_country": "ğŸŸ¢ ĞĞĞ™ĞšĞ ĞĞ©Ğ ĞšĞ ĞĞ‡ĞĞ",
        "rev_reviews_count": "Ğ²Ñ–Ğ´Ğ³.",
        "rev_main_asin": "ğŸ“¦ Ğ“Ğ¾Ğ»Ğ¾Ğ²Ğ½Ğ¸Ğ¹:",
        "rev_heatmap": "### ğŸ”¥ Ğ¢ĞµĞ¿Ğ»Ğ¾Ğ²Ğ° ĞºĞ°Ñ€Ñ‚Ğ°: ASIN Ã— ĞšÑ€Ğ°Ñ—Ğ½Ğ°",
        "rev_heatmap_hint": "ĞšĞ»Ñ–ĞºĞ½Ğ¸ Ğ½Ğ° ASIN Ñƒ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– Ğ½Ğ¸Ğ¶Ñ‡Ğµ â€” Ğ²Ñ–Ğ´ĞºÑ€Ğ¸Ñ”Ñ‚ÑŒÑÑ Ğ¹Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºĞ° Ğ½Ğ° Amazon",
        "rev_asin_compare": "### ğŸ“Š ĞŸĞ¾Ñ€Ñ–Ğ²Ğ½ÑĞ½Ğ½Ñ ASINÑ–Ğ²",
        "rev_star_dist": "### ğŸ“Š Ğ—Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ñ€Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ·Ñ–Ñ€Ğ¾Ğº",
        "rev_texts": "### ğŸ“‹ Ğ¢ĞµĞºÑÑ‚Ğ¸ Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² (Ğ´Ğ¾ 100 Ğ½Ğ° ĞºĞ¾Ğ¶Ğ½Ñƒ Ğ·Ñ–Ñ€ĞºÑƒ, max 500)",
        "rev_sort_hint": "Ğ¡Ğ¾Ñ€Ñ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ: ÑĞ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºÑƒ 1â˜… â€” Ñ‰Ğ¾Ğ± Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸ Ğ±ÑƒĞ»Ğ¸ Ğ¿ĞµÑ€ÑˆĞ¸Ğ¼Ğ¸",
        "rev_click_hint": "ğŸ‘† ĞšĞ»Ñ–ĞºĞ½Ğ¸ Ğ½Ğ° Ñ€ÑĞ´Ğ¾Ğº â€” Ğ¿Ğ¾Ğ±Ğ°Ñ‡Ğ¸Ñˆ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ñ†ÑŒĞ¾Ğ³Ğ¾ ASIN Â· ĞŸĞ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ Ğ²Ñ–Ğ´ĞºÑ€Ğ¸ÑÑ‚ÑŒ Amazon Ñƒ Ğ½Ğ¾Ğ²Ñ–Ğ¹ Ğ²ĞºĞ»Ğ°Ğ´Ñ†Ñ–",
        "rev_select_hint": "ğŸ‘‡ Ğ’Ğ¸Ğ±ĞµÑ€Ğ¸ ASIN Ğ´Ğ»Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ:",
        "rev_goto_asin": "ğŸ“¦ ĞŸĞµÑ€ĞµĞ¹Ñ‚Ğ¸ Ğ´Ğ¾ ASIN:",
        "rev_not_selected": "â€” Ğ½Ğµ Ğ²Ğ¸Ğ±Ñ€Ğ°Ğ½Ğ¾ â€”",
        "rev_back": "â† ĞĞ°Ğ·Ğ°Ğ´ Ğ´Ğ¾ Ğ²ÑÑ–Ñ… ASINÑ–Ğ²",
        "rev_asins_in_filter": "ğŸ“¦ ASINÑ–Ğ² Ñƒ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ñ–",
        "insights_title": "ğŸ§  Ğ†Ğ½ÑĞ°Ğ¹Ñ‚Ğ¸",
        "insight_rating_health": "Ğ—Ğ´Ğ¾Ñ€Ğ¾Ğ²'Ñ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ",
        "insight_loyalty": "Ğ›Ğ¾ÑĞ»ÑŒĞ½Ñ–ÑÑ‚ÑŒ",
        "insight_toxic": "Ğ¢Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ğ¸Ğ¹ ASIN",
        "insight_neg_level": "Ğ Ñ–Ğ²ĞµĞ½ÑŒ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ñƒ",
        "insight_verified": "Ğ’ĞµÑ€Ğ¸Ñ„Ñ–ĞºĞ°Ñ†Ñ–Ñ",
        "rev_table_by_country": "ğŸ“‹ Ğ—Ğ²ĞµĞ´ĞµĞ½Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ğ¿Ğ¾ ĞºÑ€Ğ°Ñ—Ğ½Ğ°Ñ…",
        "rev_count_by_country": "ğŸ“Š Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² Ğ¿Ğ¾ ĞºÑ€Ğ°Ñ—Ğ½Ğ°Ñ…",
        "rev_neg_by_country": "ğŸ”´ % ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ… Ğ¿Ğ¾ ĞºÑ€Ğ°Ñ—Ğ½Ğ°Ñ…",
        "rev_rating_by_country": "â­ Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ ĞºÑ€Ğ°Ñ—Ğ½Ğ°Ñ…",
        "rev_country_analysis": "ğŸŒ ĞĞ½Ğ°Ğ»Ñ–Ğ· Ğ¿Ğ¾ ĞºÑ€Ğ°Ñ—Ğ½Ğ°Ñ…",
        "rev_star_filter": "â­ Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³:",
        "rev_country_filter": "ğŸŒ ĞšÑ€Ğ°Ñ—Ğ½Ğ° (Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹Ñ):",
        "rev_filters": "â­ Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²",
        "all_countries": "Ğ’ÑÑ– ĞºÑ€Ğ°Ñ—Ğ½Ğ¸",
        "all_asins": "Ğ’ÑÑ– ASINĞ¸",
    },
    "EN": {
        "title": "ğŸ“¦ Amazon FBA: Business Intelligence Hub",
        "update_btn": "ğŸ”„ Refresh Data",
        "sidebar_title": "ğŸ” Filters",
        "date_label": "ğŸ“… Date:",
        "store_label": "ğŸª Store:",
        "all_stores": "All",
        "total_sku": "Total SKU",
        "total_avail": "Total Units",
        "total_value": "ğŸ’° Inventory Value",
        "velocity_30": "Sales (30 days)",
        "chart_value_treemap": "ğŸ’° Where is the money?",
        "chart_velocity": "ğŸš€ Velocity vs Stock",
        "chart_age": "â³ Inventory Age",
        "top_money_sku": "ğŸ† Top SKU by Value",
        "top_qty_sku": "ğŸ† Top SKU by Quantity",
        "avg_price": "Avg Price",
        "ai_header": "ğŸ§  AI Inventory Forecast",
        "ai_select": "Select SKU:",
        "ai_days": "Forecast Days:",
        "ai_result_date": "ğŸ“… Sold-out Date:",
        "ai_result_days": "Days left:",
        "ai_ok": "âœ… Stock sufficient",
        "ai_error": "Not enough data",
        "footer_date": "ğŸ“… Last update:",
        "download_excel": "ğŸ“¥ Download Excel",
        "settlements_title": "ğŸ¦ Financial Settlements (Payouts)",
        "net_payout": "Net Payout",
        "gross_sales": "Gross Sales",
        "total_fees": "Total Fees",
        "total_refunds": "Total Refunds",
        "chart_payout_trend": "ğŸ“‰ Payout Trend",
        "chart_fee_breakdown": "ğŸ’¸ Fee Breakdown",
        "currency_select": "ğŸ’± Currency:",
        "sales_traffic_title": "ğŸ“ˆ Sales & Traffic",
        "st_sessions": "Sessions",
        "st_page_views": "Page Views",
        "st_units": "Units Ordered",
        "st_conversion": "Conversion",
        "st_revenue": "Revenue",
        "st_buy_box": "Buy Box %",
        "reviews_title": "â­ Customer Reviews",
        "total_reviews": "Total Reviews",
        "avg_review_rating": "Average Rating",
        "verified_pct": "Verified (%)",
        "star_dist": "Star Distribution",
        "worst_asin": "Problematic ASINs (1-2â˜…)",
        "ov_title": "ğŸ“Š Business Overview",
        "ov_top_sku": "### ğŸ“Š Top 15 SKU by Stock",
        "st_daily_trends": "### ğŸ“ˆ Daily Trends",
        "st_sessions_views": "#### ğŸ‘ Sessions & Page Views",
        "st_revenue_units": "#### ğŸ’° Revenue & Units",
        "st_top_asins": "### ğŸ† Top ASINs Performance",
        "st_top_revenue": "#### ğŸ’° Top 15 by Revenue",
        "st_top_sessions": "#### ğŸ‘ Top 15 by Sessions",
        "st_full_data": "### ğŸ“‹ Full ASIN Data",
        "st_download": "ğŸ“¥ Download CSV",
        "st_filters": "ğŸ“ˆ Sales & Traffic Filters",
        "st_date_range": "ğŸ“… Date Range:",
        "ret_title": "### ğŸ“¦ Returns Overview",
        "ret_total": "ğŸ“¦ Total Returns",
        "ret_unique_sku": "ğŸ“¦ Unique SKUs",
        "ret_rate": "ğŸ“Š Return Rate",
        "ret_value": "ğŸ’° Return Value",
        "ret_avg": "ğŸ’µ Avg Return",
        "ret_by_sku": "#### ğŸ’µ Return Value by SKU (Top 10)",
        "ret_daily": "#### ğŸ“Š Daily Return Value",
        "ret_by_reason": "#### ğŸ’¸ Return Value by Reason",
        "ret_top_sku": "#### ğŸ† Top 15 Returned SKUs",
        "ret_reasons": "#### ğŸ“Š Return Reasons",
        "ret_filters": "ğŸ“¦ Returns Filters",
        "ret_date": "ğŸ“… Return Date:",
        "ret_download": "ğŸ“¥ Download Returns CSV",
        "ord_title": "### ğŸ›’ Orders Analytics",
        "insight_rating_health": "Rating Health",
        "insight_loyalty": "Loyalty",
        "insight_toxic": "Toxic ASIN",
        "insight_neg_level": "Negative Level",
        "insight_verified": "Verification",
        "rev_auto_insights": "ğŸ§  Auto Insights",
        "rev_worst_asin": "ğŸ”´ WORST ASIN",
        "rev_best_asin": "ğŸŸ¢ BEST ASIN",
        "rev_worst_country": "ğŸ”´ WORST COUNTRY",
        "rev_best_country": "ğŸŸ¢ BEST COUNTRY",
        "rev_reviews_count": "rev.",
        "rev_main_asin": "ğŸ“¦ Main:",
        "rev_heatmap": "### ğŸ”¥ Heatmap: ASIN Ã— Country",
        "rev_heatmap_hint": "Click ASIN in table below â€” opens Amazon page",
        "rev_asin_compare": "### ğŸ“Š ASIN Comparison",
        "rev_star_dist": "### ğŸ“Š Overall Star Distribution",
        "rev_texts": "### ğŸ“‹ Review Texts (up to 100 per star, max 500)",
        "rev_sort_hint": "Sorted: 1â˜… first â€” problems first",
        "rev_click_hint": "ğŸ‘† Click row to see detailed ASIN analysis Â· Links open Amazon in new tab",
        "rev_select_hint": "ğŸ‘‡ Select ASIN for detailed analysis:",
        "rev_goto_asin": "ğŸ“¦ Go to ASIN:",
        "rev_not_selected": "â€” not selected â€”",
        "rev_back": "â† Back to all ASINs",
        "rev_asins_in_filter": "ğŸ“¦ ASINs in filter",
        "insights_title": "ğŸ§  Insights",
        "insight_rating_health": "Rating Health",
        "insight_loyalty": "Loyalty",
        "insight_toxic": "Toxic ASIN",
        "insight_neg_level": "Negative Level",
        "insight_verified": "Verification",
        "rev_table_by_country": "ğŸ“‹ Summary Table by Country",
        "rev_count_by_country": "ğŸ“Š Reviews by Country",
        "rev_neg_by_country": "ğŸ”´ % Negative by Country",
        "rev_rating_by_country": "â­ Rating by Country",
        "rev_country_analysis": "ğŸŒ Country Analysis",
        "rev_star_filter": "â­ Rating:",
        "rev_country_filter": "ğŸŒ Country (marketplace):",
        "rev_filters": "â­ Review Filters",
        "all_countries": "All countries",
        "all_asins": "All ASINs",
    },
    "RU": {
        "title": "ğŸ“¦ Amazon FBA: Business Intelligence Hub",
        "update_btn": "ğŸ”„ ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ",
        "sidebar_title": "ğŸ” Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹",
        "date_label": "ğŸ“… Ğ”Ğ°Ñ‚Ğ°:",
        "store_label": "ğŸª ĞœĞ°Ğ³Ğ°Ğ·Ğ¸Ğ½:",
        "all_stores": "Ğ’ÑĞµ",
        "total_sku": "Ğ’ÑĞµĞ³Ğ¾ SKU",
        "total_avail": "Ğ¨Ñ‚ÑƒĞº Ğ½Ğ° ÑĞºĞ»Ğ°Ğ´Ğµ",
        "total_value": "ğŸ’° Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ ÑĞºĞ»Ğ°Ğ´Ğ°",
        "velocity_30": "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ (30 Ğ´Ğ½ĞµĞ¹)",
        "chart_value_treemap": "ğŸ’° Ğ“Ğ´Ğµ Ğ´ĞµĞ½ÑŒĞ³Ğ¸?",
        "chart_velocity": "ğŸš€ Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ vs ĞÑÑ‚Ğ°Ñ‚ĞºĞ¸",
        "chart_age": "â³ Ğ’Ğ¾Ğ·Ñ€Ğ°ÑÑ‚ Ğ¸Ğ½Ğ²ĞµĞ½Ñ‚Ğ°Ñ€Ñ",
        "top_money_sku": "ğŸ† Ğ¢Ğ¾Ğ¿ SKU Ğ¿Ğ¾ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸",
        "top_qty_sku": "ğŸ† Ğ¢Ğ¾Ğ¿ SKU Ğ¿Ğ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ñƒ",
        "avg_price": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ñ†ĞµĞ½Ğ°",
        "ai_header": "ğŸ§  AI ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ¾ÑÑ‚Ğ°Ñ‚ĞºĞ¾Ğ²",
        "ai_select": "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ SKU:",
        "ai_days": "Ğ“Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ°:",
        "ai_result_date": "ğŸ“… Ğ”Ğ°Ñ‚Ğ° Sold-out:",
        "ai_result_days": "Ğ”Ğ½ĞµĞ¹ Ğ¾ÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ:",
        "ai_ok": "âœ… Ğ—Ğ°Ğ¿Ğ°ÑĞ¾Ğ² Ñ…Ğ²Ğ°Ñ‚Ğ¸Ñ‚",
        "ai_error": "ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
        "footer_date": "ğŸ“… Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹:",
        "download_excel": "ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Excel",
        "settlements_title": "ğŸ¦ Ğ¤Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ğµ Ğ²Ñ‹Ğ¿Ğ»Ğ°Ñ‚Ñ‹ (Settlements)",
        "net_payout": "Ğ§Ğ¸ÑÑ‚Ğ°Ñ Ğ²Ñ‹Ğ¿Ğ»Ğ°Ñ‚Ğ°",
        "gross_sales": "Ğ’Ğ°Ğ»Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸",
        "total_fees": "Ğ’ÑĞµĞ³Ğ¾ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¹",
        "total_refunds": "Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹ ÑÑ€ĞµĞ´ÑÑ‚Ğ²",
        "chart_payout_trend": "ğŸ“‰ Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ²Ñ‹Ğ¿Ğ»Ğ°Ñ‚",
        "chart_fee_breakdown": "ğŸ’¸ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ğ¾Ğ²",
        "currency_select": "ğŸ’± Ğ’Ğ°Ğ»ÑÑ‚Ğ°:",
        "sales_traffic_title": "ğŸ“ˆ Sales & Traffic",
        "st_sessions": "Ğ¡ĞµÑÑĞ¸Ğ¸",
        "st_page_views": "ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ñ‹",
        "st_units": "Ğ—Ğ°ĞºĞ°Ğ·Ğ°Ğ½Ğ¾ ÑˆÑ‚ÑƒĞº",
        "st_conversion": "ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ",
        "st_revenue": "Ğ”Ğ¾Ñ…Ğ¾Ğ´",
        "st_buy_box": "Buy Box %",
        "reviews_title": "â­ ĞÑ‚Ğ·Ñ‹Ğ²Ñ‹ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ĞµĞ¹",
        "total_reviews": "Ğ’ÑĞµĞ³Ğ¾ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²",
        "avg_review_rating": "Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³",
        "verified_pct": "Ğ’ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ (%)",
        "star_dist": "Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ·Ğ²ĞµĞ·Ğ´Ğ°Ğ¼",
        "worst_asin": "ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğµ ASIN (1-2â˜…)",
        "ov_title": "ğŸ“Š ĞĞ±Ğ·Ğ¾Ñ€ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ°",
        "ov_top_sku": "### ğŸ“Š Ğ¢Ğ¾Ğ¿ 15 SKU Ğ¿Ğ¾ Ğ¾ÑÑ‚Ğ°Ñ‚ĞºĞ°Ğ¼",
        "st_daily_trends": "### ğŸ“ˆ Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ°Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ°",
        "st_sessions_views": "#### ğŸ‘ Ğ¡ĞµÑÑĞ¸Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ñ‹",
        "st_revenue_units": "#### ğŸ’° Ğ”Ğ¾Ñ…Ğ¾Ğ´ Ğ¸ Ğ·Ğ°ĞºĞ°Ğ·Ñ‹",
        "st_top_asins": "### ğŸ† Ğ¢Ğ¾Ğ¿ ASINÑ‹",
        "st_top_revenue": "#### ğŸ’° Ğ¢Ğ¾Ğ¿ 15 Ğ¿Ğ¾ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ñƒ",
        "st_top_sessions": "#### ğŸ‘ Ğ¢Ğ¾Ğ¿ 15 Ğ¿Ğ¾ ÑĞµÑÑĞ¸ÑĞ¼",
        "st_full_data": "### ğŸ“‹ Ğ’ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ ASINĞ°Ğ¼",
        "st_download": "ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ CSV",
        "st_filters": "ğŸ“ˆ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Sales & Traffic",
        "st_date_range": "ğŸ“… Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚:",
        "ret_title": "### ğŸ“¦ ĞĞ±Ğ·Ğ¾Ñ€ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²",
        "ret_total": "ğŸ“¦ Ğ’ÑĞµĞ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²",
        "ret_unique_sku": "ğŸ“¦ Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… SKU",
        "ret_rate": "ğŸ“Š Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²",
        "ret_value": "ğŸ’° Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²",
        "ret_avg": "ğŸ’µ Ğ¡Ñ€. ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ",
        "ret_by_sku": "#### ğŸ’µ Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ SKU (Ğ¢Ğ¾Ğ¿ 10)",
        "ret_daily": "#### ğŸ“Š Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ°Ñ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ",
        "ret_by_reason": "#### ğŸ’¸ ĞŸĞ¾ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°Ğ¼",
        "ret_top_sku": "#### ğŸ† Ğ¢Ğ¾Ğ¿ 15 SKU Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²",
        "ret_reasons": "#### ğŸ“Š ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²",
        "ret_filters": "ğŸ“¦ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²",
        "ret_date": "ğŸ“… Ğ”Ğ°Ñ‚Ğ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ°:",
        "ret_download": "ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ CSV Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²",
        "ord_title": "### ğŸ›’ ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ·Ğ°ĞºĞ°Ğ·Ğ¾Ğ²",
        "insight_rating_health": "Ğ—Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒĞµ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ°",
        "insight_loyalty": "Ğ›Ğ¾ÑĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ",
        "insight_toxic": "Ğ¢Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ğ¹ ASIN",
        "insight_neg_level": "Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ°",
        "insight_verified": "Ğ’ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ",
        "rev_auto_insights": "ğŸ§  ĞĞ²Ñ‚Ğ¾Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹",
        "rev_worst_asin": "ğŸ”´ Ğ¥Ğ£Ğ”Ğ¨Ğ˜Ğ™ ASIN",
        "rev_best_asin": "ğŸŸ¢ Ğ›Ğ£Ğ§Ğ¨Ğ˜Ğ™ ASIN",
        "rev_worst_country": "ğŸ”´ Ğ¥Ğ£Ğ”Ğ¨ĞĞ¯ Ğ¡Ğ¢Ğ ĞĞĞ",
        "rev_best_country": "ğŸŸ¢ Ğ›Ğ£Ğ§Ğ¨ĞĞ¯ Ğ¡Ğ¢Ğ ĞĞĞ",
        "rev_reviews_count": "Ğ¾Ñ‚Ğ·Ñ‹Ğ².",
        "rev_main_asin": "ğŸ“¦ Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹:",
        "rev_heatmap": "### ğŸ”¥ Ğ¢ĞµĞ¿Ğ»Ğ¾Ğ²Ğ°Ñ ĞºĞ°Ñ€Ñ‚Ğ°: ASIN Ã— Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ°",
        "rev_heatmap_hint": "ĞĞ°Ğ¶Ğ¼Ğ¸ Ğ½Ğ° ASIN Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ â€” Ğ¾Ñ‚ĞºÑ€Ğ¾ĞµÑ‚ÑÑ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° Amazon",
        "rev_asin_compare": "### ğŸ“Š Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ASINĞ¾Ğ²",
        "rev_star_dist": "### ğŸ“Š ĞĞ±Ñ‰ĞµĞµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ²Ñ‘Ğ·Ğ´",
        "rev_texts": "### ğŸ“‹ Ğ¢ĞµĞºÑÑ‚Ñ‹ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² (Ğ´Ğ¾ 100 Ğ½Ğ° Ğ·Ğ²ĞµĞ·Ğ´Ñƒ, Ğ¼Ğ°ĞºÑ 500)",
        "rev_sort_hint": "Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°: ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° 1â˜… â€” Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸",
        "rev_click_hint": "ğŸ‘† ĞĞ°Ğ¶Ğ¼Ğ¸ Ğ½Ğ° ÑÑ‚Ñ€Ğ¾ĞºÑƒ â€” ÑƒĞ²Ğ¸Ğ´Ğ¸ÑˆÑŒ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Â· Ğ¡ÑÑ‹Ğ»ĞºĞ¸ Ğ¾Ñ‚ĞºÑ€Ğ¾ÑÑ‚ Amazon Ğ² Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ",
        "rev_select_hint": "ğŸ‘‡ Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ ASIN Ğ´Ğ»Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°:",
        "rev_goto_asin": "ğŸ“¦ ĞŸĞµÑ€ĞµĞ¹Ñ‚Ğ¸ Ğº ASIN:",
        "rev_not_selected": "â€” Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ¾ â€”",
        "rev_back": "â† ĞĞ°Ğ·Ğ°Ğ´ ĞºĞ¾ Ğ²ÑĞµĞ¼ ASINĞ°Ğ¼",
        "rev_asins_in_filter": "ğŸ“¦ ASINĞ¾Ğ² Ğ² Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğµ",
        "insights_title": "ğŸ§  Ğ˜Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹",
        "insight_rating_health": "Ğ—Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒĞµ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ°",
        "insight_loyalty": "Ğ›Ğ¾ÑĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ",
        "insight_toxic": "Ğ¢Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ğ¹ ASIN",
        "insight_neg_level": "Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ°",
        "insight_verified": "Ğ’ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ",
        "rev_table_by_country": "ğŸ“‹ Ğ¡Ğ²Ğ¾Ğ´Ğ½Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ°Ğ¼",
        "rev_count_by_country": "ğŸ“Š ĞÑ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ°Ğ¼",
        "rev_neg_by_country": "ğŸ”´ % ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ°Ğ¼",
        "rev_rating_by_country": "â­ Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ°Ğ¼",
        "rev_country_analysis": "ğŸŒ ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ°Ğ¼",
        "rev_star_filter": "â­ Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³:",
        "rev_country_filter": "ğŸŒ Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ° (Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹Ñ):",
        "rev_filters": "â­ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²",
        "all_countries": "Ğ’ÑĞµ ÑÑ‚Ñ€Ğ°Ğ½Ñ‹",
        "all_asins": "Ğ’ÑĞµ ASINÑ‹",
    }
}


DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL and DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

def get_engine():
    return create_engine(
        DATABASE_URL,
        connect_args={"options": "-csearch_path=spapi,public", "connect_timeout": 10},
        pool_timeout=10,
        pool_pre_ping=True,
    )

# DATA LOADERS
# ============================================

@st.cache_data(ttl=60)
def load_data():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text("SELECT * FROM fba_inventory ORDER BY created_at DESC"), conn)
        return df
    except Exception as e:
        st.error(f"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ–Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ½Ñ Ğ´Ğ¾ Ğ‘Ğ” (Inventory): {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_orders():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM orders ORDER BY "Order Date" DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=True, errors='coerce')
        column_mappings = {
            'Quantity':       ['Quantity', 'quantity', 'qty'],
            'Item Price':     ['Item Price', 'item-price', 'item_price', 'price'],
            'Item Tax':       ['Item Tax', 'item-tax', 'item_tax', 'tax'],
            'Shipping Price': ['Shipping Price', 'shipping-price', 'shipping_price', 'shipping'],
        }
        for target_col, possible_names in column_mappings.items():
            found = False
            for col_name in possible_names:
                if col_name in df.columns:
                    df[target_col] = pd.to_numeric(df[col_name], errors='coerce').fillna(0)
                    found = True
                    break
            if not found:
                df[target_col] = 0
        df['Total Price'] = df['Item Price'] * df['Quantity']
        return df
    except Exception as e:
        st.error(f"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ orders: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_settlements():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM settlements ORDER BY "Posted Date" DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['Amount']      = pd.to_numeric(df['Amount'], errors='coerce').fillna(0.0)
        df['Quantity']    = pd.to_numeric(df['Quantity'], errors='coerce').fillna(0)
        df['Posted Date'] = pd.to_datetime(df['Posted Date'], dayfirst=True, errors='coerce')
        if 'Currency' not in df.columns:
            df['Currency'] = 'USD'
        df = df.dropna(subset=['Posted Date'])
        return df
    except Exception as e:
        st.error(f"Error loading settlements: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_sales_traffic():
    import psycopg2
    import psycopg2.extras
    db_url = DATABASE_URL
    if not db_url:
        return pd.DataFrame()
    if db_url.startswith("postgres://"):
        db_url = db_url.replace("postgres://", "postgresql://", 1)
    conn = None
    try:
        conn = psycopg2.connect(db_url, connect_timeout=10)
        cur  = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
        cur.execute("SELECT * FROM spapi.sales_traffic ORDER BY report_date DESC")
        rows    = cur.fetchall()
        columns = [desc[0] for desc in cur.description]
        cur.close()
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows, columns=columns)
        numeric_cols = [
            'sessions','page_views','units_ordered','units_ordered_b2b',
            'total_order_items','total_order_items_b2b',
            'ordered_product_sales','ordered_product_sales_b2b',
            'session_percentage','page_views_percentage',
            'buy_box_percentage','unit_session_percentage',
            'mobile_sessions','mobile_page_views',
            'browser_sessions','browser_page_views',
            'mobile_session_percentage','mobile_page_views_percentage',
            'mobile_unit_session_percentage','mobile_buy_box_percentage',
            'browser_session_percentage','browser_page_views_percentage',
            'browser_unit_session_percentage','browser_buy_box_percentage',
        ]
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df['report_date'] = pd.to_datetime(df['report_date'], errors='coerce')
        if 'created_at' in df.columns:
            created = pd.to_datetime(df['created_at'], errors='coerce').dt.normalize()
            if df['report_date'].isna().all():
                df['report_date'] = created
            elif df['report_date'].isna().any():
                mask = df['report_date'].isna()
                df.loc[mask, 'report_date'] = created[mask]
        df['report_date'] = df['report_date'].dt.normalize()
        df = df.dropna(subset=['report_date'])
        return df
    except Exception:
        return pd.DataFrame()
    finally:
        if conn:
            conn.close()


@st.cache_data(ttl=60)
def load_returns():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df_returns = pd.read_sql(text('SELECT * FROM returns ORDER BY "Return Date" DESC'), conn)
            df_orders  = pd.read_sql(text("SELECT * FROM orders"), conn)
        return df_returns, df_orders
    except Exception:
        return pd.DataFrame(), pd.DataFrame()


@st.cache_data(ttl=60)
def load_reviews():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM amazon_reviews ORDER BY review_date DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce')
        df['rating']      = pd.to_numeric(df['rating'], errors='coerce').fillna(0).astype(int)
        if 'is_verified' in df.columns:
            df['is_verified'] = df['is_verified'].astype(bool)
        if 'domain' in df.columns:
            df['domain'] = df['domain'].str.lower().str.strip()
        return df
    except Exception:
        return pd.DataFrame()


# ============================================
# HELPERS
# ============================================

def insight_card(emoji, title, text, color="#1e1e2e"):
    st.markdown(f"""
    <div style="background:{color};border-left:4px solid #4472C4;border-radius:8px;
                padding:14px 18px;margin-bottom:10px;">
        <div style="font-size:16px;font-weight:700;color:#fff;margin-bottom:4px;">{emoji} {title}</div>
        <div style="font-size:14px;color:#ccc;line-height:1.5;">{text}</div>
    </div>""", unsafe_allow_html=True)


def balanced_reviews(df, max_per_star=100):
    parts = [df[df['rating'] == s].head(max_per_star) for s in [1, 2, 3, 4, 5]]
    return pd.concat(parts, ignore_index=True) if parts else df


DOMAIN_LABELS = {
    'com':    'ğŸ‡ºğŸ‡¸ USA (com)',
    'ca':     'ğŸ‡¨ğŸ‡¦ Canada (ca)',
    'de':     'ğŸ‡©ğŸ‡ª Germany (de)',
    'co.uk':  'ğŸ‡¬ğŸ‡§ UK (co.uk)',
    'it':     'ğŸ‡®ğŸ‡¹ Italy (it)',
    'es':     'ğŸ‡ªğŸ‡¸ Spain (es)',
    'fr':     'ğŸ‡«ğŸ‡· France (fr)',
    'co.jp':  'ğŸ‡¯ğŸ‡µ Japan (co.jp)',
    'com.au': 'ğŸ‡¦ğŸ‡º Australia (com.au)',
    'com.mx': 'ğŸ‡²ğŸ‡½ Mexico (com.mx)',
    'nl':     'ğŸ‡³ğŸ‡± Netherlands (nl)',
    'pl':     'ğŸ‡µğŸ‡± Poland (pl)',
    'se':     'ğŸ‡¸ğŸ‡ª Sweden (se)',
}


# ============================================
# INSIGHT FUNCTIONS
# ============================================

def insights_sales_traffic(df_filtered, asin_stats):
    st.markdown("---")
    st.markdown("### ğŸ§  ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹")
    total_sessions = int(df_filtered['sessions'].sum())
    total_units    = int(df_filtered['units_ordered'].sum())
    total_revenue  = df_filtered['ordered_product_sales'].sum()
    avg_conv       = (total_units / total_sessions * 100) if total_sessions > 0 else 0
    avg_buy_box    = df_filtered['buy_box_percentage'].mean()
    mob            = df_filtered['mobile_sessions'].sum() if 'mobile_sessions' in df_filtered.columns else 0
    bro            = df_filtered['browser_sessions'].sum() if 'browser_sessions' in df_filtered.columns else 0
    mobile_pct     = (mob / (mob + bro) * 100) if (mob + bro) > 0 else 0
    avg_conv_all   = asin_stats['Conv %'].median()
    low_conv       = asin_stats[(asin_stats['Sessions'] > asin_stats['Sessions'].median()) & (asin_stats['Conv %'] < avg_conv_all)]
    low_bb         = asin_stats[asin_stats['Buy Box %'] < 80]
    rev_per_sess   = total_revenue / total_sessions if total_sessions > 0 else 0
    cols = st.columns(2)
    i = 0
    if avg_conv >= 12:   txt, em, col = f"ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ <b>{avg_conv:.1f}%</b> â€” Ğ²Ñ‹ÑˆĞµ Ğ½Ğ¾Ñ€Ğ¼Ñ‹. ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞ¹ Ñ€ĞµĞºĞ»Ğ°Ğ¼Ñƒ!", "ğŸŸ¢", "#0d2b1e"
    elif avg_conv >= 8:  txt, em, col = f"ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ <b>{avg_conv:.1f}%</b> â€” Ğ² Ğ½Ğ¾Ñ€Ğ¼Ğµ. ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» Ñ‡ĞµÑ€ĞµĞ· A+.", "ğŸŸ¡", "#2b2400"
    else:                txt, em, col = f"ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ <b>{avg_conv:.1f}%</b> â€” Ğ½Ğ¸Ğ¶Ğµ Ğ½Ğ¾Ñ€Ğ¼Ñ‹. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ñ„Ğ¾Ñ‚Ğ¾ Ğ¸ Ñ†ĞµĞ½Ñƒ.", "ğŸ”´", "#2b0d0d"
    with cols[i%2]: insight_card(em, "ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ", txt, col); i+=1
    if avg_buy_box >= 95:  txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> â€” Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾!", "ğŸŸ¢", "#0d2b1e"
    elif avg_buy_box >= 80: txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> â€” Ğ½Ğ¾Ñ€Ğ¼Ğ°. {len(low_bb)} ASINĞ¾Ğ² Ñ‚ĞµÑ€ÑÑÑ‚.", "ğŸŸ¡", "#2b2400"
    else:                   txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> â€” ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾! ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ñ€ĞµĞ¿Ñ€Ğ°Ğ¹ÑĞµÑ€.", "ğŸ”´", "#2b0d0d"
    with cols[i%2]: insight_card(em, "Buy Box", txt, col); i+=1
    txt = f"<b>{mobile_pct:.0f}%</b> Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ° {'â€” Ğ½Ğ¾Ñ€Ğ¼Ğ°.' if mobile_pct >= 60 else 'â€” Ğ½Ğ¸Ğ¶Ğµ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ ~65%.'}"
    with cols[i%2]: insight_card("ğŸ“±", "ĞœĞ¾Ğ±Ğ°Ğ¹Ğ»", txt, "#1a1a2e"); i+=1
    if len(low_conv) > 0:
        top = low_conv.nlargest(1,'Sessions').iloc[0]
        txt, em, col = f"<b>{len(low_conv)} ASINĞ¾Ğ²</b> Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ¼ Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸ĞµĞ¹. ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹: <b>{top['ASIN']}</b>.", "ğŸ”´", "#2b0d0d"
    else: txt, em, col = "Ğ’ÑĞµ ASINÑ‹ Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ¼ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚ÑÑ‚ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾!", "ğŸŸ¢", "#0d2b1e"
    with cols[i%2]: insight_card(em, "Ğ£Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ğ°Ñ Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ°", txt, col); i+=1
    with cols[i%2]: insight_card("ğŸ’¡", "Ğ¦ĞµĞ½Ğ° ÑĞµÑÑĞ¸Ğ¸", f"ĞšĞ°Ğ¶Ğ´Ğ°Ñ ÑĞµÑÑĞ¸Ñ â†’ <b>${rev_per_sess:.2f}</b>. +1000 ÑĞµÑÑĞ¸Ğ¹ = +${rev_per_sess*1000:,.0f}.", "#1a1a2e"); i+=1
    if not asin_stats.empty:
        top = asin_stats.nlargest(1,'Revenue').iloc[0]
        top_pct = top['Revenue']/total_revenue*100 if total_revenue > 0 else 0
        with cols[i%2]: insight_card("ğŸ†", "Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ ASIN", f"<b>{top['ASIN']}</b> = ${top['Revenue']:,.0f} ({top_pct:.0f}%).", "#1a2b1e")


def insights_settlements(df_filtered):
    st.markdown("---")
    st.markdown("### ğŸ§  ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹")
    net     = df_filtered['Amount'].sum()
    gross   = df_filtered[(df_filtered['Transaction Type']=='Order')&(df_filtered['Amount']>0)]['Amount'].sum()
    fees    = df_filtered[(df_filtered['Amount']<0)&(df_filtered['Transaction Type']!='Refund')&(~df_filtered['Transaction Type'].str.lower().str.contains('other',na=False))]['Amount'].sum()
    refunds = df_filtered[df_filtered['Transaction Type']=='Refund']['Amount'].sum()
    fee_pct    = abs(fees)/gross*100 if gross>0 else 0
    refund_pct = abs(refunds)/gross*100 if gross>0 else 0
    margin_pct = net/gross*100 if gross>0 else 0
    cols = st.columns(2); i = 0
    if margin_pct >= 30:  txt, em, col = f"ĞœĞ°Ñ€Ğ¶Ğ° <b>{margin_pct:.1f}%</b> â€” Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾!", "ğŸŸ¢", "#0d2b1e"
    elif margin_pct >= 15: txt, em, col = f"ĞœĞ°Ñ€Ğ¶Ğ° <b>{margin_pct:.1f}%</b> â€” Ğ½Ğ¾Ñ€Ğ¼Ğ° Ğ´Ğ»Ñ FBA.", "ğŸŸ¡", "#2b2400"
    else:                  txt, em, col = f"ĞœĞ°Ñ€Ğ¶Ğ° <b>{margin_pct:.1f}%</b> â€” Ğ½Ğ¸Ğ·ĞºĞ¾! ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ñ‹.", "ğŸ”´", "#2b0d0d"
    with cols[i%2]: insight_card(em, "Ğ§Ğ¸ÑÑ‚Ğ°Ñ Ğ¼Ğ°Ñ€Ğ¶Ğ°", txt, col); i+=1
    if fee_pct <= 30:  txt, em, col = f"ĞšĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸ <b>{fee_pct:.1f}%</b> â€” Ğ² Ğ½Ğ¾Ñ€Ğ¼Ğµ.", "ğŸŸ¢", "#0d2b1e"
    elif fee_pct <= 40: txt, em, col = f"ĞšĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸ <b>{fee_pct:.1f}%</b> â€” Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹ÑĞ¾ĞºĞ¾.", "ğŸŸ¡", "#2b2400"
    else:               txt, em, col = f"ĞšĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸ <b>{fee_pct:.1f}%</b> â€” ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ²Ñ‹ÑĞ¾ĞºĞ¾!", "ğŸ”´", "#2b0d0d"
    with cols[i%2]: insight_card(em, "ĞĞ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¹", txt, col); i+=1
    if refund_pct <= 3:  txt, em, col = f"Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹ <b>{refund_pct:.1f}%</b> â€” Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾.", "ğŸŸ¢", "#0d2b1e"
    elif refund_pct <= 8: txt, em, col = f"Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹ <b>{refund_pct:.1f}%</b> â€” ÑƒĞ¼ĞµÑ€ĞµĞ½Ğ½Ğ¾.", "ğŸŸ¡", "#2b2400"
    else:                 txt, em, col = f"Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹ <b>{refund_pct:.1f}%</b> â€” ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾!", "ğŸ”´", "#2b0d0d"
    with cols[i%2]: insight_card(em, "Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹", txt, col); i+=1
    with cols[i%2]: insight_card("ğŸ’°", "Ğ˜Ñ‚Ğ¾Ğ³", f"ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ <b>${gross:,.0f}</b> â†’ Ğ½Ğ° Ñ€ÑƒĞºĞ¸ <b>${net:,.0f}</b>. ĞšĞ¾Ğ¼Ğ¸ÑÑĞ¸Ğ¸: ${abs(fees):,.0f}.", "#1a1a2e")


def insights_returns(df_filtered, return_rate):
    st.markdown("---")
    st.markdown("### ğŸ§  ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹")
    total_val  = df_filtered['Return Value'].sum()
    top_reason = df_filtered['Reason'].value_counts().index[0] if 'Reason' in df_filtered.columns and not df_filtered.empty else None
    top_sku    = df_filtered['SKU'].value_counts().index[0] if not df_filtered.empty else None
    cols = st.columns(2); i = 0
    if return_rate <= 3:  txt, em, col = f"Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹ <b>{return_rate:.1f}%</b> â€” Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾.", "ğŸŸ¢", "#0d2b1e"
    elif return_rate <= 8: txt, em, col = f"Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹ <b>{return_rate:.1f}%</b> â€” Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ»ĞµĞ¼Ğ¾.", "ğŸŸ¡", "#2b2400"
    else:                  txt, em, col = f"Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹ <b>{return_rate:.1f}%</b> â€” Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾!", "ğŸ”´", "#2b0d0d"
    with cols[i%2]: insight_card(em, "Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²", txt, col); i+=1
    with cols[i%2]: insight_card("ğŸ’¸", "Ğ£Ñ‰ĞµÑ€Ğ±", f"Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ñ‹ ÑÑ‚Ğ¾ÑÑ‚ <b>${total_val:,.0f}</b>.", "#2b1a00"); i+=1
    if top_reason:
        with cols[i%2]: insight_card("ğŸ”", "Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°", f"<b>Â«{top_reason}Â»</b>", "#1a1a2e"); i+=1
    if top_sku:
        count = df_filtered['SKU'].value_counts().iloc[0]
        with cols[i%2]: insight_card("âš ï¸", "ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğ¹ SKU", f"<b>{top_sku}</b> ({count} Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ¾Ğ²).", "#2b0d0d")


def insights_inventory(df_filtered):
    st.markdown("---")
    st.markdown("### ğŸ§  ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹")
    total_val   = df_filtered['Stock Value'].sum()
    total_units = df_filtered['Available'].sum()
    avg_vel     = df_filtered['Velocity'].mean() if 'Velocity' in df_filtered.columns else 0
    top_frozen  = df_filtered.nlargest(1,'Stock Value').iloc[0] if not df_filtered.empty else None
    dead_stock  = df_filtered[df_filtered['Velocity']==0] if 'Velocity' in df_filtered.columns else pd.DataFrame()
    cols = st.columns(2); i = 0
    months = int(total_units/avg_vel/30) if avg_vel > 0 else 0
    with cols[i%2]: insight_card("ğŸ§Š","Ğ—Ğ°Ğ¼Ğ¾Ñ€Ğ¾Ğ·ĞºĞ° ĞºĞ°Ğ¿Ğ¸Ñ‚Ğ°Ğ»Ğ°",f"Ğ—Ğ°Ğ¼Ğ¾Ñ€Ğ¾Ğ¶ĞµĞ½Ğ¾ <b>${total_val:,.0f}</b>. Ğ—Ğ°Ğ¿Ğ°Ñ Ğ½Ğ° {months if avg_vel>0 else 'âˆ'} Ğ¼ĞµÑ.","#1a1a2e"); i+=1
    if top_frozen is not None:
        pct = top_frozen['Stock Value']/total_val*100 if total_val > 0 else 0
        with cols[i%2]: insight_card("ğŸ¦","Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ°ĞºÑ‚Ğ¸Ğ²",f"<b>{top_frozen['SKU']}</b> Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ${top_frozen['Stock Value']:,.0f} ({pct:.0f}%).","#1a2b1e"); i+=1
    if len(dead_stock) > 0:
        dead_val = dead_stock['Stock Value'].sum()
        with cols[i%2]: insight_card("â˜ ï¸","ĞœÑ‘Ñ€Ñ‚Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ¾Ğº",f"<b>{len(dead_stock)} SKU</b> Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶ â€” ${dead_val:,.0f}. Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸ Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ.","#2b0d0d"); i+=1
    days = int(total_units/(avg_vel*30)*30) if avg_vel > 0 else 999
    if days <= 30:   txt, em, col = f"Ğ—Ğ°Ğ¿Ğ°ÑĞ¾Ğ² Ğ½Ğ° <b>{days} Ğ´Ğ½ĞµĞ¹</b> â€” Ñ€Ğ¸ÑĞº out of stock!", "ğŸ”´", "#2b0d0d"
    elif days <= 60: txt, em, col = f"Ğ—Ğ°Ğ¿Ğ°ÑĞ¾Ğ² Ğ½Ğ° <b>{days} Ğ´Ğ½ĞµĞ¹</b> â€” Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒĞ¹ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºÑƒ.", "ğŸŸ¡", "#2b2400"
    else:            txt, em, col = f"Ğ—Ğ°Ğ¿Ğ°ÑĞ¾Ğ² Ğ½Ğ° <b>{days} Ğ´Ğ½ĞµĞ¹</b> â€” Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾.", "ğŸŸ¢", "#0d2b1e"
    with cols[i%2]: insight_card(em,"ĞĞ±Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼Ğ¾ÑÑ‚ÑŒ",txt,col)


def insights_orders(df_filtered):
    st.markdown("---")
    st.markdown("### ğŸ§  ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹")
    total_rev    = df_filtered['Total Price'].sum()
    total_orders = df_filtered['Order ID'].nunique()
    avg_order    = total_rev/total_orders if total_orders > 0 else 0
    days         = max((df_filtered['Order Date'].max()-df_filtered['Order Date'].min()).days,1)
    rev_per_day  = total_rev/days
    top_sku      = df_filtered.groupby('SKU')['Total Price'].sum().nlargest(1)
    cols = st.columns(2); i = 0
    with cols[i%2]: insight_card("ğŸ›’","Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ‡ĞµĞº",f"<b>${avg_order:.2f}</b>. +10% Ğº AOV = +${total_rev*0.1:,.0f}.","#1a1a2e"); i+=1
    with cols[i%2]: insight_card("ğŸ“ˆ","Ğ”Ğ½ĞµĞ²Ğ½Ğ°Ñ Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ°",f"<b>${rev_per_day:,.0f}/Ğ´ĞµĞ½ÑŒ</b>. ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ½Ğ° Ğ¼ĞµÑÑÑ†: ${rev_per_day*30:,.0f}.","#1a2b1e"); i+=1
    if not top_sku.empty:
        sku_name, sku_rev = top_sku.index[0], top_sku.iloc[0]
        pct = sku_rev/total_rev*100 if total_rev > 0 else 0
        with cols[i%2]: insight_card("âš¡","ĞšĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ñ€Ğ¸ÑĞºĞ°",f"<b>{sku_name}</b> = {pct:.0f}% (${sku_rev:,.0f}). Ğ”Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞ¹.","#2b1a00")


def insights_reviews(df, asin=None):
    st.markdown("---")
    label = f"ASIN {asin}" if asin else "Ğ²ÑĞµĞ¼ ASINĞ°Ğ¼"
    st.markdown(f"### {t['insights_title']} Ğ¿Ğ¾ {label}")
    total = len(df)
    if total == 0:
        st.info("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ğ¾Ğ².")
        return
    avg_rating = df['rating'].mean()
    neg_df     = df[df['rating'] <= 2]
    pos_df     = df[df['rating'] >= 4]
    neg_pct    = len(neg_df)/total*100
    pos_pct    = len(pos_df)/total*100
    cols = st.columns(2); i = 0
    if avg_rating >= 4.4:   txt, em, col = f"Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ±Ğ°Ğ»Ğ» <b>{avg_rating:.1f}â˜…</b> â€” Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾! Ğ¡Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ğµ.", "ğŸŸ¢", "#0d2b1e"
    elif avg_rating >= 4.0: txt, em, col = f"Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ±Ğ°Ğ»Ğ» <b>{avg_rating:.1f}â˜…</b> â€” Ğ½Ğ¾Ñ€Ğ¼Ğ°, Ñ€Ğ¸ÑĞº ÑƒĞ¿Ğ°ÑÑ‚ÑŒ Ğ½Ğ¸Ğ¶Ğµ 4.0.", "ğŸŸ¡", "#2b2400"
    else:                   txt, em, col = f"Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ±Ğ°Ğ»Ğ» <b>{avg_rating:.1f}â˜…</b> â€” ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾! Ğ ĞµĞ¶ĞµÑ‚ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¸ ÑƒĞ´Ğ¾Ñ€Ğ¾Ğ¶Ğ°ĞµÑ‚ PPC.", "ğŸ”´", "#2b0d0d"
    with cols[i%2]: insight_card(em,t["insight_rating_health"],txt,col); i+=1
    if neg_pct <= 10:  txt, em, col = f"Ğ’ÑĞµĞ³Ğ¾ <b>{neg_pct:.1f}%</b> Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… (1-2â˜…). ĞŸÑ€Ğ¾Ğ´ÑƒĞºÑ‚ Ğ¾Ğ¿Ñ€Ğ°Ğ²Ğ´Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ.", "ğŸŸ¢", "#0d2b1e"
    elif neg_pct <= 20: txt, em, col = f"<b>{neg_pct:.1f}%</b> Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… â€” ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°. Ğ§Ğ¸Ñ‚Ğ°Ğ¹ Ñ‚ĞµĞºÑÑ‚Ñ‹ 1â˜….", "ğŸŸ¡", "#2b2400"
    else:               txt, em, col = f"<b>{neg_pct:.1f}%</b> Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… â€” ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾! Ğ¡Ñ€Ğ¾Ñ‡Ğ½Ğ¾ Ñ„Ğ¸ĞºÑĞ¸ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚ Ğ¸Ğ»Ğ¸ Ğ»Ğ¸ÑÑ‚Ğ¸Ğ½Ğ³.", "ğŸ”´", "#2b0d0d"
    with cols[i%2]: insight_card(em,"Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ°",txt,col); i+=1
    with cols[i%2]: insight_card("ğŸ’š",t["insight_loyalty"],f"<b>{pos_pct:.1f}%</b> Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ… (4-5â˜…)","#0d2b1e" if pos_pct>=70 else "#2b2400"); i+=1
    if 'is_verified' in df.columns:
        ver_pct = df['is_verified'].mean()*100
        with cols[i%2]: insight_card("âœ…","Ğ’ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ",f"<b>{ver_pct:.1f}%</b> Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ {'â€” Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğµ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ğµ Ñƒ Amazon.' if ver_pct>=80 else 'â€” ÑĞ»ĞµĞ´Ğ¸ Ğ·Ğ° Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¾Ğ¹.'}","#1a1a2e"); i+=1
    if asin is None and not neg_df.empty and 'asin' in neg_df.columns:
        worst = neg_df['asin'].value_counts()
        if not worst.empty:
            with cols[i%2]: insight_card("âš ï¸",t["insight_toxic"],f"<b>{worst.index[0]}</b> â€” {worst.iloc[0]} Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…. ĞĞ°Ñ‡Ğ½Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ Ğ½ĞµĞ³Ğ¾.","#2b0d0d")


# ============================================
# OVERVIEW CONSOLIDATED INSIGHTS
# ============================================

def show_overview_insights(df_inventory):
    st.markdown("---")
    st.markdown("## ğŸ§  Business Intelligence: Ğ—Ğ²ĞµĞ´ĞµĞ½Ñ– Ñ–Ğ½ÑĞ°Ğ¹Ñ‚Ğ¸")
    st.caption("ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ²ÑÑ–Ñ… Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ–Ğ²")

    df_settlements = load_settlements()
    df_st          = load_sales_traffic()
    df_orders      = load_orders()
    df_ret_raw, df_ord_raw = load_returns()
    df_reviews     = load_reviews()

    df_returns  = pd.DataFrame()
    return_rate = 0
    if not df_ret_raw.empty:
        df_ret = df_ret_raw.copy()
        df_ret['Return Date'] = pd.to_datetime(df_ret['Return Date'], errors='coerce')
        if 'Price' not in df_ret.columns and not df_ord_raw.empty:
            for col in ['Item Price','item-price','item_price','price']:
                if col in df_ord_raw.columns:
                    df_ord_raw[col] = pd.to_numeric(df_ord_raw[col], errors='coerce')
                    df_ret['Price'] = df_ret['SKU'].map(df_ord_raw.groupby('SKU')[col].mean()).fillna(0)
                    break
        if 'Price' not in df_ret.columns: df_ret['Price'] = 0
        df_ret['Price']        = pd.to_numeric(df_ret['Price'], errors='coerce').fillna(0)
        df_ret['Quantity']     = pd.to_numeric(df_ret.get('Quantity',1), errors='coerce').fillna(1)
        df_ret['Return Value'] = df_ret['Price'] * df_ret['Quantity']
        df_returns = df_ret
        if not df_ord_raw.empty:
            for col in ['Order ID','order-id','order_id','OrderID']:
                if col in df_ord_raw.columns:
                    total_orders = df_ord_raw[col].nunique()
                    unique_ret   = df_returns['Order ID'].nunique() if 'Order ID' in df_returns.columns else 0
                    return_rate  = unique_ret/total_orders*100 if total_orders > 0 else 0
                    break

    tabs = st.tabs(["ğŸ’° Inventory","ğŸ¦ Settlements","ğŸ“ˆ Sales & Traffic","ğŸ›’ Orders","ğŸ“¦ Returns","â­ Reviews"])

    with tabs[0]:
        if not df_inventory.empty and 'Stock Value' in df_inventory.columns:
            insights_inventory(df_inventory)
        else: st.info("ğŸ“¦ Ğ”Ğ°Ğ½Ñ– Ğ¿Ğ¾ Ñ–Ğ½Ğ²ĞµĞ½Ñ‚Ğ°Ñ€Ñ Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–")

    with tabs[1]:
        if not df_settlements.empty:
            max_d  = df_settlements['Posted Date'].max()
            df_s30 = df_settlements[df_settlements['Posted Date'] >= max_d - dt.timedelta(days=30)]
            insights_settlements(df_s30 if not df_s30.empty else df_settlements)
        else: st.info("ğŸ¦ Ğ”Ğ°Ğ½Ñ– Ğ¿Ğ¾ Ğ²Ğ¸Ğ¿Ğ»Ğ°Ñ‚Ğ°Ñ… Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–.")

    with tabs[2]:
        if not df_st.empty:
            max_d   = df_st['report_date'].max()
            df_use  = df_st[df_st['report_date'] >= max_d - dt.timedelta(days=14)]
            df_use  = df_use if not df_use.empty else df_st
            asin_col = 'child_asin' if 'child_asin' in df_use.columns else df_use.columns[0]
            as_ = df_use.groupby(asin_col).agg({'sessions':'sum','units_ordered':'sum','ordered_product_sales':'sum','buy_box_percentage':'mean'}).reset_index()
            as_.columns = ['ASIN','Sessions','Units','Revenue','Buy Box %']
            as_['Conv %'] = (as_['Units']/as_['Sessions']*100).fillna(0)
            insights_sales_traffic(df_use, as_)
        else: st.info("ğŸ“ˆ Ğ”Ğ°Ğ½Ñ– Sales & Traffic Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–.")

    with tabs[3]:
        if not df_orders.empty:
            max_d  = df_orders['Order Date'].max()
            df_o30 = df_orders[df_orders['Order Date'] >= max_d - dt.timedelta(days=30)]
            insights_orders(df_o30 if not df_o30.empty else df_orders)
        else: st.info("ğŸ›’ Ğ”Ğ°Ğ½Ñ– Ğ·Ğ°Ğ¼Ğ¾Ğ²Ğ»ĞµĞ½ÑŒ Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–.")

    with tabs[4]:
        if not df_returns.empty:
            max_d  = df_returns['Return Date'].max()
            df_r30 = df_returns[df_returns['Return Date'] >= max_d - dt.timedelta(days=30)]
            insights_returns(df_r30 if not df_r30.empty else df_returns, return_rate)
        else: st.info("ğŸ“¦ Ğ”Ğ°Ğ½Ñ– Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ĞµĞ½ÑŒ Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–.")

    with tabs[5]:
        if not df_reviews.empty: insights_reviews(df_reviews, asin=None)
        else: st.info("â­ Ğ”Ğ°Ğ½Ñ– Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–.")


# ============================================
# â­ REVIEWS MODULE
# ============================================

def make_amazon_url(domain, asin):
    return f"https://www.amazon.{domain}/dp/{asin}"


def show_global_insights(df, has_domain):
    st.markdown(f"### {t['rev_auto_insights']}")

    asin_stats, dom_stats = None, None

    if 'asin' in df.columns:
        asin_stats = df.groupby('asin').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
        ).reset_index()
        asin_stats['Neg %'] = (asin_stats['Neg'] / asin_stats['Reviews'] * 100).round(1)
        asin_stats = asin_stats[asin_stats['Reviews'] >= 5]

    if has_domain and 'domain' in df.columns:
        dom_stats = df.groupby('domain').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
        ).reset_index()
        dom_stats['Neg %'] = (dom_stats['Neg'] / dom_stats['Reviews'] * 100).round(1)
        dom_stats = dom_stats[dom_stats['Reviews'] >= 5]

    col1, col2, col3, col4 = st.columns(4)

    if asin_stats is not None and not asin_stats.empty:
        worst_a = asin_stats.loc[asin_stats['Neg %'].idxmax()]
        best_a  = asin_stats.loc[asin_stats['Rating'].idxmax()]

        worst_asin_country = ""
        if has_domain and 'domain' in df.columns:
            asin_dom = df[df['asin'] == worst_a['asin']].groupby('domain')['rating'].count()
            if not asin_dom.empty:
                top_dom = asin_dom.idxmax()
                worst_asin_country = DOMAIN_LABELS.get(top_dom, top_dom)

        best_asin_country = ""
        if has_domain and 'domain' in df.columns:
            asin_dom2 = df[df['asin'] == best_a['asin']].groupby('domain')['rating'].count()
            if not asin_dom2.empty:
                top_dom2 = asin_dom2.idxmax()
                best_asin_country = DOMAIN_LABELS.get(top_dom2, top_dom2)

        neg_pct = worst_a['Neg %']
        bar_color = "#F44336" if neg_pct > 20 else "#FFC107"
        country_line = f"<div style='font-size:11px;color:#aaa;margin-top:2px'>ğŸŒ {worst_asin_country}</div>" if worst_asin_country else ""

        with col1:
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:5px solid {bar_color};border-radius:10px;padding:16px 20px;height:140px">
              <div style="font-size:11px;color:#888;margin-bottom:4px">ğŸ”´ ĞĞĞ™Ğ“Ğ†Ğ Ğ¨Ğ˜Ğ™ ASIN</div>
              <div style="font-size:20px;font-weight:800;color:#fff;letter-spacing:1px">{worst_a['asin']}</div>
              {country_line}
              <div style="display:flex;gap:12px;margin-top:8px;flex-wrap:wrap">
                <span style="color:#aaa;font-size:12px">â­ {worst_a['Rating']:.2f}â˜…</span>
                <span style="color:{bar_color};font-size:12px;font-weight:700">ğŸ”´ {neg_pct:.1f}% neg</span>
                <span style="color:#666;font-size:12px">{int(worst_a['Reviews'])} {t['rev_reviews_count']}</span>
              </div>
              <div style="margin-top:10px;background:#2a2a3e;border-radius:4px;height:5px">
                <div style="width:{min(neg_pct,100):.0f}%;background:{bar_color};border-radius:4px;height:5px"></div>
              </div>
            </div>""", unsafe_allow_html=True)

        rating_color = "#4CAF50" if best_a['Rating'] >= 4.4 else "#FFC107"
        country_line2 = f"<div style='font-size:11px;color:#aaa;margin-top:2px'>ğŸŒ {best_asin_country}</div>" if best_asin_country else ""
        with col2:
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:5px solid {rating_color};border-radius:10px;padding:16px 20px;height:140px">
              <div style="font-size:11px;color:#888;margin-bottom:4px">ğŸŸ¢ ĞĞĞ™ĞšĞ ĞĞ©Ğ˜Ğ™ ASIN</div>
              <div style="font-size:20px;font-weight:800;color:#fff;letter-spacing:1px">{best_a['asin']}</div>
              {country_line2}
              <div style="display:flex;gap:12px;margin-top:8px;flex-wrap:wrap">
                <span style="color:{rating_color};font-size:12px;font-weight:700">â­ {best_a['Rating']:.2f}â˜…</span>
                <span style="color:#aaa;font-size:12px">ğŸ”´ {best_a['Neg %']:.1f}% neg</span>
                <span style="color:#666;font-size:12px">{int(best_a['Reviews'])} {t['rev_reviews_count']}</span>
              </div>
              <div style="margin-top:10px;background:#2a2a3e;border-radius:4px;height:5px">
                <div style="width:{((best_a['Rating']-1)/4*100):.0f}%;background:{rating_color};border-radius:4px;height:5px"></div>
              </div>
            </div>""", unsafe_allow_html=True)

    if dom_stats is not None and not dom_stats.empty:
        worst_d = dom_stats.loc[dom_stats['Neg %'].idxmax()]
        best_d  = dom_stats.loc[dom_stats['Rating'].idxmax()]
        worst_label = DOMAIN_LABELS.get(worst_d['domain'], worst_d['domain'])
        best_label  = DOMAIN_LABELS.get(best_d['domain'], best_d['domain'])

        worst_country_asin = ""
        if 'asin' in df.columns:
            df_wdom = df[df['domain'] == worst_d['domain']]
            if not df_wdom.empty:
                per_asin = df_wdom.groupby('asin').agg(
                    Neg=('rating', lambda x: (x<=2).sum()),
                    Reviews=('rating','count')
                ).reset_index()
                per_asin['Neg %'] = per_asin['Neg'] / per_asin['Reviews'] * 100
                per_asin = per_asin[per_asin['Reviews'] >= 3]
                if not per_asin.empty:
                    worst_country_asin = per_asin.loc[per_asin['Neg %'].idxmax(), 'asin']

        best_country_asin = ""
        if 'asin' in df.columns:
            df_bdom = df[df['domain'] == best_d['domain']]
            if not df_bdom.empty:
                per_asin2 = df_bdom.groupby('asin').agg(
                    Rating=('rating','mean'), Reviews=('rating','count')
                ).reset_index()
                per_asin2 = per_asin2[per_asin2['Reviews'] >= 3]
                if not per_asin2.empty:
                    best_country_asin = per_asin2.loc[per_asin2['Rating'].idxmax(), 'asin']

        neg_pct = worst_d['Neg %']
        bar_color = "#F44336" if neg_pct > 20 else "#FFC107"
        asin_line_w = f"<div style='font-size:11px;color:#aaa;margin-top:2px'>{t['rev_main_asin']} {worst_country_asin}</div>" if worst_country_asin else ""
        asin_line_b = f"<div style='font-size:11px;color:#aaa;margin-top:2px'>{t['rev_main_asin']} {best_country_asin}</div>" if best_country_asin else ""

        with col3:
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:5px solid {bar_color};border-radius:10px;padding:16px 20px;height:140px">
              <div style="font-size:11px;color:#888;margin-bottom:4px">ğŸ”´ ĞĞĞ™Ğ“Ğ†Ğ Ğ¨Ğ ĞšĞ ĞĞ‡ĞĞ</div>
              <div style="font-size:18px;font-weight:800;color:#fff">{worst_label}</div>
              {asin_line_w}
              <div style="display:flex;gap:12px;margin-top:8px;flex-wrap:wrap">
                <span style="color:#aaa;font-size:12px">â­ {worst_d['Rating']:.2f}â˜…</span>
                <span style="color:{bar_color};font-size:12px;font-weight:700">ğŸ”´ {neg_pct:.1f}% neg</span>
                <span style="color:#666;font-size:12px">{int(worst_d['Reviews'])} {t['rev_reviews_count']}</span>
              </div>
              <div style="margin-top:10px;background:#2a2a3e;border-radius:4px;height:5px">
                <div style="width:{min(neg_pct,100):.0f}%;background:{bar_color};border-radius:4px;height:5px"></div>
              </div>
            </div>""", unsafe_allow_html=True)

        rating_color = "#4CAF50" if best_d['Rating'] >= 4.4 else "#FFC107"
        with col4:
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:5px solid {rating_color};border-radius:10px;padding:16px 20px;height:140px">
              <div style="font-size:11px;color:#888;margin-bottom:4px">ğŸŸ¢ ĞĞĞ™ĞšĞ ĞĞ©Ğ ĞšĞ ĞĞ‡ĞĞ</div>
              <div style="font-size:18px;font-weight:800;color:#fff">{best_label}</div>
              {asin_line_b}
              <div style="display:flex;gap:12px;margin-top:8px;flex-wrap:wrap">
                <span style="color:{rating_color};font-size:12px;font-weight:700">â­ {best_d['Rating']:.2f}â˜…</span>
                <span style="color:#aaa;font-size:12px">ğŸ”´ {best_d['Neg %']:.1f}% neg</span>
                <span style="color:#666;font-size:12px">{int(best_d['Reviews'])} {t['rev_reviews_count']}</span>
              </div>
              <div style="margin-top:10px;background:#2a2a3e;border-radius:4px;height:5px">
                <div style="width:{((best_d['Rating']-1)/4*100):.0f}%;background:{rating_color};border-radius:4px;height:5px"></div>
              </div>
            </div>""", unsafe_allow_html=True)


def show_single_asin_detail(df_asin, asin, has_domain):
    total = len(df_asin)
    if total == 0:
        st.info("ĞĞµĞ¼Ğ°Ñ” Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² Ğ¿Ğ¾ Ñ†ÑŒĞ¾Ğ¼Ñƒ ASIN.")
        return

    avg_r   = df_asin['rating'].mean()
    neg_cnt = int((df_asin['rating'] <= 2).sum())
    pos_cnt = int((df_asin['rating'] >= 4).sum())
    neg_pct = neg_cnt / total * 100

    r_color = "#4CAF50" if avg_r >= 4.4 else "#FFC107" if avg_r >= 4.0 else "#F44336"
    n_color = "#4CAF50" if neg_pct <= 10 else "#FFC107" if neg_pct <= 20 else "#F44336"

    st.markdown(f"""
    <div style="background:#1e1e2e;border-radius:12px;padding:18px 24px;margin-bottom:16px;display:flex;gap:40px;align-items:center">
      <div>
        <div style="font-size:11px;color:#888">ASIN</div>
        <div style="font-size:20px;font-weight:800;color:#fff;letter-spacing:1px">{asin}</div>
      </div>
      <div>
        <div style="font-size:11px;color:#888">Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³</div>
        <div style="font-size:28px;font-weight:800;color:{r_color}">{avg_r:.2f}â˜…</div>
      </div>
      <div>
        <div style="font-size:11px;color:#888">Ğ’ÑÑŒĞ¾Ğ³Ğ¾ Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²</div>
        <div style="font-size:28px;font-weight:800;color:#fff">{total}</div>
      </div>
      <div>
        <div style="font-size:11px;color:#888">ğŸ”´ ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…</div>
        <div style="font-size:28px;font-weight:800;color:{n_color}">{neg_pct:.1f}%</div>
      </div>
      <div>
        <div style="font-size:11px;color:#888">ğŸŸ¢ ĞŸĞ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…</div>
        <div style="font-size:28px;font-weight:800;color:#4CAF50">{pos_cnt/total*100:.1f}%</div>
      </div>
    </div>""", unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### â­ Ğ Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ·Ñ–Ñ€Ğ¾Ğº")
        star_counts = df_asin['rating'].value_counts().reindex([5,4,3,2,1]).fillna(0).reset_index()
        star_counts.columns = ['Stars', 'Count']
        star_counts['Pct'] = (star_counts['Count'] / total * 100).round(1)
        star_counts['label'] = star_counts['Stars'].astype(str) + 'â˜…'
        color_map = {5:'#4CAF50',4:'#8BC34A',3:'#FFC107',2:'#FF9800',1:'#F44336'}
        fig = go.Figure(go.Bar(
            x=star_counts['Count'], y=star_counts['label'], orientation='h',
            marker_color=[color_map.get(int(s),'#888') for s in star_counts['Stars']],
            text=[f"{c:.0f} ({p:.0f}%)" for c,p in zip(star_counts['Count'], star_counts['Pct'])],
            textposition='outside'
        ))
        fig.update_layout(
            yaxis=dict(categoryorder='array', categoryarray=['1â˜…','2â˜…','3â˜…','4â˜…','5â˜…']),
            height=260, margin=dict(l=5,r=60,t=10,b=10)
        )
        st.plotly_chart(fig, width="stretch")

    with col2:
        if has_domain and 'domain' in df_asin.columns and df_asin['domain'].nunique() > 1:
            st.markdown("#### ğŸŒ Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ ĞºÑ€Ğ°Ñ—Ğ½Ğ°Ñ… Ğ´Ğ»Ñ Ñ†ÑŒĞ¾Ğ³Ğ¾ ASIN")
            dom_s = df_asin.groupby('domain').agg(
                Reviews=('rating','count'), Rating=('rating','mean'),
                Neg=('rating', lambda x: (x<=2).sum())
            ).reset_index()
            dom_s['Neg %'] = (dom_s['Neg']/dom_s['Reviews']*100).round(1)
            dom_s['Country'] = dom_s['domain'].map(lambda x: DOMAIN_LABELS.get(x, x))
            dom_s = dom_s.sort_values('Rating', ascending=True)
            colors = ['#F44336' if r<4.0 else '#FFC107' if r<4.4 else '#4CAF50' for r in dom_s['Rating']]
            fig2 = go.Figure(go.Bar(
                x=dom_s['Rating'], y=dom_s['Country'], orientation='h',
                marker_color=colors,
                text=[f"{r:.2f}â˜…  {n:.0f}% neg" for r,n in zip(dom_s['Rating'], dom_s['Neg %'])],
                textposition='outside'
            ))
            fig2.add_vline(x=4.0, line_dash="dash", line_color="orange")
            fig2.update_layout(height=260, xaxis_range=[1,5.8], margin=dict(l=5,r=80,t=10,b=10))
            st.plotly_chart(fig2, width="stretch")
        else:
            st.markdown("#### ğŸ“Š Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ Ñ‡Ğ°ÑÑƒ")
            if 'review_date' in df_asin.columns:
                df_time = df_asin.dropna(subset=['review_date']).copy()
                df_time['month'] = df_time['review_date'].dt.to_period('M').astype(str)
                monthly = df_time.groupby('month')['rating'].mean().reset_index()
                fig_t = px.line(monthly, x='month', y='rating', markers=True)
                fig_t.add_hline(y=4.0, line_dash='dash', line_color='orange')
                fig_t.update_layout(height=260, yaxis_range=[1,5])
                st.plotly_chart(fig_t, width="stretch")

    st.markdown("#### ğŸ”´ ĞÑÑ‚Ğ°Ğ½Ğ½Ñ– Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ– Ğ²Ñ–Ğ´Ğ³ÑƒĞºĞ¸ (1-2â˜…)")
    neg_df = df_asin[df_asin['rating'] <= 2].sort_values('review_date', ascending=False).head(5)
    if not neg_df.empty:
        for _, row in neg_df.iterrows():
            domain_str = f" Â· {DOMAIN_LABELS.get(row.get('domain',''), row.get('domain',''))}" if 'domain' in neg_df.columns else ""
            date_str = str(row['review_date'])[:10] if pd.notna(row.get('review_date')) else ''
            stars = 'â˜…' * int(row['rating']) + 'â˜†' * (5 - int(row['rating']))
            title = row.get('title', '') or ''
            content = (row.get('content', '') or '')[:300]
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:4px solid #F44336;border-radius:8px;padding:12px 16px;margin-bottom:8px">
              <div style="display:flex;justify-content:space-between;margin-bottom:6px">
                <span style="color:#F44336;font-weight:700">{stars}</span>
                <span style="color:#666;font-size:12px">{date_str}{domain_str}</span>
              </div>
              <div style="color:#fff;font-weight:600;margin-bottom:4px">{title}</div>
              <div style="color:#aaa;font-size:13px;line-height:1.5">{content}{"..." if len(row.get("content","") or "") > 300 else ""}</div>
            </div>""", unsafe_allow_html=True)
    else:
        st.success("ğŸ‰ ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ… Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² Ğ½ĞµĞ¼Ğ°Ñ”!")


def show_asin_links_table(df, has_domain):
    st.markdown("### ğŸ”— Ğ’ÑÑ– ASINĞ¸ â€” Ğ¾Ğ³Ğ»ÑĞ´ Ğ¿Ğ¾ ĞºÑ€Ğ°Ñ—Ğ½Ğ°Ñ…")
    st.caption(t["rev_click_hint"])

    if 'asin' not in df.columns:
        st.info("ĞĞµĞ¼Ğ°Ñ” Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾ ASINĞ¸.")
        return None, None

    if has_domain and 'domain' in df.columns:
        combos = df.groupby(['asin', 'domain']).agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
        ).reset_index()
        combos['Neg %'] = (combos['Neg'] / combos['Reviews'] * 100).round(1)
        combos['Country'] = combos['domain'].map(lambda x: DOMAIN_LABELS.get(x, f'ğŸŒ {x}'))
        combos['ğŸ”— Amazon'] = combos.apply(
            lambda r: f"https://www.amazon.{r['domain']}/dp/{r['asin']}", axis=1
        )
        combos = combos.sort_values(['Neg %'], ascending=False)
        table_df = combos[['asin', 'Country', 'Reviews', 'Rating', 'Neg %', 'domain', 'ğŸ”— Amazon']].rename(
            columns={'asin': 'ASIN', 'domain': '_domain'}
        ).reset_index(drop=True)
    else:
        asin_stats = df.groupby('asin').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
        ).reset_index()
        asin_stats['Neg %'] = (asin_stats['Neg'] / asin_stats['Reviews'] * 100).round(1)
        asin_stats['ğŸ”— Amazon'] = asin_stats['asin'].apply(lambda a: f"https://www.amazon.com/dp/{a}")
        asin_stats['_domain'] = 'com'
        table_df = asin_stats[['asin', 'Reviews', 'Rating', 'Neg %', '_domain', 'ğŸ”— Amazon']].rename(
            columns={'asin': 'ASIN'}
        ).reset_index(drop=True)

    table_df['Rating'] = table_df['Rating'].round(2)

    st.dataframe(
        table_df.drop(columns=['_domain']),
        column_config={
            "ğŸ”— Amazon": st.column_config.LinkColumn("ğŸ”— Amazon", display_text="Ğ’Ñ–Ğ´ĞºÑ€Ğ¸Ñ‚Ğ¸ â†’"),
            "Rating": st.column_config.NumberColumn("â­ Rating", format="%.2f â˜…"),
            "Neg %": st.column_config.NumberColumn("ğŸ”´ Neg %", format="%.1f%%"),
            "Reviews": st.column_config.NumberColumn("ğŸ“ Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²"),
        },
        width="stretch",
        hide_index=True,
        height=min(400, 45 + len(table_df) * 35),
    )

    asin_list = table_df['ASIN'].unique().tolist()
    st.caption(t["rev_select_hint"])
    sel_col, _ = st.columns([2, 3])
    with sel_col:
        chosen = st.selectbox(t["rev_goto_asin"], [t["rev_not_selected"]] + asin_list,
                              key="asin_table_jump")
    not_selected_values = {"â€” Ğ½Ğµ Ğ²Ğ¸Ğ±Ñ€Ğ°Ğ½Ğ¾ â€”", "â€” not selected â€”", "â€” Ğ½Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ¾ â€”"}
    if chosen and chosen not in not_selected_values:
        matched = table_df[table_df['ASIN'] == chosen]
        if not matched.empty:
            row = matched.iloc[0]
            return chosen, row['_domain']

    return None, None


def show_reviews(t):
    df_all = load_reviews()
    if df_all.empty:
        st.warning("âš ï¸ ĞĞµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾ Ğ²Ñ–Ğ´Ğ³ÑƒĞºĞ¸. ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ñ‚Ğµ ETL-ÑĞºÑ€Ğ¸Ğ¿Ñ‚ (Apify â†’ Postgres).")
        return

    has_domain = 'domain' in df_all.columns

    st.sidebar.markdown("---")
    st.sidebar.subheader(t["rev_filters"])

    selected_domains = []
    if has_domain:
        all_domains = sorted(df_all['domain'].dropna().unique().tolist())
        domain_display_list = [DOMAIN_LABELS.get(d, f'ğŸŒ {d}') for d in all_domains]
        display_to_code = {DOMAIN_LABELS.get(d, f'ğŸŒ {d}'): d for d in all_domains}
        sel_domain_display = st.sidebar.multiselect(
            t["rev_country_filter"], domain_display_list, default=[], key="rev_domain"
        )
        selected_domains = [display_to_code[d] for d in sel_domain_display if d in display_to_code]

    jumped_asin = st.session_state.pop('rev_asin_jump', None)

    df_for_asin = df_all.copy()
    if selected_domains:
        df_for_asin = df_for_asin[df_for_asin['domain'].isin(selected_domains)]
    asins = sorted(df_for_asin['asin'].dropna().unique().tolist()) if 'asin' in df_for_asin.columns else []
    asin_options = ['ğŸŒ Ğ’ÑÑ– ASINĞ¸'] + asins

    default_asin_idx = 0
    if jumped_asin and jumped_asin in asins:
        default_asin_idx = asin_options.index(jumped_asin)

    sel_raw = st.sidebar.selectbox("ğŸ“¦ ASIN:", asin_options, index=default_asin_idx, key="rev_asin")
    selected_asin = None if sel_raw == 'ğŸŒ Ğ’ÑÑ– ASINĞ¸' else sel_raw

    star_filter = st.sidebar.multiselect(t["rev_star_filter"], [5, 4, 3, 2, 1], default=[], key="rev_stars")

    if selected_asin and has_domain:
        st.sidebar.markdown("---")
        st.sidebar.markdown("**ğŸ”— Ğ’Ñ–Ğ´ĞºÑ€Ğ¸Ñ‚Ğ¸ Ğ½Ğ° Amazon:**")
        asin_domains = sorted(df_all[df_all['asin'] == selected_asin]['domain'].dropna().unique().tolist())
        for dom in asin_domains:
            url = make_amazon_url(dom, selected_asin)
            flag = DOMAIN_LABELS.get(dom, 'ğŸŒ').split(' ')[0]
            label = DOMAIN_LABELS.get(dom, dom).split('(')[0].strip()
            st.sidebar.markdown(f"[{flag} {label}]({url})")
        st.sidebar.markdown("---")
        if st.sidebar.button(t["rev_back"], width="stretch"):
            st.session_state['rev_asin_jump'] = None
            st.rerun()

    df = df_all.copy()
    if selected_domains:
        df = df[df['domain'].isin(selected_domains)]
    if selected_asin:
        df = df[df['asin'] == selected_asin]
    if star_filter:
        df = df[df['rating'].isin(star_filter)]

    if df.empty:
        st.warning("ĞĞµĞ¼Ğ°Ñ” Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² Ğ·Ğ° Ñ†Ğ¸Ğ¼Ğ¸ Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼Ğ¸.")
        return

    asin_label    = selected_asin if selected_asin else t["all_asins"]
    country_label = ", ".join([DOMAIN_LABELS.get(d, d) for d in selected_domains]) if selected_domains else t["all_countries"]

    if selected_asin:
        first_domain = df['domain'].dropna().iloc[0] if has_domain and not df.empty else 'com'
        amazon_url = make_amazon_url(first_domain, selected_asin)
        st.markdown(
            f"### {t['reviews_title']} â€” "
            f"<a href='{amazon_url}' target='_blank' style='color:#5B9BD5'>{selected_asin} ğŸ”—</a>"
            f" | ğŸŒ {country_label}",
            unsafe_allow_html=True
        )
    else:
        st.markdown(f"### {t['reviews_title']} â€” {asin_label} | ğŸŒ {country_label}")

    total_revs   = len(df)
    avg_rating   = df['rating'].mean()
    verified_pct = df['is_verified'].mean() * 100 if 'is_verified' in df.columns and total_revs > 0 else 0
    neg_count    = int((df['rating'] <= 2).sum())
    pos_count    = int((df['rating'] >= 4).sum())
    total_asins = df['asin'].nunique() if 'asin' in df.columns else 0
    total_asins_db = df_all['asin'].nunique() if 'asin' in df_all.columns else 0

    c1, c2, c3, c4, c5, c6 = st.columns(6)
    c1.metric(t["total_reviews"],     f"{total_revs:,}")
    c2.metric(t["rev_asins_in_filter"],  f"{total_asins:,}",
              delta=f"Ğ· {total_asins_db} Ğ² Ğ±Ğ°Ğ·Ñ–" if total_asins != total_asins_db else None,
              delta_color="off")
    c3.metric(t["avg_review_rating"], f"{avg_rating:.2f} â­")
    c4.metric(t["verified_pct"],      f"{verified_pct:.1f}%")
    c5.metric("ğŸ”´ ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ… (1-2â˜…)", f"{neg_count:,}")
    c6.metric("ğŸŸ¢ ĞŸĞ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ… (4-5â˜…)", f"{pos_count:,}")

    st.markdown("---")
    show_global_insights(df_all if selected_asin is None else df, has_domain)
    st.markdown("---")

    if selected_asin is not None:
        show_single_asin_detail(df, selected_asin, has_domain)
        st.markdown("---")

    if has_domain and selected_asin is None:
        st.markdown(f"### {t['rev_country_analysis']}")

        domain_stats = df.groupby('domain').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
            Pos=('rating', lambda x: (x >= 4).sum()),
        ).reset_index()
        domain_stats['Neg %'] = (domain_stats['Neg'] / domain_stats['Reviews'] * 100).round(1)
        domain_stats['Pos %'] = (domain_stats['Pos'] / domain_stats['Reviews'] * 100).round(1)
        domain_stats['Country'] = domain_stats['domain'].map(lambda x: DOMAIN_LABELS.get(x, f'ğŸŒ {x}'))

        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown(f"#### {t['rev_rating_by_country']}")
            ds_sort = domain_stats.sort_values('Rating', ascending=True)
            colors = ['#F44336' if r < 4.0 else '#FFC107' if r < 4.4 else '#4CAF50' for r in ds_sort['Rating']]
            fig = go.Figure(go.Bar(
                x=ds_sort['Rating'], y=ds_sort['Country'], orientation='h',
                marker_color=colors,
                text=[f"{v:.2f}â˜…" for v in ds_sort['Rating']], textposition='outside'
            ))
            fig.add_vline(x=4.0, line_dash="dash", line_color="orange", annotation_text="4.0")
            fig.update_layout(height=max(280, len(ds_sort) * 50), xaxis_range=[1, 5.5],
                              margin=dict(l=10, r=60, t=20, b=20))
            st.plotly_chart(fig, width="stretch")

        with col2:
            st.markdown(f"#### {t['rev_neg_by_country']}")
            ds_neg = domain_stats.sort_values('Neg %', ascending=False)
            neg_colors = ['#F44336' if v > 20 else '#FFC107' if v > 10 else '#4CAF50' for v in ds_neg['Neg %']]
            fig2 = go.Figure(go.Bar(
                x=ds_neg['Neg %'], y=ds_neg['Country'], orientation='h',
                marker_color=neg_colors,
                text=[f"{v:.1f}%" for v in ds_neg['Neg %']], textposition='outside'
            ))
            fig2.update_layout(height=max(280, len(ds_neg) * 50), margin=dict(l=10, r=60, t=20, b=20))
            st.plotly_chart(fig2, width="stretch")

        with col3:
            st.markdown(f"#### {t['rev_count_by_country']}")
            fig3 = px.pie(domain_stats, values='Reviews', names='Country', hole=0.4,
                          color_discrete_sequence=px.colors.qualitative.Set3)
            fig3.update_layout(height=max(280, len(domain_stats) * 50))
            st.plotly_chart(fig3, width="stretch")

        st.markdown(f"#### {t['rev_table_by_country']}")
        disp = domain_stats[['Country', 'Reviews', 'Rating', 'Neg %', 'Pos %']].sort_values('Rating', ascending=False)
        st.dataframe(
            disp.style
                .format({'Rating': '{:.2f}', 'Neg %': '{:.1f}%', 'Pos %': '{:.1f}%'})
                .background_gradient(subset=['Rating'], cmap='RdYlGn')
                .background_gradient(subset=['Neg %'], cmap='RdYlGn_r'),
            width="stretch"
        )

        if 'asin' in df.columns and df['domain'].nunique() > 1:
            st.markdown("---")
            st.markdown(t["rev_heatmap"])
            st.caption(t["rev_heatmap_hint"])

            pivot = df.groupby(['asin', 'domain'])['rating'].mean().reset_index()
            pivot_table = pivot.pivot(index='asin', columns='domain', values='rating')
            pivot_table.columns = [DOMAIN_LABELS.get(c, f'ğŸŒ {c}') for c in pivot_table.columns]

            fig_heat = go.Figure(data=go.Heatmap(
                z=pivot_table.values,
                x=list(pivot_table.columns),
                y=list(pivot_table.index),
                colorscale='RdYlGn',
                zmin=1, zmax=5,
                text=[[f"{v:.2f}" if not pd.isna(v) else "â€”" for v in row] for row in pivot_table.values],
                texttemplate="%{text}",
                colorbar=dict(title="â˜… Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³"),
            ))
            fig_heat.update_layout(
                height=max(350, len(pivot_table) * 45 + 100),
                xaxis_title="ĞšÑ€Ğ°Ñ—Ğ½Ğ°", yaxis_title="ASIN",
                margin=dict(l=20, r=20, t=30, b=20)
            )
            st.plotly_chart(fig_heat, width="stretch")
            st.caption("ğŸŸ¢ â‰¥4.4â˜… Ğ²Ñ–Ğ´Ğ¼Ñ–Ğ½Ğ½Ğ¾ Â· ğŸŸ¡ 4.0â€“4.4â˜… Ğ½Ğ¾Ñ€Ğ¼Ğ° Â· ğŸ”´ <4.0â˜… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°")

        st.markdown("---")

    if selected_asin is None:
        clicked_asin, clicked_domain = show_asin_links_table(df, has_domain)
        if clicked_asin:
            st.session_state['rev_asin_jump'] = clicked_asin
            st.rerun()
        st.markdown("---")

    if selected_asin is None and 'asin' in df.columns:
        st.markdown(t["rev_asin_compare"])

        asin_stats = df.groupby('asin').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
            Pos=('rating', lambda x: (x >= 4).sum()),
        ).reset_index()
        asin_stats.columns = ['ASIN', 'Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²', 'Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³', 'ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…', 'ĞŸĞ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…']
        asin_stats['Neg %'] = (asin_stats['ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…'] / asin_stats['Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²'] * 100).round(1)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### â­ Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ ASINĞ°Ñ…")
            asin_sort = asin_stats.sort_values('Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³', ascending=True)
            colors = ['#F44336' if r < 4.0 else '#FFC107' if r < 4.4 else '#4CAF50' for r in asin_sort['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³']]
            fig = go.Figure(go.Bar(
                x=asin_sort['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³'], y=asin_sort['ASIN'], orientation='h',
                marker_color=colors,
                text=[f"{v:.2f}â˜…" for v in asin_sort['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³']], textposition='outside'
            ))
            fig.add_vline(x=4.0, line_dash="dash", line_color="orange", annotation_text="ĞŸĞ¾Ñ€Ñ–Ğ³ 4.0")
            fig.update_layout(height=max(300, len(asin_sort) * 38), xaxis_range=[1, 5.5])
            st.plotly_chart(fig, width="stretch")

        with col2:
            st.markdown("#### ğŸ”´ % ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ… Ğ¿Ğ¾ ASINĞ°Ñ…")
            asin_neg = asin_stats.sort_values('Neg %', ascending=False)
            neg_colors = ['#F44336' if v > 20 else '#FFC107' if v > 10 else '#4CAF50' for v in asin_neg['Neg %']]
            fig2 = go.Figure(go.Bar(
                x=asin_neg['Neg %'], y=asin_neg['ASIN'], orientation='h',
                marker_color=neg_colors,
                text=[f"{v:.1f}%" for v in asin_neg['Neg %']], textposition='outside'
            ))
            fig2.update_layout(height=max(300, len(asin_neg) * 38))
            st.plotly_chart(fig2, width="stretch")

        st.markdown("#### ğŸ“‹ Ğ—Ğ²ĞµĞ´ĞµĞ½Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ğ¿Ğ¾ ASINĞ°Ñ…")
        st.dataframe(
            asin_stats.sort_values('Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³').style
                .format({'Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³': '{:.2f}', 'Neg %': '{:.1f}%'})
                .background_gradient(subset=['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³'], cmap='RdYlGn')
                .background_gradient(subset=['Neg %'], cmap='RdYlGn_r'),
            width="stretch"
        )

        if 'product_attributes' in df.columns:
            st.markdown("---")
            st.markdown("### ğŸ¨ Ğ¯ĞºÑ– Ğ²Ğ°Ñ€Ñ–Ğ°Ğ½Ñ‚Ğ¸ (Size / Color) Ğ·Ğ±Ğ¸Ñ€Ğ°ÑÑ‚ÑŒ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²?")

            df_attr = df.copy()
            df_attr['product_attributes'] = df_attr['product_attributes'].fillna('').astype(str)

            def parse_attr(s):
                size, color = None, None
                for part in s.split(','):
                    part = part.strip()
                    if part.lower().startswith('size:'):
                        size = part.split(':', 1)[1].strip()
                    elif part.lower().startswith('color:'):
                        color = part.split(':', 1)[1].strip()
                return pd.Series({'Size': size or 'N/A', 'Color': color or 'N/A'})

            parsed = df_attr['product_attributes'].apply(parse_attr)
            df_attr = pd.concat([df_attr.reset_index(drop=True), parsed], axis=1)

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ğŸ“ Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ Size")
                size_stats = df_attr[df_attr['Size'] != 'N/A'].groupby('Size').agg(
                    Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²=('rating', 'count'),
                    Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³=('rating', 'mean'),
                    Neg=('rating', lambda x: (x <= 2).sum()),
                ).reset_index()
                size_stats['Neg %'] = (size_stats['Neg'] / size_stats['Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²'] * 100).round(1)
                size_stats = size_stats[size_stats['Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²'] >= 3].sort_values('Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³', ascending=True)
                if not size_stats.empty:
                    colors_s = ['#F44336' if r < 3.5 else '#FFC107' if r < 4.2 else '#4CAF50' for r in size_stats['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³']]
                    fig_s = go.Figure(go.Bar(
                        x=size_stats['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³'], y=size_stats['Size'], orientation='h',
                        marker_color=colors_s,
                        text=[f"{r:.2f}â˜… ({n:.0f}% neg)" for r, n in zip(size_stats['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³'], size_stats['Neg %'])],
                        textposition='outside',
                    ))
                    fig_s.add_vline(x=4.0, line_dash="dash", line_color="orange")
                    fig_s.update_layout(height=max(280, len(size_stats) * 40), xaxis_range=[1, 5.8])
                    st.plotly_chart(fig_s, width="stretch")
                else:
                    st.info("ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ½ÑŒĞ¾ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ¿Ğ¾ Ñ€Ğ¾Ğ·Ğ¼Ñ–Ñ€Ğ°Ñ…")

            with col2:
                st.markdown("#### ğŸ¨ Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ Color")
                color_stats = df_attr[df_attr['Color'] != 'N/A'].groupby('Color').agg(
                    Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²=('rating', 'count'),
                    Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³=('rating', 'mean'),
                    Neg=('rating', lambda x: (x <= 2).sum()),
                ).reset_index()
                color_stats['Neg %'] = (color_stats['Neg'] / color_stats['Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²'] * 100).round(1)
                color_stats = color_stats[color_stats['Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²'] >= 3].sort_values('Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³', ascending=True)
                if not color_stats.empty:
                    colors_c = ['#F44336' if r < 3.5 else '#FFC107' if r < 4.2 else '#4CAF50' for r in color_stats['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³']]
                    fig_c = go.Figure(go.Bar(
                        x=color_stats['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³'], y=color_stats['Color'], orientation='h',
                        marker_color=colors_c,
                        text=[f"{r:.2f}â˜… ({n:.0f}% neg)" for r, n in zip(color_stats['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³'], color_stats['Neg %'])],
                        textposition='outside',
                    ))
                    fig_c.add_vline(x=4.0, line_dash="dash", line_color="orange")
                    fig_c.update_layout(height=max(280, len(color_stats) * 40), xaxis_range=[1, 5.8])
                    st.plotly_chart(fig_c, width="stretch")
                else:
                    st.info("ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ½ÑŒĞ¾ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ¿Ğ¾ ĞºĞ¾Ğ»ÑŒĞ¾Ñ€Ğ°Ñ…")

            st.markdown("#### âš ï¸ Ğ¢Ğ¾Ğ¿ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ğ¸Ñ… Ğ²Ğ°Ñ€Ñ–Ğ°Ğ½Ñ‚Ñ–Ğ² (Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ < 4.0, Ğ¼Ñ–Ğ½. 3 Ğ²Ñ–Ğ´Ğ³ÑƒĞºĞ¸)")
            df_v = df_attr[df_attr['Size'] != 'N/A'].copy()
            group_cols = ['asin', 'Size', 'Color'] if 'asin' in df_v.columns else ['Size', 'Color']
            var_group = df_v.groupby(group_cols).agg(
                Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²=('rating', 'count'),
                Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³=('rating', 'mean'),
                Neg=('rating', lambda x: (x <= 2).sum()),
            ).reset_index()
            var_group['Neg %'] = (var_group['Neg'] / var_group['Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²'] * 100).round(1)
            problem = var_group[(var_group['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³'] < 4.0) & (var_group['Ğ’Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ²'] >= 3)].sort_values('Neg %', ascending=False).head(20)
            if not problem.empty:
                st.dataframe(
                    problem.style
                        .format({'Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³': '{:.2f}', 'Neg %': '{:.1f}%'})
                        .background_gradient(subset=['Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³'], cmap='RdYlGn')
                        .background_gradient(subset=['Neg %'], cmap='RdYlGn_r'),
                    width="stretch"
                )
            else:
                st.success("ğŸ‰ Ğ’ÑÑ– Ğ²Ğ°Ñ€Ñ–Ğ°Ğ½Ñ‚Ğ¸ Ğ¼Ğ°ÑÑ‚ÑŒ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ â‰¥ 4.0")

        st.markdown("---")
        st.markdown(t["rev_star_dist"])

    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"#### {t['star_dist']}")
        star_counts = df['rating'].value_counts().reindex([5, 4, 3, 2, 1]).fillna(0).reset_index()
        star_counts.columns = ['Ğ—Ñ–Ñ€ĞºĞ¸', 'ĞšÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ']
        star_counts['label'] = star_counts['Ğ—Ñ–Ñ€ĞºĞ¸'].astype(str) + 'â˜…'
        color_map = {5: '#4CAF50', 4: '#8BC34A', 3: '#FFC107', 2: '#FF9800', 1: '#F44336'}
        fig_stars = go.Figure(go.Bar(
            x=star_counts['ĞšÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ'], y=star_counts['label'], orientation='h',
            marker_color=[color_map.get(int(s), '#888') for s in star_counts['Ğ—Ñ–Ñ€ĞºĞ¸']],
            text=star_counts['ĞšÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ'], textposition='outside'
        ))
        fig_stars.update_layout(
            yaxis=dict(categoryorder='array', categoryarray=['1â˜…', '2â˜…', '3â˜…', '4â˜…', '5â˜…']),
            height=300, margin=dict(l=10, r=40, t=20, b=20)
        )
        st.plotly_chart(fig_stars, width="stretch")

    with col2:
        st.markdown(f"#### {t['worst_asin']}")
        bad = df_all[df_all['rating'] <= 2]
        if selected_domains and has_domain:
            bad = bad[bad['domain'].isin(selected_domains)]
        if 'asin' in bad.columns and not bad.empty:
            bad_asins = bad['asin'].value_counts().head(8).reset_index()
            bad_asins.columns = ['ASIN', 'ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…']
            fig_bad = px.bar(bad_asins, x='ASIN', y='ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…', text='ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…',
                             color='ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ…', color_continuous_scale='Reds')
            fig_bad.update_layout(height=300, showlegend=False)
            st.plotly_chart(fig_bad, width="stretch")
        else:
            st.success("ğŸ‰ ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ… Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾!")

    insights_reviews(df, asin=selected_asin)

    st.markdown("---")
    st.markdown(t["rev_texts"])
    st.caption(t["rev_sort_hint"])

    df_table = balanced_reviews(df, max_per_star=100).sort_values('rating', ascending=True)
    display_cols   = ['review_date', 'asin', 'domain', 'rating', 'title', 'content', 'product_attributes', 'author', 'is_verified']
    available_cols = [c for c in display_cols if c in df_table.columns]

    st.dataframe(df_table[available_cols], width="stretch", height=450)

    star_summary = df_table['rating'].value_counts().sort_index(ascending=False)
    summary_str  = " | ".join([f"{s}â˜…: {c}" for s, c in star_summary.items()])
    st.caption(f"ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾ {len(df_table)} Ğ· {len(df)} Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² Â· {summary_str}")

    col1, col2 = st.columns(2)
    with col1:
        st.download_button("ğŸ“¥ Ğ’Ğ¸Ğ±Ñ–Ñ€ĞºĞ° balanced (CSV)",
            df_table[available_cols].to_csv(index=False).encode('utf-8'),
            f"reviews_balanced_{asin_label}.csv", "text/csv")
    with col2:
        st.download_button("ğŸ“¥ Ğ’ÑÑ– Ğ²Ñ–Ğ´Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ– (CSV)",
            df[available_cols].to_csv(index=False).encode('utf-8'),
            f"reviews_full_{asin_label}.csv", "text/csv")


# ============================================
# OTHER REPORT FUNCTIONS
# ============================================

def show_overview(df_filtered, t, selected_date):
    st.markdown(f"### {t['ov_title']}")
    st.caption(f"Data snapshot: {selected_date}")
    col1,col2,col3,col4 = st.columns(4)
    with col1: st.metric(t["total_sku"], len(df_filtered))
    with col2: st.metric(t["total_avail"], f"{int(df_filtered['Available'].sum()):,}")
    with col3: st.metric(t["total_value"], f"${df_filtered['Stock Value'].sum():,.0f}")
    with col4: st.metric(t["velocity_30"], f"{int(df_filtered['Velocity'].sum()*30):,} units")
    st.markdown("---")
    col1,col2,col3,col4 = st.columns(4)
    btns = [
        (col1, f"#### {t['settlements_title']}", "Payouts, Net Profit, Fees", "ğŸ¦ View Finance â†’","btn_s","ğŸ¦ Settlements (Payouts)"),
        (col2, "#### ğŸ“ˆ Sales & Traffic","Sessions, Conversions, Buy Box","ğŸ“ˆ View Traffic â†’","btn_st","ğŸ“ˆ Sales & Traffic"),
        (col3, "#### ğŸ›’ Orders Analytics","Sales Trends, Top Products","ğŸ“Š View Orders â†’","btn_o","ğŸ›’ Orders Analytics"),
        (col4, "#### ğŸ“¦ Returns Analytics","Return rates, Problem SKUs","ğŸ“¦ View Returns â†’","btn_r","ğŸ“¦ Returns Analytics"),
    ]
    for c,hdr,sub,btn_lbl,key,dest in btns:
        with c:
            with st.container(border=True):
                st.markdown(hdr); st.markdown(sub)
                if st.button(btn_lbl, key=key, width="stretch", type="primary"):
                    st.session_state.report_choice = dest; st.rerun()
    st.markdown("")
    col1,col2,col3,col4 = st.columns(4)
    btns2 = [
        (col1,"#### ğŸ’° Inventory Value","Money map, Pricing","ğŸ’° View Inventory â†’","btn_f","ğŸ’° Inventory Value (CFO)"),
        (col2,"#### ğŸ§  AI Forecast","Sold-out predictions","ğŸ§  View AI Forecast â†’","btn_a","ğŸ§  AI Forecast"),
        (col3,"#### ğŸ¢ Inventory Health","Aging analysis","ğŸ¢ View Health â†’","btn_h","ğŸ¢ Inventory Health (Aging)"),
        (col4,"#### â­ Amazon Reviews","Ratings, problem ASINs","â­ View Reviews â†’","btn_rev","â­ Amazon Reviews"),
    ]
    for c,hdr,sub,btn_lbl,key,dest in btns2:
        with c:
            with st.container(border=True):
                st.markdown(hdr); st.markdown(sub)
                if st.button(btn_lbl, key=key, width="stretch", type="primary"):
                    st.session_state.report_choice = dest; st.rerun()
    st.markdown("---")
    st.markdown(t["ov_top_sku"])
    if not df_filtered.empty:
        df_top = df_filtered.nlargest(15,'Available')
        fig = px.bar(df_top, x='Available', y='SKU', orientation='h',
                     text='Available', color='Available', color_continuous_scale='Blues')
        fig.update_layout(yaxis={'categoryorder':'total ascending'}, height=400)
        st.plotly_chart(fig, width="stretch")
    show_overview_insights(df_filtered)


def show_sales_traffic(t):
    df_st = load_sales_traffic()
    if df_st.empty:
        st.warning("âš ï¸ No Sales & Traffic data found."); return
    st.sidebar.markdown("---"); st.sidebar.subheader(t["st_filters"])
    min_date = df_st['report_date'].min().date()
    max_date = df_st['report_date'].max().date()
    date_range = st.sidebar.date_input(t["st_date_range"],
        value=(max(min_date, max_date-dt.timedelta(days=14)), max_date),
        min_value=min_date, max_value=max_date, key="st_date_range")
    if len(date_range)==2:
        mask = (df_st['report_date'].dt.date>=date_range[0])&(df_st['report_date'].dt.date<=date_range[1])
        df_filtered = df_st[mask]
    else:
        df_filtered = df_st
    if df_filtered.empty:
        st.warning("No data for selected period"); return
    st.markdown(f"### {t['sales_traffic_title']}")
    ts = int(df_filtered['sessions'].sum()); tpv = int(df_filtered['page_views'].sum())
    tu = int(df_filtered['units_ordered'].sum()); tr = df_filtered['ordered_product_sales'].sum()
    ac = tu/ts*100 if ts>0 else 0; ab = df_filtered['buy_box_percentage'].mean()
    c1,c2,c3,c4,c5,c6 = st.columns(6)
    c1.metric(t["st_sessions"],f"{ts:,}"); c2.metric(t["st_page_views"],f"{tpv:,}")
    c3.metric(t["st_units"],f"{tu:,}"); c4.metric(t["st_revenue"],f"${tr:,.2f}")
    c5.metric(t["st_conversion"],f"{ac:.2f}%"); c6.metric(t["st_buy_box"],f"{ab:.1f}%")
    st.markdown("---"); st.markdown(t["st_daily_trends"])
    daily = df_filtered.groupby(df_filtered['report_date'].dt.date).agg(
        {'sessions':'sum','page_views':'sum','units_ordered':'sum','ordered_product_sales':'sum'}).reset_index()
    daily.columns = ['Date','Sessions','Page Views','Units','Revenue']
    daily['Conversion %'] = (daily['Units']/daily['Sessions']*100).fillna(0)
    col1,col2 = st.columns(2)
    with col1:
        st.markdown(t["st_sessions_views"])
        fig = go.Figure()
        fig.add_trace(go.Bar(x=daily['Date'],y=daily['Sessions'],name='Sessions',marker_color='#4472C4'))
        fig.add_trace(go.Scatter(x=daily['Date'],y=daily['Page Views'],name='Page Views',mode='lines+markers',line=dict(color='#ED7D31',width=2),yaxis='y2'))
        fig.update_layout(yaxis=dict(title='Sessions'),yaxis2=dict(title='Page Views',overlaying='y',side='right'),height=380,legend=dict(orientation='h',y=1.12))
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.markdown(t["st_revenue_units"])
        fig = go.Figure()
        fig.add_trace(go.Bar(x=daily['Date'],y=daily['Revenue'],name='Revenue $',marker_color='#70AD47'))
        fig.add_trace(go.Scatter(x=daily['Date'],y=daily['Units'],name='Units',mode='lines+markers',line=dict(color='#FFC000',width=2),yaxis='y2'))
        fig.update_layout(yaxis=dict(title='Revenue $'),yaxis2=dict(title='Units',overlaying='y',side='right'),height=380,legend=dict(orientation='h',y=1.12))
        st.plotly_chart(fig, width="stretch")
    fig_conv = go.Figure(go.Scatter(x=daily['Date'],y=daily['Conversion %'],mode='lines+markers+text',
        text=[f"{v:.1f}%" for v in daily['Conversion %']],textposition='top center',line=dict(color='#5B9BD5',width=3),marker=dict(size=8)))
    fig_conv.update_layout(height=300,yaxis_title='Conversion %')
    st.plotly_chart(fig_conv, width="stretch")
    st.markdown("---"); st.markdown(t["st_top_asins"])
    asin_col = 'child_asin' if 'child_asin' in df_filtered.columns else df_filtered.columns[0]
    as_ = df_filtered.groupby(asin_col).agg({'sessions':'sum','page_views':'sum','units_ordered':'sum','ordered_product_sales':'sum','buy_box_percentage':'mean'}).reset_index()
    as_.columns=['ASIN','Sessions','Page Views','Units','Revenue','Buy Box %']
    as_['Conv %'] = (as_['Units']/as_['Sessions']*100).fillna(0)
    col1,col2 = st.columns(2)
    with col1:
        st.markdown(t["st_top_revenue"])
        fig = px.bar(as_.nlargest(15,'Revenue'),x='Revenue',y='ASIN',orientation='h',text='Revenue',color='Revenue',color_continuous_scale='Greens')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450); fig.update_traces(texttemplate='$%{text:,.0f}',textposition='outside')
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.markdown(t["st_top_sessions"])
        fig = px.bar(as_.nlargest(15,'Sessions'),x='Sessions',y='ASIN',orientation='h',text='Sessions',color='Sessions',color_continuous_scale='Blues')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450)
        st.plotly_chart(fig, width="stretch")
    st.markdown("---"); st.markdown(t["st_full_data"])
    st.dataframe(as_.sort_values('Revenue',ascending=False).style.format({'Revenue':'${:,.2f}','Conv %':'{:.2f}%','Buy Box %':'{:.1f}%'}),width="stretch",height=500)
    csv = as_.to_csv(index=False).encode('utf-8')
    st.download_button(t["st_download"], csv, "sales_traffic.csv","text/csv")
    insights_sales_traffic(df_filtered, as_)


def show_settlements(t):
    df_settlements = load_settlements()
    if df_settlements.empty:
        st.warning("âš ï¸ No settlement data found."); return
    st.sidebar.markdown("---"); st.sidebar.subheader("ğŸ’° Settlement Filters")
    currencies = ['All'] + sorted(df_settlements['Currency'].dropna().unique().tolist())
    sel_cur = st.sidebar.selectbox(t["currency_select"], currencies, index=1 if "USD" in currencies else 0)
    min_date = df_settlements['Posted Date'].min().date()
    max_date = df_settlements['Posted Date'].max().date()
    date_range = st.sidebar.date_input("ğŸ“… Transaction Date:",value=(max_date-dt.timedelta(days=30),max_date),min_value=min_date,max_value=max_date)
    df_f = df_settlements.copy()
    if sel_cur != 'All': df_f = df_f[df_f['Currency']==sel_cur]
    if len(date_range)==2:
        df_f = df_f[(df_f['Posted Date'].dt.date>=date_range[0])&(df_f['Posted Date'].dt.date<=date_range[1])]
    if df_f.empty:
        st.warning("No data for selected filters"); return
    st.markdown(f"### {t['settlements_title']}")
    net = df_f['Amount'].sum()
    gross = df_f[(df_f['Transaction Type']=='Order')&(df_f['Amount']>0)]['Amount'].sum()
    refunds = df_f[df_f['Transaction Type']=='Refund']['Amount'].sum()
    fees = df_f[(df_f['Amount']<0)&(df_f['Transaction Type']!='Refund')]['Amount'].sum()
    sym = "$" if sel_cur in ['USD','CAD','All'] else ""
    c1,c2,c3,c4 = st.columns(4)
    c1.metric(t['net_payout'],f"{sym}{net:,.2f}"); c2.metric(t['gross_sales'],f"{sym}{gross:,.2f}")
    c3.metric(t['total_refunds'],f"{sym}{refunds:,.2f}"); c4.metric(t['total_fees'],f"{sym}{fees:,.2f}")
    st.markdown("---")
    col1,col2 = st.columns([2,1])
    with col1:
        st.subheader(t['chart_payout_trend'])
        dt_ = df_f.groupby(df_f['Posted Date'].dt.date)['Amount'].sum().reset_index()
        dt_.columns=['Date','Net Amount']
        fig = go.Figure(go.Bar(x=dt_['Date'],y=dt_['Net Amount'],marker_color=dt_['Net Amount'].apply(lambda x:'green' if x>=0 else 'red')))
        fig.update_layout(height=400,yaxis_title=f"Net Amount ({sel_cur})")
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.subheader(t['chart_fee_breakdown'])
        df_costs = df_f[df_f['Amount']<0]
        if not df_costs.empty:
            cb = df_costs.groupby('Transaction Type')['Amount'].sum().abs().reset_index()
            fig = px.pie(cb,values='Amount',names='Transaction Type',hole=0.4)
            fig.update_layout(height=400)
            st.plotly_chart(fig, width="stretch")
        else: st.info("No costs in selected period")
    disp = ['Posted Date','Transaction Type','Order ID','Amount','Currency','Description']
    st.dataframe(df_f[[c for c in disp if c in df_f.columns]].sort_values('Posted Date',ascending=False).head(100),width="stretch")
    insights_settlements(df_f)


def show_returns(t=None):
    if t is None: t = translations.get("UA", {})
    df_ret_raw, df_orders = load_returns()
    if df_ret_raw.empty:
        st.warning("âš ï¸ No returns data."); return
    df_r = df_ret_raw.copy()
    df_r['Return Date'] = pd.to_datetime(df_r['Return Date'], errors='coerce')
    if 'Price' not in df_r.columns and not df_orders.empty:
        try:
            for col in ['Item Price','item-price','item_price','price','Price']:
                if col in df_orders.columns:
                    df_orders[col] = pd.to_numeric(df_orders[col],errors='coerce')
                    df_r['Price'] = df_r['SKU'].map(df_orders.groupby('SKU')[col].mean()).fillna(0)
                    break
        except: df_r['Price'] = 0
    elif 'Price' not in df_r.columns: df_r['Price'] = 0
    df_r['Price']        = pd.to_numeric(df_r['Price'],errors='coerce').fillna(0)
    df_r['Quantity']     = pd.to_numeric(df_r['Quantity'],errors='coerce').fillna(1)
    df_r['Return Value'] = df_r['Price'] * df_r['Quantity']
    st.sidebar.markdown("---"); st.sidebar.subheader(t["ret_filters"])
    min_date = df_r['Return Date'].min().date(); max_date = df_r['Return Date'].max().date()
    date_range = st.sidebar.date_input(t["ret_date"],value=(max_date-dt.timedelta(days=30),max_date),min_value=min_date,max_value=max_date)
    sel_store = 'All'
    if 'Store Name' in df_r.columns:
        stores = ['All'] + sorted(df_r['Store Name'].dropna().unique().tolist())
        sel_store = st.sidebar.selectbox("ğŸª Store:", stores)
    df_f = df_r[(df_r['Return Date'].dt.date>=date_range[0])&(df_r['Return Date'].dt.date<=date_range[1])] if len(date_range)==2 else df_r
    if sel_store != 'All': df_f = df_f[df_f['Store Name']==sel_store]
    st.markdown(t["ret_title"])
    rr = 0
    try:
        if not df_orders.empty:
            for col in ['Order ID','order-id','order_id','OrderID']:
                if col in df_orders.columns:
                    rr = df_f['Order ID'].nunique()/df_orders[col].nunique()*100 if df_orders[col].nunique()>0 else 0
                    break
    except: pass
    c1,c2,c3,c4,c5 = st.columns(5)
    c1.metric(t["ret_total"],f"{len(df_f):,}"); c2.metric(t["ret_unique_sku"],df_f['SKU'].nunique())
    c3.metric(t["ret_rate"],f"{rr:.1f}%"); c4.metric(t["ret_value"],f"${df_f['Return Value'].sum():,.2f}")
    c5.metric(t["ret_avg"],f"${df_f['Return Value'].mean():.2f}")
    st.markdown("---")
    col1,col2,col3 = st.columns(3)
    with col1:
        st.markdown(t["ret_by_sku"])
        tv = df_f.groupby('SKU')['Return Value'].sum().nlargest(10).reset_index()
        fig = px.bar(tv,x='Return Value',y='SKU',orientation='h',text='Return Value',color='Return Value',color_continuous_scale='Reds')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=350); fig.update_traces(texttemplate='$%{text:,.0f}',textposition='outside')
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.markdown(t["ret_daily"])
        dv = df_f.groupby(df_f['Return Date'].dt.date)['Return Value'].sum().reset_index(); dv.columns=['Date','Value']
        fig = px.area(dv,x='Date',y='Value',line_shape='spline',color_discrete_sequence=['#FF6B6B'])
        fig.update_layout(height=350); st.plotly_chart(fig, width="stretch")
    with col3:
        if 'Reason' in df_f.columns:
            st.markdown(t["ret_by_reason"])
            rv = df_f.groupby('Reason')['Return Value'].sum().nlargest(8).reset_index()
            fig = px.pie(rv,values='Return Value',names='Reason',hole=0.4,color_discrete_sequence=px.colors.sequential.RdBu)
            fig.update_layout(height=350); st.plotly_chart(fig, width="stretch")
    st.markdown("---")
    col1,col2 = st.columns(2)
    with col1:
        st.markdown(t["ret_top_sku"])
        ts = df_f['SKU'].value_counts().head(15).reset_index(); ts.columns=['SKU','Returns']
        fig = px.bar(ts,x='Returns',y='SKU',orientation='h',color='Returns',color_continuous_scale='Oranges',text='Returns')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450); st.plotly_chart(fig, width="stretch")
    with col2:
        if 'Reason' in df_f.columns:
            st.markdown(t["ret_reasons"])
            rs = df_f['Reason'].value_counts().head(10).reset_index(); rs.columns=['Reason','Count']
            fig = px.pie(rs,values='Count',names='Reason',hole=0.4,color_discrete_sequence=px.colors.sequential.RdBu)
            fig.update_layout(height=450); st.plotly_chart(fig, width="stretch")
    st.markdown("---")
    dc = ['Return Date','SKU','Product Name','Quantity','Price','Return Value','Reason','Status']
    st.dataframe(df_f[[c for c in dc if c in df_f.columns]].sort_values('Return Date',ascending=False).head(100).style.format({'Price':'${:.2f}','Return Value':'${:.2f}'}),width="stretch")
    st.download_button(t["ret_download"],df_f.to_csv(index=False).encode('utf-8'),"returns.csv","text/csv")
    insights_returns(df_f, rr)


def show_inventory_finance(df_filtered, t):
    tv = df_filtered['Stock Value'].sum(); tu = df_filtered['Available'].sum()
    ap = df_filtered[df_filtered['Price']>0]['Price'].mean()
    c1,c2,c3 = st.columns(3)
    c1.metric("ğŸ’° Total Inventory Value",f"${tv:,.2f}")
    c2.metric(t["avg_price"],f"${ap:,.2f}" if not pd.isna(ap) else "$0")
    c3.metric("ğŸ’µ Avg Value per Unit",f"${tv/tu:.2f}" if tu>0 else "$0")
    st.markdown("---"); st.subheader(t["chart_value_treemap"])
    dm = df_filtered[df_filtered['Stock Value']>0]
    if not dm.empty:
        fig = px.treemap(dm,path=['Store Name','SKU'],values='Stock Value',color='Stock Value',color_continuous_scale='RdYlGn_r')
        st.plotly_chart(fig, width="stretch")
    st.subheader(t["top_money_sku"])
    dt_ = df_filtered[['SKU','Product Name','Available','Price','Stock Value']].sort_values('Stock Value',ascending=False).head(10)
    st.dataframe(dt_.style.format({'Price':"${:.2f}",'Stock Value':"${:,.2f}"}),width="stretch")
    insights_inventory(df_filtered)


def show_aging(df_filtered, t):
    if df_filtered.empty: st.warning("No data"); return
    age_cols = ['Upto 90 Days','91 to 180 Days','181 to 270 Days','271 to 365 Days','More than 365 Days']
    valid    = [c for c in age_cols if c in df_filtered.columns]
    if not valid: st.warning("Aging data not available."); return
    da = df_filtered[valid].copy()
    for c in valid: da[c] = pd.to_numeric(da[c],errors='coerce').fillna(0)
    if da.sum().sum()==0: st.info("All inventory is fresh"); return
    as_ = da.sum().reset_index(); as_.columns=['Age Group','Units']; as_ = as_[as_['Units']>0]
    col1,col2 = st.columns(2)
    with col1:
        st.subheader(t["chart_age"])
        fig = px.pie(as_,values='Units',names='Age Group',hole=0.4); fig.update_layout(height=400)
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.subheader(t["chart_velocity"])
        if all(c in df_filtered.columns for c in ['Available','Velocity','Stock Value']):
            ds = df_filtered[(df_filtered['Available']>0)&(df_filtered['Velocity']>=0)&(df_filtered['Stock Value']>0)].copy()
            if not ds.empty:
                fig = px.scatter(ds,x='Available',y='Velocity',size='Stock Value',color='Store Name' if 'Store Name' in ds.columns else None,hover_name='SKU',log_x=True)
                fig.update_layout(height=400); st.plotly_chart(fig, width="stretch")


def show_ai_forecast(df, t):
    st.markdown("### Select SKU for Forecast")
    skus = sorted(df['SKU'].unique())
    if not skus: st.info("No SKU available"); return
    col1,col2 = st.columns([2,1])
    target_sku    = col1.selectbox(t["ai_select"],skus)
    forecast_days = col2.slider(t["ai_days"],7,90,30)
    sd = df[df['SKU']==target_sku].copy().sort_values('created_at')
    sd['date_ordinal'] = sd['created_at'].map(dt.datetime.toordinal)
    if len(sd)>=3:
        model = LinearRegression().fit(sd[['date_ordinal']], sd['Available'])
        last  = sd['created_at'].max()
        fd    = [last+dt.timedelta(days=x) for x in range(1,forecast_days+1)]
        fo    = np.array([d.toordinal() for d in fd]).reshape(-1,1)
        preds = [max(0,int(p)) for p in model.predict(fo)]
        df_fc = pd.DataFrame({'date':fd,'Predicted':preds})
        so    = df_fc[df_fc['Predicted']==0]
        if not so.empty: st.error(f"{t['ai_result_date']} **{so.iloc[0]['date'].date()}**")
        else:             st.success(t['ai_ok'])
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=sd['created_at'],y=sd['Available'],name='Historical'))
        fig.add_trace(go.Scatter(x=df_fc['date'],y=df_fc['Predicted'],name='Forecast',line=dict(dash='dash',color='red')))
        st.plotly_chart(fig, width="stretch")
    else: st.warning(t["ai_error"])


def show_data_table(df_filtered, t, selected_date):
    st.markdown("### ğŸ“Š FBA Inventory Dataset")
    st.download_button("ğŸ“¥ Download CSV",df_filtered.to_csv(index=False).encode('utf-8'),"fba_inventory.csv","text/csv")
    st.dataframe(df_filtered, width="stretch", height=600)


def show_orders(t=None):
    if t is None: t = translations.get("UA", {})
    df_orders = load_orders()
    if df_orders.empty: st.warning("âš ï¸ No orders data."); return
    st.sidebar.markdown("---"); st.sidebar.subheader("ğŸ›’ Orders Filters")
    min_date = df_orders['Order Date'].min().date(); max_date = df_orders['Order Date'].max().date()
    date_range = st.sidebar.date_input(t["st_date_range"],value=(max_date-dt.timedelta(days=7),max_date),min_value=min_date,max_value=max_date)
    df_f = df_orders[(df_orders['Order Date'].dt.date>=date_range[0])&(df_orders['Order Date'].dt.date<=date_range[1])] if len(date_range)==2 else df_orders
    c1,c2,c3 = st.columns(3)
    c1.metric("ğŸ“¦ Orders",df_f['Order ID'].nunique()); c2.metric("ğŸ’° Revenue",f"${df_f['Total Price'].sum():,.2f}"); c3.metric("ğŸ“¦ Items",int(df_f['Quantity'].sum()))
    st.markdown("#### ğŸ“ˆ Daily Revenue")
    daily = df_f.groupby(df_f['Order Date'].dt.date)['Total Price'].sum().reset_index()
    fig = px.bar(daily,x='Order Date',y='Total Price',title="Daily Revenue")
    st.plotly_chart(fig, width="stretch")
    col1,col2 = st.columns(2)
    with col1:
        st.markdown("#### ğŸ† Top 10 SKU by Revenue")
        ts = df_f.groupby('SKU')['Total Price'].sum().nlargest(10).reset_index()
        fig2 = px.bar(ts,x='Total Price',y='SKU',orientation='h'); fig2.update_layout(yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig2, width="stretch")
    with col2:
        if 'Order Status' in df_f.columns:
            st.markdown("#### ğŸ“Š Order Status")
            sc = df_f['Order Status'].value_counts().reset_index(); sc.columns=['Status','Count']
            fig3 = px.pie(sc,values='Count',names='Status',hole=0.4); st.plotly_chart(fig3, width="stretch")
    insights_orders(df_f)


# ============================================
# ğŸ•· SCRAPER MANAGER â€” SIMPLIFIED
# ============================================

APIFY_TOKEN_DEFAULT = os.getenv("APIFY_TOKEN", "")
STARS_MAP = {5: "fiveStar", 4: "fourStar", 3: "threeStar", 2: "twoStar", 1: "oneStar"}
DOMAIN_FLAGS = {
    "com": "ğŸ‡ºğŸ‡¸", "ca": "ğŸ‡¨ğŸ‡¦", "de": "ğŸ‡©ğŸ‡ª", "co.uk": "ğŸ‡¬ğŸ‡§",
    "it": "ğŸ‡®ğŸ‡¹", "es": "ğŸ‡ªğŸ‡¸", "fr": "ğŸ‡«ğŸ‡·", "co.jp": "ğŸ‡¯ğŸ‡µ",
    "com.au": "ğŸ‡¦ğŸ‡º", "com.mx": "ğŸ‡²ğŸ‡½", "nl": "ğŸ‡³ğŸ‡±", "pl": "ğŸ‡µğŸ‡±", "se": "ğŸ‡¸ğŸ‡ª",
}


def _scr_get_conn():
    from urllib.parse import urlparse
    r = urlparse(DATABASE_URL)
    return psycopg2.connect(
        database=r.path[1:], user=r.username, password=r.password,
        host=r.hostname, port=r.port, connect_timeout=10
    )


def _scr_ensure_table():
    conn = _scr_get_conn(); cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS amazon_reviews (
            id SERIAL PRIMARY KEY, asin VARCHAR(20), domain VARCHAR(20),
            review_id VARCHAR(100) UNIQUE, author VARCHAR(255), rating INTEGER,
            title TEXT, content TEXT, is_verified BOOLEAN,
            product_attributes TEXT, review_date TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
    """)
    conn.commit(); cur.close(); conn.close()


def _scr_save(reviews, asin, domain):
    conn = _scr_get_conn(); cur = conn.cursor(); inserted = 0
    for rev in reviews:
        url = rev.get("reviewUrl", "")
        rid = url.split("/")[-1] if url else f"{asin}_{domain}_{rev.get('position','?')}"
        try:
            cur.execute("""
                INSERT INTO amazon_reviews
                (asin,domain,review_id,author,rating,title,content,is_verified,product_attributes,review_date)
                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) ON CONFLICT (review_id) DO NOTHING
            """, (asin, domain, rid,
                  rev.get("author","Amazon User"), int(rev.get("ratingScore",0)),
                  rev.get("reviewTitle",""), rev.get("reviewDescription",""),
                  bool(rev.get("isVerified",False)), rev.get("variant",""), rev.get("date","")))
            if cur.rowcount > 0: inserted += 1
        except: pass
    conn.commit(); cur.close(); conn.close()
    return inserted


def _scr_count(asin, domain):
    try:
        conn = _scr_get_conn(); cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM amazon_reviews WHERE asin=%s AND domain=%s", (asin, domain))
        n = cur.fetchone()[0]; cur.close(); conn.close(); return n
    except: return 0


def _scr_parse_url(url):
    from urllib.parse import urlparse
    p = urlparse(url.strip())
    domain = p.netloc.replace("www.amazon.", "")
    m = re.search(r"([A-Z0-9]{10})", p.path)
    return domain, (m.group(1) if m else "UNKNOWN")


def _scr_worker(urls, max_per_star, log_q, progress_q, loop_mode, stop_event, apify_token):
    try:
        _scr_ensure_table()
    except Exception as e:
        log_q.put(f"âŒ DB error: {e}"); progress_q.put({"done": True}); return

    endpoint = (
        f"https://api.apify.com/v2/acts/junglee~amazon-reviews-scraper"
        f"/run-sync-get-dataset-items?token={apify_token}"
    )
    cycle = 0
    while not stop_event.is_set():
        cycle += 1
        total_steps = len(urls) * 5
        step = 0
        cycle_total = 0

        if loop_mode:
            log_q.put(f"\n{'ğŸ”„'*20}")
            log_q.put(f"ğŸ”„  Ğ¦Ğ˜ĞšĞ› #{cycle} Ğ ĞĞ—ĞŸĞĞ§ĞĞ¢Ğ")
            log_q.put(f"{'ğŸ”„'*20}")

        for url in urls:
            if stop_event.is_set(): break
            domain, asin = _scr_parse_url(url)
            flag = DOMAIN_FLAGS.get(domain, "ğŸŒ")
            log_q.put(f"\n{'='*50}")
            log_q.put(f"{flag}  {asin}  Â·  amazon.{domain}  (Ñ†Ğ¸ĞºĞ» #{cycle})")
            log_q.put(f"{'='*50}")

            url_new = 0
            for star_num, star_text in STARS_MAP.items():
                if stop_event.is_set(): break
                step += 1
                pct = int(step / total_steps * 100)
                log_q.put(f"  â³ {star_num}â˜… â€” Ğ·Ğ±Ğ¸Ñ€Ğ°Ñ”Ğ¼Ğ¾ (max {max_per_star})...")
                progress_q.put({"pct": pct, "label": f"Ğ¦Ğ¸ĞºĞ» #{cycle} Â· {asin} Â· {star_num}â˜…"})
                payload = {
                    "productUrls": [{"url": url}],
                    "filterByRatings": [star_text],
                    "maxReviews": max_per_star,
                    "sort": "recent",
                }
                try:
                    res = requests.post(endpoint, json=payload, timeout=360)
                    if res.status_code in (200, 201):
                        data = res.json()
                        if data:
                            ins = _scr_save(data, asin, domain)
                            url_new   += ins
                            cycle_total += ins
                            log_q.put(f"  âœ… {star_num}â˜…: Ğ¾Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ğ½Ğ¾ {len(data)}, Ğ½Ğ¾Ğ²Ğ¸Ñ…: {ins}")
                        else:
                            log_q.put(f"  âš ï¸ {star_num}â˜…: Ğ²Ñ–Ğ´Ğ³ÑƒĞºÑ–Ğ² Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾")
                    else:
                        log_q.put(f"  âŒ {star_num}â˜…: HTTP {res.status_code}")
                except Exception as e:
                    log_q.put(f"  âŒ {star_num}â˜…: {e}")
                time.sleep(1.5)

            in_db = _scr_count(asin, domain)
            log_q.put(f"ğŸ¯ {asin}/{domain}: +{url_new} Ğ½Ğ¾Ğ²Ğ¸Ñ… Â· Ğ² Ğ‘Ğ”: {in_db}")
            time.sleep(3)

        if loop_mode and not stop_event.is_set():
            pause_min = 30
            log_q.put(f"\nğŸ Ğ¦Ğ¸ĞºĞ» #{cycle} Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾! +{cycle_total} Ğ½Ğ¾Ğ²Ğ¸Ñ….")
            log_q.put(f"â¸  ĞŸĞ°ÑƒĞ·Ğ° {pause_min} Ñ…Ğ² Ğ¿ĞµÑ€ĞµĞ´ Ğ½Ğ°ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ğ¼ Ñ†Ğ¸ĞºĞ»Ğ¾Ğ¼...")
            progress_q.put({"pct": 100, "label": f"Ğ¦Ğ¸ĞºĞ» #{cycle} Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾, Ğ¿Ğ°ÑƒĞ·Ğ° {pause_min} Ñ…Ğ²..."})
            for _ in range(pause_min * 12):
                if stop_event.is_set(): break
                time.sleep(5)
        else:
            break

    log_q.put(f"\nğŸ Ğ—Ğ‘Ğ†Ğ  Ğ—Ğ£ĞŸĞ˜ĞĞ•ĞĞ Ğ¿Ñ–ÑĞ»Ñ {cycle} Ñ†Ğ¸ĞºĞ»(Ñ–Ğ²)")
    progress_q.put({"pct": 100, "label": "Ğ—ÑƒĞ¿Ğ¸Ğ½ĞµĞ½Ğ¾", "done": True, "total": cycle})


def _scr_init():
    defaults = {
        "scr_running": False, "scr_logs": [], "scr_pct": 0,
        "scr_label": "", "scr_done": False, "scr_cycles": 0,
        "scr_log_q": None, "scr_prog_q": None,
        "scr_stop_event": None,
    }
    for k, v in defaults.items():
        if k not in st.session_state: st.session_state[k] = v


def _scr_flush():
    lq = st.session_state.scr_log_q
    pq = st.session_state.scr_prog_q
    if lq:
        while not lq.empty():
            try: st.session_state.scr_logs.append(lq.get_nowait())
            except: break
    if pq:
        while not pq.empty():
            try:
                msg = pq.get_nowait()
                if "pct"   in msg: st.session_state.scr_pct    = msg["pct"]
                if "label" in msg: st.session_state.scr_label  = msg["label"]
                if "done"  in msg and msg["done"]:
                    st.session_state.scr_done    = True
                    st.session_state.scr_running = False
                    st.session_state.scr_cycles  = msg.get("total", 0)
            except: break


def show_scraper_manager():
    _scr_init()
    _scr_flush()

    st.markdown("## ğŸ•· Scraper Reviews")

    # â”€â”€ Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ â”€â”€
    if st.session_state.scr_running:
        st.info(f"ğŸ”„ {st.session_state.scr_label or 'Ğ—Ğ±Ñ–Ñ€ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ–...'}")
    elif st.session_state.scr_done:
        st.success(f"âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾! Ğ¦Ğ¸ĞºĞ»Ñ–Ğ²: **{st.session_state.scr_cycles}**")

    st.progress(st.session_state.scr_pct, text=st.session_state.scr_label or " ")
    st.markdown("---")

    # â”€â”€ Ğ¤Ğ¾Ñ€Ğ¼Ğ° â”€â”€
    urls_input = st.text_area(
        "ğŸ”— ĞŸĞ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ Amazon (Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ½Ğ° Ñ€ÑĞ´Ğ¾Ğº):",
        height=180,
        placeholder=(
            "https://www.amazon.com/dp/B08HR2131Z\n"
            "https://www.amazon.de/dp/B08HWCL2RY\n"
            "https://www.amazon.co.uk/dp/B07XCDPRGZ"
        ),
        disabled=st.session_state.scr_running,
        key="scr_urls_input"
    )

    max_per_star = 100  # Amazon limit
    c2, c3 = st.columns([3, 1])
    with c2:
        loop_mode = st.toggle(
            "ğŸ”„ ĞĞµÑĞºÑ–Ğ½Ñ‡ĞµĞ½Ğ½Ğ¸Ğ¹ Ñ†Ğ¸ĞºĞ» (Ğ¿Ğ°ÑƒĞ·Ğ° 30 Ñ…Ğ² Ğ¼Ñ–Ğ¶ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ°Ğ¼Ğ¸)",
            value=False,
            disabled=st.session_state.scr_running
        )
    with c3:
        st.markdown("<div style='margin-top:28px'>", unsafe_allow_html=True)
        if st.session_state.scr_running:
            if st.button("â›” Ğ—ÑƒĞ¿Ğ¸Ğ½Ğ¸Ñ‚Ğ¸", width="stretch", type="secondary"):
                if st.session_state.scr_stop_event:
                    st.session_state.scr_stop_event.set()
                st.session_state.scr_running = False
                st.session_state.scr_done    = True
                st.rerun()
        else:
            raw_lines = [u.strip() for u in (urls_input or "").splitlines() if u.strip()]
            if st.button("ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğ¸", width="stretch", type="primary",
                         disabled=not raw_lines):
                lq      = queue.Queue()
                pq      = queue.Queue()
                stop_ev = threading.Event()

                st.session_state.scr_logs       = []
                st.session_state.scr_pct        = 0
                st.session_state.scr_label      = "Ğ¡Ñ‚Ğ°Ñ€Ñ‚..."
                st.session_state.scr_done       = False
                st.session_state.scr_running    = True
                st.session_state.scr_cycles     = 0
                st.session_state.scr_log_q      = lq
                st.session_state.scr_prog_q     = pq
                st.session_state.scr_stop_event = stop_ev

                threading.Thread(
                    target=_scr_worker,
                    args=(raw_lines, max_per_star, lq, pq,
                          loop_mode, stop_ev, APIFY_TOKEN_DEFAULT),
                    daemon=True
                ).start()
                st.rerun()

    st.markdown("---")

    # â”€â”€ Ğ›Ğ¾Ğ³Ğ¸ â”€â”€
    st.markdown("### ğŸ“œ Ğ›Ğ¾Ğ³Ğ¸")
    logs = st.session_state.scr_logs
    if logs:
        colored = []
        for line in logs[-100:]:
            if "===" in line:
                colored.append(f'<span style="color:#5B9BD5;font-weight:700">{line}</span>')
            elif "ğŸ”„" in line and "Ğ¦Ğ˜ĞšĞ›" in line:
                colored.append(f'<span style="color:#AB47BC;font-weight:800;font-size:14px">{line}</span>')
            elif "âœ…" in line:
                colored.append(f'<span style="color:#4CAF50">{line}</span>')
            elif "âŒ" in line:
                colored.append(f'<span style="color:#F44336">{line}</span>')
            elif "âš ï¸" in line:
                colored.append(f'<span style="color:#FFC107">{line}</span>')
            elif "ğŸ" in line or "Ğ—Ğ£ĞŸĞ˜ĞĞ•ĞĞ" in line:
                colored.append(f'<span style="color:#FFD700;font-weight:800">{line}</span>')
            elif "ğŸ¯" in line:
                colored.append(f'<span style="color:#AB47BC">{line}</span>')
            elif "â¸" in line:
                colored.append(f'<span style="color:#888;font-style:italic">{line}</span>')
            else:
                colored.append(f'<span style="color:#ccc">{line}</span>')

        st.markdown(f"""
        <div style="background:#0d1117;border:1px solid #30363d;border-radius:10px;
                    padding:16px 20px;font-family:'Courier New',monospace;font-size:13px;
                    line-height:1.7;max-height:520px;overflow-y:auto">
          {"<br>".join(colored)}
        </div>""", unsafe_allow_html=True)

        c1, c2, _ = st.columns([1, 1, 3])
        with c1:
            if st.button("ğŸ—‘ ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚Ğ¸ Ğ»Ğ¾Ğ³Ğ¸", width="stretch"):
                st.session_state.scr_logs = []
                st.session_state.scr_done = False
                st.rerun()
        with c2:
            st.download_button(
                "ğŸ“¥ Ğ—Ğ±ĞµÑ€ĞµĞ³Ñ‚Ğ¸ Ğ»Ğ¾Ğ³",
                "\n".join(logs).encode(),
                "scraper_log.txt", "text/plain", width="stretch"
            )
    else:
        st.markdown("""
        <div style="background:#0d1117;border:1px solid #30363d;border-radius:10px;
                    padding:24px;color:#555;font-family:monospace;text-align:center">
          Ğ›Ğ¾Ğ³Ğ¸ Ğ·'ÑĞ²Ğ»ÑÑ‚ÑŒÑÑ Ğ¿Ñ–ÑĞ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ...
        </div>""", unsafe_allow_html=True)

    # Auto-refresh Ğ¿Ğ¾ĞºĞ¸ Ñ–Ğ´Ğµ
    if st.session_state.scr_running:
        time.sleep(2)
        st.rerun()


# ============================================
# MAIN
# ============================================

from auth import (
    ensure_tables, create_admin_if_not_exists,
    show_login, logout, can_view,
    show_admin_panel, ALL_REPORTS
)

# â”€â”€ Init DB tables on first run â”€â”€
try:
    ensure_tables()
    create_admin_if_not_exists()
except Exception as e:
    st.error(f"DB init error: {e}")
    st.stop()

# â”€â”€ Not logged in â†’ show login form â”€â”€
if "user" not in st.session_state or not st.session_state.user:
    show_login()
    st.stop()

# â”€â”€ Logged in â”€â”€
user = st.session_state.user

# Sidebar: user info + logout
st.sidebar.markdown(f"""
<div style="background:#1e1e2e;border-radius:8px;padding:10px 14px;margin-bottom:8px">
  <div style="font-size:14px;font-weight:700;color:#fff">{user['name'] or user['email']}</div>
  <div style="font-size:12px;color:#888">{user['email']}</div>
  <div style="font-size:11px;color:#AB47BC;margin-top:4px;font-weight:600">{user['role'].upper()}</div>
</div>""", unsafe_allow_html=True)
if st.sidebar.button("ğŸšª Ğ’Ğ¸Ğ¹Ñ‚Ğ¸", width="stretch"):
    logout()

if 'report_choice' not in st.session_state:
    st.session_state.report_choice = "ğŸ  Overview"

lang_option = st.sidebar.selectbox("ğŸŒ Language", ["UA ğŸ‡ºğŸ‡¦","EN ğŸ‡ºğŸ‡¸","RU ğŸŒ"], index=0)
lang = "UA" if "UA" in lang_option else "EN" if "EN" in lang_option else "RU"
t    = translations[lang]

if st.sidebar.button(t["update_btn"], width="stretch"):
    st.cache_data.clear(); st.rerun()

df = load_data()

if not df.empty:
    for col in ['Available','Price','Velocity','Stock Value']:
        if col not in df.columns: df[col] = 0
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    df['Stock Value'] = df['Available'] * df['Price']
    df['created_at']  = pd.to_datetime(df['created_at'])
    df['date']        = df['created_at'].dt.date
    st.sidebar.header(t["sidebar_title"])
    dates         = sorted(df['date'].unique(), reverse=True)
    selected_date = st.sidebar.selectbox(t["date_label"], dates) if dates else None
    stores        = [t["all_stores"]] + list(df['Store Name'].unique()) if 'Store Name' in df.columns else [t["all_stores"]]
    selected_store = st.sidebar.selectbox(t["store_label"], stores)
    df_filtered    = df[df['date']==selected_date] if selected_date else df
    if selected_store != t["all_stores"]:
        df_filtered = df_filtered[df_filtered['Store Name']==selected_store]
else:
    df_filtered = pd.DataFrame(); selected_date = None

st.sidebar.markdown("---")
st.sidebar.header("ğŸ“Š Reports")

# Ğ¤Ğ¾Ñ€Ğ¼ÑƒÑ”Ğ¼Ğ¾ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ñ… Ğ·Ğ²Ñ–Ñ‚Ñ–Ğ² Ğ´Ğ»Ñ Ñ†ÑŒĞ¾Ğ³Ğ¾ ÑĞ·ĞµÑ€Ğ°
all_nav = [
    "ğŸ  Overview","ğŸ“ˆ Sales & Traffic","ğŸ¦ Settlements (Payouts)",
    "ğŸ’° Inventory Value (CFO)","ğŸ›’ Orders Analytics","ğŸ“¦ Returns Analytics",
    "â­ Amazon Reviews","ğŸ¢ Inventory Health (Aging)","ğŸ§  AI Forecast",
    "ğŸ“‹ FBA Inventory Table","ğŸ•· Scraper Reviews",
]
# ĞĞ´Ğ¼Ñ–Ğ½ Ğ±Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ + Ğ°Ğ´Ğ¼Ñ–Ğ½ĞºÑƒ
if user["role"] == "admin":
    report_options = all_nav + ["ğŸ‘‘ User Management"]
else:
    report_options = [r for r in all_nav if can_view(r)]

if not report_options:
    st.warning("Ğ£ Ğ²Ğ°Ñ Ğ½ĞµĞ¼Ğ°Ñ” Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ñƒ Ğ´Ğ¾ Ğ¶Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ¾Ğ·Ğ´Ñ–Ğ»Ñƒ. Ğ—Ğ²ĞµÑ€Ğ½Ñ–Ñ‚ÑŒÑÑ Ğ´Ğ¾ Ğ°Ğ´Ğ¼Ñ–Ğ½Ñ–ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°.")
    st.stop()

if st.session_state.report_choice not in report_options:
    st.session_state.report_choice = report_options[0]

current_index = report_options.index(st.session_state.report_choice)
report_choice = st.sidebar.radio("Select Report:", report_options, index=current_index)
st.session_state.report_choice = report_choice

if   report_choice == "ğŸ  Overview":                show_overview(df_filtered, t, selected_date)
elif report_choice == "ğŸ“ˆ Sales & Traffic":          show_sales_traffic(t)
elif report_choice == "ğŸ¦ Settlements (Payouts)":   show_settlements(t)
elif report_choice == "ğŸ’° Inventory Value (CFO)":   show_inventory_finance(df_filtered, t)
elif report_choice == "ğŸ›’ Orders Analytics":         show_orders(t)
elif report_choice == "ğŸ“¦ Returns Analytics":        show_returns(t)
elif report_choice == "â­ Amazon Reviews":           show_reviews(t)
elif report_choice == "ğŸ¢ Inventory Health (Aging)":show_aging(df_filtered, t)
elif report_choice == "ğŸ§  AI Forecast":              show_ai_forecast(df, t)
elif report_choice == "ğŸ“‹ FBA Inventory Table":      show_data_table(df_filtered, t, selected_date)
elif report_choice == "ğŸ•· Scraper Reviews":          show_scraper_manager()
elif report_choice == "ğŸ‘‘ User Management":          show_admin_panel()

st.sidebar.markdown("---")
st.sidebar.caption("ğŸ“¦ Amazon FBA BI System v5.0 ğŸŒ")
