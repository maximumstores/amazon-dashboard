import streamlit as st
import pandas as pd
import os
import re
import psycopg2
import requests
import threading
import queue
import time
import plotly.express as px
import plotly.graph_objects as go
from sklearn.linear_model import LinearRegression
import numpy as np
import datetime as dt
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
try:
    import google.generativeai as genai
    GEMINI_OK = True
except ImportError:
    GEMINI_OK = False

load_dotenv()

st.set_page_config(page_title="Amazon FBA Ultimate BI", layout="wide", page_icon="üì¶")

translations = {
    "UA": {
        "title": "üì¶ Amazon FBA: Business Intelligence Hub",
        "update_btn": "üîÑ –û–Ω–æ–≤–∏—Ç–∏ –¥–∞–Ω—ñ",
        "sidebar_title": "üîç –§—ñ–ª—å—Ç—Ä–∏",
        "date_label": "üìÖ –î–∞—Ç–∞:",
        "store_label": "üè™ –ú–∞–≥–∞–∑–∏–Ω:",
        "all_stores": "–í—Å—ñ",
        "total_sku": "–í—Å—å–æ–≥–æ SKU",
        "total_avail": "–®—Ç—É–∫ –Ω–∞ —Å–∫–ª–∞–¥—ñ",
        "total_value": "üí∞ –í–∞—Ä—Ç—ñ—Å—Ç—å —Å–∫–ª–∞–¥—É",
        "velocity_30": "–ü—Ä–æ–¥–∞–∂—ñ (30 –¥–Ω—ñ–≤)",
        "chart_value_treemap": "üí∞ –î–µ –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ñ –≥—Ä–æ—à—ñ?",
        "chart_velocity": "üöÄ –®–≤–∏–¥–∫—ñ—Å—Ç—å vs –ó–∞–ª–∏—à–∫–∏",
        "chart_age": "‚è≥ –í—ñ–∫ —ñ–Ω–≤–µ–Ω—Ç–∞—Ä—é",
        "top_money_sku": "üèÜ –¢–æ–ø SKU –∑–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—é",
        "top_qty_sku": "üèÜ –¢–æ–ø SKU –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—é",
        "avg_price": "–°–µ—Ä–µ–¥–Ω—è —Ü—ñ–Ω–∞",
        "ai_header": "üß† AI –ü—Ä–æ–≥–Ω–æ–∑ –∑–∞–ª–∏—à–∫—ñ–≤",
        "ai_select": "–û–±–µ—Ä—ñ—Ç—å SKU:",
        "ai_days": "–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑—É:",
        "ai_result_date": "üìÖ –î–∞—Ç–∞ Sold-out:",
        "ai_result_days": "–î–Ω—ñ–≤ –∑–∞–ª–∏—à–∏–ª–æ—Å—å:",
        "ai_ok": "‚úÖ –ó–∞–ø–∞—Å—ñ–≤ –≤–∏—Å—Ç–∞—á–∏—Ç—å",
        "ai_error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É",
        "footer_date": "üìÖ –î–∞–Ω—ñ –æ–Ω–æ–≤–ª–µ–Ω–æ:",
        "download_excel": "üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Excel",
        "settlements_title": "üè¶ –§—ñ–Ω–∞–Ω—Å–æ–≤—ñ –≤–∏–ø–ª–∞—Ç–∏ (Settlements)",
        "net_payout": "–ß–∏—Å—Ç–∞ –≤–∏–ø–ª–∞—Ç–∞",
        "gross_sales": "–í–∞–ª–æ–≤—ñ –ø—Ä–æ–¥–∞–∂—ñ",
        "total_fees": "–í—Å—å–æ–≥–æ –∫–æ–º—ñ—Å—ñ–π",
        "total_refunds": "–ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –∫–æ—à—Ç—ñ–≤",
        "chart_payout_trend": "üìâ –î–∏–Ω–∞–º—ñ–∫–∞ –≤–∏–ø–ª–∞—Ç",
        "chart_fee_breakdown": "üí∏ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∏—Ç—Ä–∞—Ç",
        "currency_select": "üí± –í–∞–ª—é—Ç–∞:",
        "sales_traffic_title": "üìà Sales & Traffic",
        "st_sessions": "–°–µ—Å—ñ—ó",
        "st_page_views": "–ü–µ—Ä–µ–≥–ª—è–¥–∏",
        "st_units": "–ó–∞–º–æ–≤–ª–µ–Ω–æ —à—Ç—É–∫",
        "st_conversion": "–ö–æ–Ω–≤–µ—Ä—Å—ñ—è",
        "st_revenue": "–î–æ—Ö—ñ–¥",
        "st_buy_box": "Buy Box %",
        "reviews_title": "‚≠ê –í—ñ–¥–≥—É–∫–∏ –ø–æ–∫—É–ø—Ü—ñ–≤",
        "total_reviews": "–í—Å—å–æ–≥–æ –≤—ñ–¥–≥—É–∫—ñ–≤",
        "avg_review_rating": "–°–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥",
        "verified_pct": "–í–µ—Ä–∏—Ñ—ñ–∫–æ–≤–∞–Ω—ñ (%)",
        "star_dist": "–†–æ–∑–ø–æ–¥—ñ–ª –ø–æ –∑—ñ—Ä–∫–∞—Ö",
        "worst_asin": "–ü—Ä–æ–±–ª–µ–º–Ω—ñ ASIN (1-2‚òÖ)",
        "ov_title": "üìä –û–≥–ª—è–¥ –±—ñ–∑–Ω–µ—Å—É",
        "ov_top_sku": "### üìä –¢–æ–ø 15 SKU –∑–∞ –∑–∞–ª–∏—à–∫–∞–º–∏",
        "st_daily_trends": "### üìà –©–æ–¥–µ–Ω–Ω–∞ –¥–∏–Ω–∞–º—ñ–∫–∞",
        "st_sessions_views": "#### üëÅ –°–µ—Å—ñ—ó —Ç–∞ –ø–µ—Ä–µ–≥–ª—è–¥–∏",
        "st_revenue_units": "#### üí∞ –î–æ—Ö—ñ–¥ —Ç–∞ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è",
        "st_top_asins": "### üèÜ –¢–æ–ø ASIN–∏",
        "st_top_revenue": "#### üí∞ –¢–æ–ø 15 –∑–∞ –¥–æ—Ö–æ–¥–æ–º",
        "st_top_sessions": "#### üëÅ –¢–æ–ø 15 –∑–∞ —Å–µ—Å—ñ—è–º–∏",
        "st_full_data": "### üìã –í—Å—ñ –¥–∞–Ω—ñ –ø–æ ASIN–∞—Ö",
        "st_download": "üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ CSV",
        "st_filters": "üìà –§—ñ–ª—å—Ç—Ä–∏ Sales & Traffic",
        "st_date_range": "üìÖ –î—ñ–∞–ø–∞–∑–æ–Ω –¥–∞—Ç:",
        "ret_title": "### üì¶ –û–≥–ª—è–¥ –ø–æ–≤–µ—Ä–Ω–µ–Ω—å",
        "ret_total": "üì¶ –í—Å—å–æ–≥–æ –ø–æ–≤–µ—Ä–Ω–µ–Ω—å",
        "ret_unique_sku": "üì¶ –£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö SKU",
        "ret_rate": "üìä –†—ñ–≤–µ–Ω—å –ø–æ–≤–µ—Ä–Ω–µ–Ω—å",
        "ret_value": "üí∞ –í–∞—Ä—Ç—ñ—Å—Ç—å –ø–æ–≤–µ—Ä–Ω–µ–Ω—å",
        "ret_avg": "üíµ –°–µ—Ä. –≤–∞—Ä—Ç—ñ—Å—Ç—å",
        "ret_by_sku": "#### üíµ –í–∞—Ä—Ç—ñ—Å—Ç—å –ø–æ SKU (–¢–æ–ø 10)",
        "ret_daily": "#### üìä –©–æ–¥–µ–Ω–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å",
        "ret_by_reason": "#### üí∏ –ü–æ –ø—Ä–∏—á–∏–Ω–∞—Ö",
        "ret_top_sku": "#### üèÜ –¢–æ–ø 15 SKU –ø–æ–≤–µ—Ä–Ω–µ–Ω—å",
        "ret_reasons": "#### üìä –ü—Ä–∏—á–∏–Ω–∏ –ø–æ–≤–µ—Ä–Ω–µ–Ω—å",
        "ret_filters": "üì¶ –§—ñ–ª—å—Ç—Ä–∏ –ø–æ–≤–µ—Ä–Ω–µ–Ω—å",
        "ret_date": "üìÖ –î–∞—Ç–∞ –ø–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è:",
        "ret_download": "üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ CSV –ø–æ–≤–µ—Ä–Ω–µ–Ω—å",
        "ord_title": "### üõí –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –∑–∞–º–æ–≤–ª–µ–Ω—å",
        "ins_neg_trend": "–¢—Ä–µ–Ω–¥ –Ω–µ–≥–∞—Ç–∏–≤—É",
        "ins_verified": "–í–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—è",
        "ins_pos_rate": "–†—ñ–≤–µ–Ω—å –ø–æ–∑–∏—Ç–∏–≤—É",
        "rev_auto_insights": "üß† –ê–≤—Ç–æ—ñ–Ω—Å–∞–π—Ç–∏",
        "rev_worst_asin": "üî¥ –ù–ê–ô–ì–Ü–†–®–ò–ô ASIN",
        "rev_best_asin": "üü¢ –ù–ê–ô–ö–†–ê–©–ò–ô ASIN",
        "rev_worst_country": "üî¥ –ù–ê–ô–ì–Ü–†–®–ê –ö–†–ê–á–ù–ê",
        "rev_best_country": "üü¢ –ù–ê–ô–ö–†–ê–©–ê –ö–†–ê–á–ù–ê",
        "rev_reviews_count": "–≤—ñ–¥–≥.",
        "rev_main_asin": "üì¶ –ì–æ–ª–æ–≤–Ω–∏–π:",
        "rev_heatmap": "### üî• –¢–µ–ø–ª–æ–≤–∞ –∫–∞—Ä—Ç–∞: ASIN √ó –ö—Ä–∞—ó–Ω–∞",
        "rev_heatmap_hint": "–ö–ª—ñ–∫–Ω–∏ –Ω–∞ ASIN —É —Ç–∞–±–ª–∏—Ü—ñ –Ω–∏–∂—á–µ ‚Äî –≤—ñ–¥–∫—Ä–∏—î—Ç—å—Å—è –π–æ–≥–æ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ –Ω–∞ Amazon",
        "rev_asin_compare": "### üìä –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è ASIN—ñ–≤",
        "rev_star_dist": "### üìä –ó–∞–≥–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –∑—ñ—Ä–æ–∫",
        "rev_texts": "### üìã –¢–µ–∫—Å—Ç–∏ –≤—ñ–¥–≥—É–∫—ñ–≤ (–¥–æ 100 –Ω–∞ –∫–æ–∂–Ω—É –∑—ñ—Ä–∫—É, max 500)",
        "rev_sort_hint": "–°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è: —Å–ø–æ—á–∞—Ç–∫—É 1‚òÖ ‚Äî —â–æ–± –ø—Ä–æ–±–ª–µ–º–∏ –±—É–ª–∏ –ø–µ—Ä—à–∏–º–∏",
        "rev_dl_balanced": "üì• –°–∫–∞—á–∞—Ç–∏ –ø–æ —Ñ—ñ–ª—å—Ç—Ä—É",
        "rev_dl_all": "üì• –°–∫–∞—á–∞—Ç–∏ –≤—Å–µ –∑ –±–∞–∑–∏",
        "rev_dl_balanced_hint": "–í–∏–±—Ä–∞–Ω—ñ ASIN / –∫—Ä–∞—ó–Ω–∞ ‚Äî –¥–æ 100 –≤—ñ–¥–≥—É–∫—ñ–≤ –Ω–∞ –∑—ñ—Ä–∫—É",
        "rev_dl_all_hint": "–í—Å—ñ –≤—ñ–¥–≥—É–∫–∏ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö –±–µ–∑ –æ–±–º–µ–∂–µ–Ω—å",
        "rev_shown": "–ü–æ–∫–∞–∑–∞–Ω–æ {n} –∑ {total} –≤—ñ–¥–≥—É–∫—ñ–≤",
        "rev_click_hint": "üëÜ –ö–ª—ñ–∫–Ω–∏ –Ω–∞ —Ä—è–¥–æ–∫ ‚Äî –ø–æ–±–∞—á–∏—à –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ü—å–æ–≥–æ ASIN ¬∑ –ü–æ—Å–∏–ª–∞–Ω–Ω—è –≤—ñ–¥–∫—Ä–∏—é—Ç—å Amazon —É –Ω–æ–≤—ñ–π –≤–∫–ª–∞–¥—Ü—ñ",
        "rev_select_hint": "üëá –í–∏–±–µ—Ä–∏ ASIN –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É:",
        "rev_goto_asin": "üì¶ –ü–µ—Ä–µ–π—Ç–∏ –¥–æ ASIN:",
        "rev_not_selected": "‚Äî –Ω–µ –≤–∏–±—Ä–∞–Ω–æ ‚Äî",
        "rev_back": "‚Üê –ù–∞–∑–∞–¥ –¥–æ –≤—Å—ñ—Ö ASIN—ñ–≤",
        "about_title": "## ‚ÑπÔ∏è –ü—Ä–æ Merino BI Dashboard",
        "about_caption": "Amazon Intelligence Platform ‚Äî –ø–æ–≤–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ FBA –±—ñ–∑–Ω–µ—Å–æ–º –≤ –æ–¥–Ω–æ–º—É –º—ñ—Å—Ü—ñ",
        "about_modules": "### üì¶ –ú–æ–¥—É–ª—ñ —Å–∏—Å—Ç–µ–º–∏",
        "about_pipeline": "### ‚öôÔ∏è Data Pipeline",
        "about_features": "**‚úÖ –û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ**",
        "about_stack": "**üîß –¢–µ—Ö–Ω—ñ—á–Ω–∏–π —Å—Ç–µ–∫**",
        "about_footer": "MR.EQUIPP LIMITED ¬∑ Built with obsession ¬∑ v5.0",
        "rev_asins_in_filter": "üì¶ ASIN—ñ–≤ —É —Ñ—ñ–ª—å—Ç—Ä—ñ",
        "insights_title": "üß† –Ü–Ω—Å–∞–π—Ç–∏",
        "insight_rating_health": "–ó–¥–æ—Ä–æ–≤'—è —Ä–µ–π—Ç–∏–Ω–≥—É",
        "insight_loyalty": "–õ–æ—è–ª—å–Ω—ñ—Å—Ç—å",
        "insight_toxic": "–¢–æ–∫—Å–∏—á–Ω–∏–π ASIN",
        "insight_neg_level": "–†—ñ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤—É",
        "insight_verified": "–í–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—è",
        "rev_table_by_country": "üìã –ó–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö",
        "rev_count_by_country": "üìä –í—ñ–¥–≥—É–∫—ñ–≤ –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö",
        "rev_neg_by_country": "üî¥ % –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö",
        "rev_rating_by_country": "‚≠ê –†–µ–π—Ç–∏–Ω–≥ –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö",
        "rev_country_analysis": "üåç –ê–Ω–∞–ª—ñ–∑ –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö",
        "rev_star_filter": "‚≠ê –†–µ–π—Ç–∏–Ω–≥:",
        "rev_country_filter": "üåç –ö—Ä–∞—ó–Ω–∞ (–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å):",
        "rev_filters": "‚≠ê –§—ñ–ª—å—Ç—Ä–∏ –≤—ñ–¥–≥—É–∫—ñ–≤",
        "all_countries": "–í—Å—ñ –∫—Ä–∞—ó–Ω–∏",
        "all_asins": "–í—Å—ñ ASIN–∏",
    },
    "EN": {
        "title": "üì¶ Amazon FBA: Business Intelligence Hub",
        "update_btn": "üîÑ Refresh Data",
        "sidebar_title": "üîç Filters",
        "date_label": "üìÖ Date:",
        "store_label": "üè™ Store:",
        "all_stores": "All",
        "total_sku": "Total SKU",
        "total_avail": "Total Units",
        "total_value": "üí∞ Inventory Value",
        "velocity_30": "Sales (30 days)",
        "chart_value_treemap": "üí∞ Where is the money?",
        "chart_velocity": "üöÄ Velocity vs Stock",
        "chart_age": "‚è≥ Inventory Age",
        "top_money_sku": "üèÜ Top SKU by Value",
        "top_qty_sku": "üèÜ Top SKU by Quantity",
        "avg_price": "Avg Price",
        "ai_header": "üß† AI Inventory Forecast",
        "ai_select": "Select SKU:",
        "ai_days": "Forecast Days:",
        "ai_result_date": "üìÖ Sold-out Date:",
        "ai_result_days": "Days left:",
        "ai_ok": "‚úÖ Stock sufficient",
        "ai_error": "Not enough data",
        "footer_date": "üìÖ Last update:",
        "download_excel": "üì• Download Excel",
        "settlements_title": "üè¶ Financial Settlements (Payouts)",
        "net_payout": "Net Payout",
        "gross_sales": "Gross Sales",
        "total_fees": "Total Fees",
        "total_refunds": "Total Refunds",
        "chart_payout_trend": "üìâ Payout Trend",
        "chart_fee_breakdown": "üí∏ Fee Breakdown",
        "currency_select": "üí± Currency:",
        "sales_traffic_title": "üìà Sales & Traffic",
        "st_sessions": "Sessions",
        "st_page_views": "Page Views",
        "st_units": "Units Ordered",
        "st_conversion": "Conversion",
        "st_revenue": "Revenue",
        "st_buy_box": "Buy Box %",
        "reviews_title": "‚≠ê Customer Reviews",
        "total_reviews": "Total Reviews",
        "avg_review_rating": "Average Rating",
        "verified_pct": "Verified (%)",
        "star_dist": "Star Distribution",
        "worst_asin": "Problematic ASINs (1-2‚òÖ)",
        "ov_title": "üìä Business Overview",
        "ov_top_sku": "### üìä Top 15 SKU by Stock",
        "st_daily_trends": "### üìà Daily Trends",
        "st_sessions_views": "#### üëÅ Sessions & Page Views",
        "st_revenue_units": "#### üí∞ Revenue & Units",
        "st_top_asins": "### üèÜ Top ASINs Performance",
        "st_top_revenue": "#### üí∞ Top 15 by Revenue",
        "st_top_sessions": "#### üëÅ Top 15 by Sessions",
        "st_full_data": "### üìã Full ASIN Data",
        "st_download": "üì• Download CSV",
        "st_filters": "üìà Sales & Traffic Filters",
        "st_date_range": "üìÖ Date Range:",
        "ret_title": "### üì¶ Returns Overview",
        "ret_total": "üì¶ Total Returns",
        "ret_unique_sku": "üì¶ Unique SKUs",
        "ret_rate": "üìä Return Rate",
        "ret_value": "üí∞ Return Value",
        "ret_avg": "üíµ Avg Return",
        "ret_by_sku": "#### üíµ Return Value by SKU (Top 10)",
        "ret_daily": "#### üìä Daily Return Value",
        "ret_by_reason": "#### üí∏ Return Value by Reason",
        "ret_top_sku": "#### üèÜ Top 15 Returned SKUs",
        "ret_reasons": "#### üìä Return Reasons",
        "ret_filters": "üì¶ Returns Filters",
        "ret_date": "üìÖ Return Date:",
        "ret_download": "üì• Download Returns CSV",
        "ord_title": "### üõí Orders Analytics",
        "insight_rating_health": "Rating Health",
        "insight_loyalty": "Loyalty",
        "insight_toxic": "Toxic ASIN",
        "insight_neg_level": "Negative Level",
        "insight_verified": "Verification",
        "rev_auto_insights": "üß† Auto Insights",
        "rev_worst_asin": "üî¥ WORST ASIN",
        "rev_best_asin": "üü¢ BEST ASIN",
        "rev_worst_country": "üî¥ WORST COUNTRY",
        "rev_best_country": "üü¢ BEST COUNTRY",
        "rev_reviews_count": "rev.",
        "rev_main_asin": "üì¶ Main:",
        "rev_heatmap": "### üî• Heatmap: ASIN √ó Country",
        "rev_heatmap_hint": "Click ASIN in table below ‚Äî opens Amazon page",
        "rev_asin_compare": "### üìä ASIN Comparison",
        "rev_star_dist": "### üìä Overall Star Distribution",
        "rev_texts": "### üìã Review Texts (up to 100 per star, max 500)",
        "rev_sort_hint": "Sorted: 1‚òÖ first ‚Äî problems first",
        "rev_dl_balanced": "üì• Download filtered",
        "rev_dl_all": "üì• Download all from DB",
        "rev_dl_balanced_hint": "Selected ASIN / country ‚Äî up to 100 per star",
        "rev_dl_all_hint": "All reviews from database, no limits",
        "rev_shown": "Showing {n} of {total} reviews",
        "rev_click_hint": "üëÜ Click row to see detailed ASIN analysis ¬∑ Links open Amazon in new tab",
        "rev_select_hint": "üëá Select ASIN for detailed analysis:",
        "rev_goto_asin": "üì¶ Go to ASIN:",
        "rev_not_selected": "‚Äî not selected ‚Äî",
        "rev_back": "‚Üê Back to all ASINs",
        "about_title": "## ‚ÑπÔ∏è About Merino BI Dashboard",
        "about_caption": "Amazon Intelligence Platform ‚Äî full control over your FBA business in one place",
        "about_modules": "### üì¶ System Modules",
        "about_pipeline": "### ‚öôÔ∏è Data Pipeline",
        "about_features": "**‚úÖ Features**",
        "about_stack": "**üîß Tech Stack**",
        "about_footer": "MR.EQUIPP LIMITED ¬∑ Built with obsession ¬∑ v5.0",
        "rev_asins_in_filter": "üì¶ ASINs in filter",
        "insights_title": "üß† Insights",
        "insight_rating_health": "Rating Health",
        "insight_loyalty": "Loyalty",
        "insight_toxic": "Toxic ASIN",
        "insight_neg_level": "Negative Level",
        "insight_verified": "Verification",
        "rev_table_by_country": "üìã Summary Table by Country",
        "rev_count_by_country": "üìä Reviews by Country",
        "rev_neg_by_country": "üî¥ % Negative by Country",
        "rev_rating_by_country": "‚≠ê Rating by Country",
        "rev_country_analysis": "üåç Country Analysis",
        "rev_star_filter": "‚≠ê Rating:",
        "rev_country_filter": "üåç Country (marketplace):",
        "rev_filters": "‚≠ê Review Filters",
        "all_countries": "All countries",
        "all_asins": "All ASINs",
    },
    "RU": {
        "title": "üì¶ Amazon FBA: Business Intelligence Hub",
        "update_btn": "üîÑ –û–±–Ω–æ–≤–∏—Ç—å",
        "sidebar_title": "üîç –§–∏–ª—å—Ç—Ä—ã",
        "date_label": "üìÖ –î–∞—Ç–∞:",
        "store_label": "üè™ –ú–∞–≥–∞–∑–∏–Ω:",
        "all_stores": "–í—Å–µ",
        "total_sku": "–í—Å–µ–≥–æ SKU",
        "total_avail": "–®—Ç—É–∫ –Ω–∞ —Å–∫–ª–∞–¥–µ",
        "total_value": "üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å —Å–∫–ª–∞–¥–∞",
        "velocity_30": "–ü—Ä–æ–¥–∞–∂–∏ (30 –¥–Ω–µ–π)",
        "chart_value_treemap": "üí∞ –ì–¥–µ –¥–µ–Ω—å–≥–∏?",
        "chart_velocity": "üöÄ –°–∫–æ—Ä–æ—Å—Ç—å vs –û—Å—Ç–∞—Ç–∫–∏",
        "chart_age": "‚è≥ –í–æ–∑—Ä–∞—Å—Ç –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è",
        "top_money_sku": "üèÜ –¢–æ–ø SKU –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏",
        "top_qty_sku": "üèÜ –¢–æ–ø SKU –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É",
        "avg_price": "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞",
        "ai_header": "üß† AI –ü—Ä–æ–≥–Ω–æ–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤",
        "ai_select": "–í—ã–±–µ—Ä–∏—Ç–µ SKU:",
        "ai_days": "–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞:",
        "ai_result_date": "üìÖ –î–∞—Ç–∞ Sold-out:",
        "ai_result_days": "–î–Ω–µ–π –æ—Å—Ç–∞–ª–æ—Å—å:",
        "ai_ok": "‚úÖ –ó–∞–ø–∞—Å–æ–≤ —Ö–≤–∞—Ç–∏—Ç",
        "ai_error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö",
        "footer_date": "üìÖ –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã:",
        "download_excel": "üì• –°–∫–∞—á–∞—Ç—å Excel",
        "settlements_title": "üè¶ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤—ã–ø–ª–∞—Ç—ã (Settlements)",
        "net_payout": "–ß–∏—Å—Ç–∞—è –≤—ã–ø–ª–∞—Ç–∞",
        "gross_sales": "–í–∞–ª–æ–≤—ã–µ –ø—Ä–æ–¥–∞–∂–∏",
        "total_fees": "–í—Å–µ–≥–æ –∫–æ–º–∏—Å—Å–∏–π",
        "total_refunds": "–í–æ–∑–≤—Ä–∞—Ç—ã —Å—Ä–µ–¥—Å—Ç–≤",
        "chart_payout_trend": "üìâ –î–∏–Ω–∞–º–∏–∫–∞ –≤—ã–ø–ª–∞—Ç",
        "chart_fee_breakdown": "üí∏ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–∞—Å—Ö–æ–¥–æ–≤",
        "currency_select": "üí± –í–∞–ª—é—Ç–∞:",
        "sales_traffic_title": "üìà Sales & Traffic",
        "st_sessions": "–°–µ—Å—Å–∏–∏",
        "st_page_views": "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã",
        "st_units": "–ó–∞–∫–∞–∑–∞–Ω–æ —à—Ç—É–∫",
        "st_conversion": "–ö–æ–Ω–≤–µ—Ä—Å–∏—è",
        "st_revenue": "–î–æ—Ö–æ–¥",
        "st_buy_box": "Buy Box %",
        "reviews_title": "‚≠ê –û—Ç–∑—ã–≤—ã –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π",
        "total_reviews": "–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤",
        "avg_review_rating": "–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥",
        "verified_pct": "–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (%)",
        "star_dist": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∑–≤–µ–∑–¥–∞–º",
        "worst_asin": "–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ ASIN (1-2‚òÖ)",
        "ov_title": "üìä –û–±–∑–æ—Ä –±–∏–∑–Ω–µ—Å–∞",
        "ov_top_sku": "### üìä –¢–æ–ø 15 SKU –ø–æ –æ—Å—Ç–∞—Ç–∫–∞–º",
        "st_daily_trends": "### üìà –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞",
        "st_sessions_views": "#### üëÅ –°–µ—Å—Å–∏–∏ –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã",
        "st_revenue_units": "#### üí∞ –î–æ—Ö–æ–¥ –∏ –∑–∞–∫–∞–∑—ã",
        "st_top_asins": "### üèÜ –¢–æ–ø ASIN—ã",
        "st_top_revenue": "#### üí∞ –¢–æ–ø 15 –ø–æ –¥–æ—Ö–æ–¥—É",
        "st_top_sessions": "#### üëÅ –¢–æ–ø 15 –ø–æ —Å–µ—Å—Å–∏—è–º",
        "st_full_data": "### üìã –í—Å–µ –¥–∞–Ω–Ω—ã–µ –ø–æ ASIN–∞–º",
        "st_download": "üì• –°–∫–∞—á–∞—Ç—å CSV",
        "st_filters": "üìà –§–∏–ª—å—Ç—Ä—ã Sales & Traffic",
        "st_date_range": "üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç:",
        "ret_title": "### üì¶ –û–±–∑–æ—Ä –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "ret_total": "üì¶ –í—Å–µ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "ret_unique_sku": "üì¶ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SKU",
        "ret_rate": "üìä –£—Ä–æ–≤–µ–Ω—å –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "ret_value": "üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "ret_avg": "üíµ –°—Ä. —Å—Ç–æ–∏–º–æ—Å—Ç—å",
        "ret_by_sku": "#### üíµ –°—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ SKU (–¢–æ–ø 10)",
        "ret_daily": "#### üìä –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å",
        "ret_by_reason": "#### üí∏ –ü–æ –ø—Ä–∏—á–∏–Ω–∞–º",
        "ret_top_sku": "#### üèÜ –¢–æ–ø 15 SKU –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "ret_reasons": "#### üìä –ü—Ä–∏—á–∏–Ω—ã –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "ret_filters": "üì¶ –§–∏–ª—å—Ç—Ä—ã –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "ret_date": "üìÖ –î–∞—Ç–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞:",
        "ret_download": "üì• –°–∫–∞—á–∞—Ç—å CSV –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "ord_title": "### üõí –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∑–∞–∫–∞–∑–æ–≤",
        "insight_rating_health": "–ó–¥–æ—Ä–æ–≤—å–µ —Ä–µ–π—Ç–∏–Ω–≥–∞",
        "insight_loyalty": "–õ–æ—è–ª—å–Ω–æ—Å—Ç—å",
        "insight_toxic": "–¢–æ–∫—Å–∏—á–Ω—ã–π ASIN",
        "insight_neg_level": "–£—Ä–æ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–∞",
        "insight_verified": "–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è",
        "rev_auto_insights": "üß† –ê–≤—Ç–æ–∏–Ω—Å–∞–π—Ç—ã",
        "rev_worst_asin": "üî¥ –•–£–î–®–ò–ô ASIN",
        "rev_best_asin": "üü¢ –õ–£–ß–®–ò–ô ASIN",
        "rev_worst_country": "üî¥ –•–£–î–®–ê–Ø –°–¢–†–ê–ù–ê",
        "rev_best_country": "üü¢ –õ–£–ß–®–ê–Ø –°–¢–†–ê–ù–ê",
        "rev_reviews_count": "–æ—Ç–∑—ã–≤.",
        "rev_main_asin": "üì¶ –ì–ª–∞–≤–Ω—ã–π:",
        "rev_heatmap": "### üî• –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞: ASIN √ó –°—Ç—Ä–∞–Ω–∞",
        "rev_heatmap_hint": "–ù–∞–∂–º–∏ –Ω–∞ ASIN –≤ —Ç–∞–±–ª–∏—Ü–µ ‚Äî –æ—Ç–∫—Ä–æ–µ—Ç—Å—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ Amazon",
        "rev_asin_compare": "### üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ ASIN–æ–≤",
        "rev_star_dist": "### üìä –û–±—â–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–≤—ë–∑–¥",
        "rev_texts": "### üìã –¢–µ–∫—Å—Ç—ã –æ—Ç–∑—ã–≤–æ–≤ (–¥–æ 100 –Ω–∞ –∑–≤–µ–∑–¥—É, –º–∞–∫—Å 500)",
        "rev_sort_hint": "–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: —Å–Ω–∞—á–∞–ª–∞ 1‚òÖ ‚Äî –ø—Ä–æ–±–ª–µ–º—ã –ø–µ—Ä–≤—ã–º–∏",
        "rev_dl_balanced": "üì• –°–∫–∞—á–∞—Ç—å –ø–æ —Ñ–∏–ª—å—Ç—Ä—É",
        "rev_dl_all": "üì• –°–∫–∞—á–∞—Ç—å –≤—Å—ë –∏–∑ –±–∞–∑—ã",
        "rev_dl_balanced_hint": "–í—ã–±—Ä–∞–Ω–Ω—ã–π ASIN / —Å—Ç—Ä–∞–Ω–∞ ‚Äî –¥–æ 100 –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –∑–≤–µ–∑–¥—É",
        "rev_dl_all_hint": "–í—Å–µ –æ—Ç–∑—ã–≤—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π",
        "rev_shown": "–ü–æ–∫–∞–∑–∞–Ω–æ {n} –∏–∑ {total} –æ—Ç–∑—ã–≤–æ–≤",
        "rev_click_hint": "üëÜ –ù–∞–∂–º–∏ –Ω–∞ —Å—Ç—Ä–æ–∫—É ‚Äî —É–≤–∏–¥–∏—à—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ ¬∑ –°—Å—ã–ª–∫–∏ –æ—Ç–∫—Ä–æ—é—Ç Amazon –≤ –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–µ",
        "rev_select_hint": "üëá –í—ã–±–µ—Ä–∏ ASIN –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:",
        "rev_goto_asin": "üì¶ –ü–µ—Ä–µ–π—Ç–∏ –∫ ASIN:",
        "rev_not_selected": "‚Äî –Ω–µ –≤—ã–±—Ä–∞–Ω–æ ‚Äî",
        "rev_back": "‚Üê –ù–∞–∑–∞–¥ –∫–æ –≤—Å–µ–º ASIN–∞–º",
        "about_title": "## ‚ÑπÔ∏è –û Merino BI Dashboard",
        "about_caption": "Amazon Intelligence Platform ‚Äî –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ FBA –±–∏–∑–Ω–µ—Å–æ–º –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ",
        "about_modules": "### üì¶ –ú–æ–¥—É–ª–∏ —Å–∏—Å—Ç–µ–º—ã",
        "about_pipeline": "### ‚öôÔ∏è Data Pipeline",
        "about_features": "**‚úÖ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**",
        "about_stack": "**üîß –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏**",
        "about_footer": "MR.EQUIPP LIMITED ¬∑ Built with obsession ¬∑ v5.0",
        "rev_asins_in_filter": "üì¶ ASIN–æ–≤ –≤ —Ñ–∏–ª—å—Ç—Ä–µ",
        "insights_title": "üß† –ò–Ω—Å–∞–π—Ç—ã",
        "insight_rating_health": "–ó–¥–æ—Ä–æ–≤—å–µ —Ä–µ–π—Ç–∏–Ω–≥–∞",
        "insight_loyalty": "–õ–æ—è–ª—å–Ω–æ—Å—Ç—å",
        "insight_toxic": "–¢–æ–∫—Å–∏—á–Ω—ã–π ASIN",
        "insight_neg_level": "–£—Ä–æ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–∞",
        "insight_verified": "–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è",
        "rev_table_by_country": "üìã –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º",
        "rev_count_by_country": "üìä –û—Ç–∑—ã–≤–æ–≤ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º",
        "rev_neg_by_country": "üî¥ % –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ —Å—Ç—Ä–∞–Ω–∞–º",
        "rev_rating_by_country": "‚≠ê –†–µ–π—Ç–∏–Ω–≥ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º",
        "rev_country_analysis": "üåç –ê–Ω–∞–ª–∏–∑ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º",
        "rev_star_filter": "‚≠ê –†–µ–π—Ç–∏–Ω–≥:",
        "rev_country_filter": "üåç –°—Ç—Ä–∞–Ω–∞ (–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å):",
        "rev_filters": "‚≠ê –§–∏–ª—å—Ç—Ä—ã –æ—Ç–∑—ã–≤–æ–≤",
        "all_countries": "–í—Å–µ —Å—Ç—Ä–∞–Ω—ã",
        "all_asins": "–í—Å–µ ASIN—ã",
    }
}


DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL and DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

def get_engine():
    return create_engine(
        DATABASE_URL,
        connect_args={"options": "-csearch_path=spapi,public", "connect_timeout": 10},
        pool_timeout=10,
        pool_pre_ping=True,
    )

# DATA LOADERS
# ============================================

@st.cache_data(ttl=60)
def load_data():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text("SELECT * FROM fba_inventory ORDER BY created_at DESC"), conn)
        return df
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î (Inventory): {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_orders():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM orders ORDER BY "Order Date" DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=True, errors='coerce')
        column_mappings = {
            'Quantity':       ['Quantity', 'quantity', 'qty'],
            'Item Price':     ['Item Price', 'item-price', 'item_price', 'price'],
            'Item Tax':       ['Item Tax', 'item-tax', 'item_tax', 'tax'],
            'Shipping Price': ['Shipping Price', 'shipping-price', 'shipping_price', 'shipping'],
        }
        for target_col, possible_names in column_mappings.items():
            found = False
            for col_name in possible_names:
                if col_name in df.columns:
                    df[target_col] = pd.to_numeric(df[col_name], errors='coerce').fillna(0)
                    found = True
                    break
            if not found:
                df[target_col] = 0
        df['Total Price'] = df['Item Price'] * df['Quantity']
        return df
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è orders: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_settlements():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM settlements ORDER BY "Posted Date" DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['Amount']      = pd.to_numeric(df['Amount'], errors='coerce').fillna(0.0)
        df['Quantity']    = pd.to_numeric(df['Quantity'], errors='coerce').fillna(0)
        df['Posted Date'] = pd.to_datetime(df['Posted Date'], dayfirst=True, errors='coerce')
        if 'Currency' not in df.columns:
            df['Currency'] = 'USD'
        df = df.dropna(subset=['Posted Date'])
        return df
    except Exception as e:
        st.error(f"Error loading settlements: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_sales_traffic():
    import psycopg2
    import psycopg2.extras
    db_url = DATABASE_URL
    if not db_url:
        return pd.DataFrame()
    if db_url.startswith("postgres://"):
        db_url = db_url.replace("postgres://", "postgresql://", 1)
    conn = None
    try:
        conn = psycopg2.connect(db_url, connect_timeout=10)
        cur  = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
        cur.execute("SELECT * FROM spapi.sales_traffic ORDER BY report_date DESC")
        rows    = cur.fetchall()
        columns = [desc[0] for desc in cur.description]
        cur.close()
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows, columns=columns)
        numeric_cols = [
            'sessions','page_views','units_ordered','units_ordered_b2b',
            'total_order_items','total_order_items_b2b',
            'ordered_product_sales','ordered_product_sales_b2b',
            'session_percentage','page_views_percentage',
            'buy_box_percentage','unit_session_percentage',
            'mobile_sessions','mobile_page_views',
            'browser_sessions','browser_page_views',
            'mobile_session_percentage','mobile_page_views_percentage',
            'mobile_unit_session_percentage','mobile_buy_box_percentage',
            'browser_session_percentage','browser_page_views_percentage',
            'browser_unit_session_percentage','browser_buy_box_percentage',
        ]
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df['report_date'] = pd.to_datetime(df['report_date'], errors='coerce')
        if 'created_at' in df.columns:
            created = pd.to_datetime(df['created_at'], errors='coerce').dt.normalize()
            if df['report_date'].isna().all():
                df['report_date'] = created
            elif df['report_date'].isna().any():
                mask = df['report_date'].isna()
                df.loc[mask, 'report_date'] = created[mask]
        df['report_date'] = df['report_date'].dt.normalize()
        df = df.dropna(subset=['report_date'])
        return df
    except Exception:
        return pd.DataFrame()
    finally:
        if conn:
            conn.close()


@st.cache_data(ttl=60)
def load_returns():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df_returns = pd.read_sql(text('SELECT * FROM returns ORDER BY "Return Date" DESC'), conn)
            df_orders  = pd.read_sql(text("SELECT * FROM orders"), conn)
        return df_returns, df_orders
    except Exception:
        return pd.DataFrame(), pd.DataFrame()


@st.cache_data(ttl=60)
def load_reviews():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM amazon_reviews ORDER BY review_date DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce')
        df['rating']      = pd.to_numeric(df['rating'], errors='coerce').fillna(0).astype(int)
        if 'is_verified' in df.columns:
            df['is_verified'] = df['is_verified'].astype(bool)
        if 'domain' in df.columns:
            df['domain'] = df['domain'].str.lower().str.strip()
        return df
    except Exception:
        return pd.DataFrame()


# ============================================
# HELPERS
# ============================================

def insight_card(emoji, title, text, color="#1e1e2e"):
    st.markdown(f"""
    <div style="background:{color};border-left:4px solid #4472C4;border-radius:8px;
                padding:14px 18px;margin-bottom:10px;">
        <div style="font-size:16px;font-weight:700;color:#fff;margin-bottom:4px;">{emoji} {title}</div>
        <div style="font-size:14px;color:#ccc;line-height:1.5;">{text}</div>
    </div>""", unsafe_allow_html=True)


def balanced_reviews(df, max_per_star=100):
    parts = [df[df['rating'] == s].head(max_per_star) for s in [1, 2, 3, 4, 5]]
    return pd.concat(parts, ignore_index=True) if parts else df


DOMAIN_LABELS = {
    'com':    'üá∫üá∏ USA (com)',
    'ca':     'üá®üá¶ Canada (ca)',
    'de':     'üá©üá™ Germany (de)',
    'co.uk':  'üá¨üáß UK (co.uk)',
    'it':     'üáÆüáπ Italy (it)',
    'es':     'üá™üá∏ Spain (es)',
    'fr':     'üá´üá∑ France (fr)',
    'co.jp':  'üáØüáµ Japan (co.jp)',
    'com.au': 'üá¶üá∫ Australia (com.au)',
    'com.mx': 'üá≤üáΩ Mexico (com.mx)',
    'nl':     'üá≥üá± Netherlands (nl)',
    'pl':     'üáµüá± Poland (pl)',
    'se':     'üá∏üá™ Sweden (se)',
}


# ============================================
# INSIGHT FUNCTIONS
# ============================================

def insights_sales_traffic(df_filtered, asin_stats):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    total_sessions = int(df_filtered['sessions'].sum())
    total_units    = int(df_filtered['units_ordered'].sum())
    total_revenue  = df_filtered['ordered_product_sales'].sum()
    avg_conv       = (total_units / total_sessions * 100) if total_sessions > 0 else 0
    avg_buy_box    = df_filtered['buy_box_percentage'].mean()
    mob            = df_filtered['mobile_sessions'].sum() if 'mobile_sessions' in df_filtered.columns else 0
    bro            = df_filtered['browser_sessions'].sum() if 'browser_sessions' in df_filtered.columns else 0
    mobile_pct     = (mob / (mob + bro) * 100) if (mob + bro) > 0 else 0
    avg_conv_all   = asin_stats['Conv %'].median()
    low_conv       = asin_stats[(asin_stats['Sessions'] > asin_stats['Sessions'].median()) & (asin_stats['Conv %'] < avg_conv_all)]
    low_bb         = asin_stats[asin_stats['Buy Box %'] < 80]
    rev_per_sess   = total_revenue / total_sessions if total_sessions > 0 else 0
    cols = st.columns(2)
    i = 0
    if avg_conv >= 12:   txt, em, col = f"–ö–æ–Ω–≤–µ—Ä—Å–∏—è <b>{avg_conv:.1f}%</b> ‚Äî –≤—ã—à–µ –Ω–æ—Ä–º—ã. –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–π —Ä–µ–∫–ª–∞–º—É!", "üü¢", "#0d2b1e"
    elif avg_conv >= 8:  txt, em, col = f"–ö–æ–Ω–≤–µ—Ä—Å–∏—è <b>{avg_conv:.1f}%</b> ‚Äî –≤ –Ω–æ—Ä–º–µ. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —á–µ—Ä–µ–∑ A+.", "üü°", "#2b2400"
    else:                txt, em, col = f"–ö–æ–Ω–≤–µ—Ä—Å–∏—è <b>{avg_conv:.1f}%</b> ‚Äî –Ω–∏–∂–µ –Ω–æ—Ä–º—ã. –ü—Ä–æ–≤–µ—Ä—å —Ñ–æ—Ç–æ –∏ —Ü–µ–Ω—É.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–ö–æ–Ω–≤–µ—Ä—Å–∏—è", txt, col); i+=1
    if avg_buy_box >= 95:  txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ!", "üü¢", "#0d2b1e"
    elif avg_buy_box >= 80: txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> ‚Äî –Ω–æ—Ä–º–∞. {len(low_bb)} ASIN–æ–≤ —Ç–µ—Ä—è—é—Ç.", "üü°", "#2b2400"
    else:                   txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ! –ü—Ä–æ–≤–µ—Ä—å —Ä–µ–ø—Ä–∞–π—Å–µ—Ä.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "Buy Box", txt, col); i+=1
    txt = f"<b>{mobile_pct:.0f}%</b> –º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞ {'‚Äî –Ω–æ—Ä–º–∞.' if mobile_pct >= 60 else '‚Äî –Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ ~65%.'}"
    with cols[i%2]: insight_card("üì±", "–ú–æ–±–∞–π–ª", txt, "#1a1a2e"); i+=1
    if len(low_conv) > 0:
        top = low_conv.nlargest(1,'Sessions').iloc[0]
        txt, em, col = f"<b>{len(low_conv)} ASIN–æ–≤</b> —Å –≤—ã—Å–æ–∫–∏–º —Ç—Ä–∞—Ñ–∏–∫–æ–º –∏ –Ω–∏–∑–∫–æ–π –∫–æ–Ω–≤–µ—Ä—Å–∏–µ–π. –ö—Ä–∏—Ç–∏—á–Ω—ã–π: <b>{top['ASIN']}</b>.", "üî¥", "#2b0d0d"
    else: txt, em, col = "–í—Å–µ ASIN—ã —Å –≤—ã—Å–æ–∫–∏–º —Ç—Ä–∞—Ñ–∏–∫–æ–º –∫–æ–Ω–≤–µ—Ä—Ç—è—Ç —Ö–æ—Ä–æ—à–æ!", "üü¢", "#0d2b1e"
    with cols[i%2]: insight_card(em, "–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞", txt, col); i+=1
    with cols[i%2]: insight_card("üí°", "–¶–µ–Ω–∞ —Å–µ—Å—Å–∏–∏", f"–ö–∞–∂–¥–∞—è —Å–µ—Å—Å–∏—è ‚Üí <b>${rev_per_sess:.2f}</b>. +1000 —Å–µ—Å—Å–∏–π = +${rev_per_sess*1000:,.0f}.", "#1a1a2e"); i+=1
    if not asin_stats.empty:
        top = asin_stats.nlargest(1,'Revenue').iloc[0]
        top_pct = top['Revenue']/total_revenue*100 if total_revenue > 0 else 0
        with cols[i%2]: insight_card("üèÜ", "–ì–ª–∞–≤–Ω—ã–π ASIN", f"<b>{top['ASIN']}</b> = ${top['Revenue']:,.0f} ({top_pct:.0f}%).", "#1a2b1e")


def insights_settlements(df_filtered):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    net     = df_filtered['Amount'].sum()
    gross   = df_filtered[(df_filtered['Transaction Type']=='Order')&(df_filtered['Amount']>0)]['Amount'].sum()
    fees    = df_filtered[(df_filtered['Amount']<0)&(df_filtered['Transaction Type']!='Refund')&(~df_filtered['Transaction Type'].str.lower().str.contains('other',na=False))]['Amount'].sum()
    refunds = df_filtered[df_filtered['Transaction Type']=='Refund']['Amount'].sum()
    fee_pct    = abs(fees)/gross*100 if gross>0 else 0
    refund_pct = abs(refunds)/gross*100 if gross>0 else 0
    margin_pct = net/gross*100 if gross>0 else 0
    cols = st.columns(2); i = 0
    if margin_pct >= 30:  txt, em, col = f"–ú–∞—Ä–∂–∞ <b>{margin_pct:.1f}%</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ!", "üü¢", "#0d2b1e"
    elif margin_pct >= 15: txt, em, col = f"–ú–∞—Ä–∂–∞ <b>{margin_pct:.1f}%</b> ‚Äî –Ω–æ—Ä–º–∞ –¥–ª—è FBA.", "üü°", "#2b2400"
    else:                  txt, em, col = f"–ú–∞—Ä–∂–∞ <b>{margin_pct:.1f}%</b> ‚Äî –Ω–∏–∑–∫–æ! –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∞—Å—Ö–æ–¥—ã.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–ß–∏—Å—Ç–∞—è –º–∞—Ä–∂–∞", txt, col); i+=1
    if fee_pct <= 30:  txt, em, col = f"–ö–æ–º–∏—Å—Å–∏–∏ <b>{fee_pct:.1f}%</b> ‚Äî –≤ –Ω–æ—Ä–º–µ.", "üü¢", "#0d2b1e"
    elif fee_pct <= 40: txt, em, col = f"–ö–æ–º–∏—Å—Å–∏–∏ <b>{fee_pct:.1f}%</b> ‚Äî –Ω–µ–º–Ω–æ–≥–æ –≤—ã—Å–æ–∫–æ.", "üü°", "#2b2400"
    else:               txt, em, col = f"–ö–æ–º–∏—Å—Å–∏–∏ <b>{fee_pct:.1f}%</b> ‚Äî —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–æ!", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–ù–∞–≥—Ä—É–∑–∫–∞ –∫–æ–º–∏—Å—Å–∏–π", txt, col); i+=1
    if refund_pct <= 3:  txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{refund_pct:.1f}%</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ.", "üü¢", "#0d2b1e"
    elif refund_pct <= 8: txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{refund_pct:.1f}%</b> ‚Äî —É–º–µ—Ä–µ–Ω–Ω–æ.", "üü°", "#2b2400"
    else:                 txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{refund_pct:.1f}%</b> ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ!", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–í–æ–∑–≤—Ä–∞—Ç—ã", txt, col); i+=1
    with cols[i%2]: insight_card("üí∞", "–ò—Ç–æ–≥", f"–ü—Ä–æ–¥–∞–∂–∏ <b>${gross:,.0f}</b> ‚Üí –Ω–∞ —Ä—É–∫–∏ <b>${net:,.0f}</b>. –ö–æ–º–∏—Å—Å–∏–∏: ${abs(fees):,.0f}.", "#1a1a2e")


def insights_returns(df_filtered, return_rate):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    total_val  = df_filtered['Return Value'].sum()
    top_reason = df_filtered['Reason'].value_counts().index[0] if 'Reason' in df_filtered.columns and not df_filtered.empty else None
    top_sku    = df_filtered['SKU'].value_counts().index[0] if not df_filtered.empty else None
    cols = st.columns(2); i = 0
    if return_rate <= 3:  txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{return_rate:.1f}%</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ.", "üü¢", "#0d2b1e"
    elif return_rate <= 8: txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{return_rate:.1f}%</b> ‚Äî –ø—Ä–∏–µ–º–ª–µ–º–æ.", "üü°", "#2b2400"
    else:                  txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{return_rate:.1f}%</b> ‚Äî –æ–ø–∞—Å–Ω–æ!", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–£—Ä–æ–≤–µ–Ω—å –≤–æ–∑–≤—Ä–∞—Ç–æ–≤", txt, col); i+=1
    with cols[i%2]: insight_card("üí∏", "–£—â–µ—Ä–±", f"–í–æ–∑–≤—Ä–∞—Ç—ã —Å—Ç–æ—è—Ç <b>${total_val:,.0f}</b>.", "#2b1a00"); i+=1
    if top_reason:
        with cols[i%2]: insight_card("üîç", "–ì–ª–∞–≤–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞", f"<b>¬´{top_reason}¬ª</b>", "#1a1a2e"); i+=1
    if top_sku:
        count = df_filtered['SKU'].value_counts().iloc[0]
        with cols[i%2]: insight_card("‚ö†Ô∏è", "–ü—Ä–æ–±–ª–µ–º–Ω—ã–π SKU", f"<b>{top_sku}</b> ({count} –≤–æ–∑–≤—Ä–∞—Ç–æ–≤).", "#2b0d0d")


def insights_inventory(df_filtered):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    total_val   = df_filtered['Stock Value'].sum()
    total_units = df_filtered['Available'].sum()
    avg_vel     = df_filtered['Velocity'].mean() if 'Velocity' in df_filtered.columns else 0
    top_frozen  = df_filtered.nlargest(1,'Stock Value').iloc[0] if not df_filtered.empty else None
    dead_stock  = df_filtered[df_filtered['Velocity']==0] if 'Velocity' in df_filtered.columns else pd.DataFrame()
    cols = st.columns(2); i = 0
    months = int(total_units/avg_vel/30) if avg_vel > 0 else 0
    with cols[i%2]: insight_card("üßä","–ó–∞–º–æ—Ä–æ–∑–∫–∞ –∫–∞–ø–∏—Ç–∞–ª–∞",f"–ó–∞–º–æ—Ä–æ–∂–µ–Ω–æ <b>${total_val:,.0f}</b>. –ó–∞–ø–∞—Å –Ω–∞ {months if avg_vel>0 else '‚àû'} –º–µ—Å.","#1a1a2e"); i+=1
    if top_frozen is not None:
        pct = top_frozen['Stock Value']/total_val*100 if total_val > 0 else 0
        with cols[i%2]: insight_card("üè¶","–ì–ª–∞–≤–Ω—ã–π –∞–∫—Ç–∏–≤",f"<b>{top_frozen['SKU']}</b> –¥–µ—Ä–∂–∏—Ç ${top_frozen['Stock Value']:,.0f} ({pct:.0f}%).","#1a2b1e"); i+=1
    if len(dead_stock) > 0:
        dead_val = dead_stock['Stock Value'].sum()
        with cols[i%2]: insight_card("‚ò†Ô∏è","–ú—ë—Ä—Ç–≤—ã–π —Å—Ç–æ–∫",f"<b>{len(dead_stock)} SKU</b> –±–µ–∑ –ø—Ä–æ–¥–∞–∂ ‚Äî ${dead_val:,.0f}. –†–∞—Å—Å–º–æ—Ç—Ä–∏ –ª–∏–∫–≤–∏–¥–∞—Ü–∏—é.","#2b0d0d"); i+=1
    days = int(total_units/(avg_vel*30)*30) if avg_vel > 0 else 999
    if days <= 30:   txt, em, col = f"–ó–∞–ø–∞—Å–æ–≤ –Ω–∞ <b>{days} –¥–Ω–µ–π</b> ‚Äî —Ä–∏—Å–∫ out of stock!", "üî¥", "#2b0d0d"
    elif days <= 60: txt, em, col = f"–ó–∞–ø–∞—Å–æ–≤ –Ω–∞ <b>{days} –¥–Ω–µ–π</b> ‚Äî –ø–ª–∞–Ω–∏—Ä—É–π –ø–æ—Å—Ç–∞–≤–∫—É.", "üü°", "#2b2400"
    else:            txt, em, col = f"–ó–∞–ø–∞—Å–æ–≤ –Ω–∞ <b>{days} –¥–Ω–µ–π</b> ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.", "üü¢", "#0d2b1e"
    with cols[i%2]: insight_card(em,"–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å",txt,col)


def insights_orders(df_filtered):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    total_rev    = df_filtered['Total Price'].sum()
    total_orders = df_filtered['Order ID'].nunique()
    avg_order    = total_rev/total_orders if total_orders > 0 else 0
    days         = max((df_filtered['Order Date'].max()-df_filtered['Order Date'].min()).days,1)
    rev_per_day  = total_rev/days
    top_sku      = df_filtered.groupby('SKU')['Total Price'].sum().nlargest(1)
    cols = st.columns(2); i = 0
    with cols[i%2]: insight_card("üõí","–°—Ä–µ–¥–Ω–∏–π —á–µ–∫",f"<b>${avg_order:.2f}</b>. +10% –∫ AOV = +${total_rev*0.1:,.0f}.","#1a1a2e"); i+=1
    with cols[i%2]: insight_card("üìà","–î–Ω–µ–≤–Ω–∞—è –≤—ã—Ä—É—á–∫–∞",f"<b>${rev_per_day:,.0f}/–¥–µ–Ω—å</b>. –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –º–µ—Å—è—Ü: ${rev_per_day*30:,.0f}.","#1a2b1e"); i+=1
    if not top_sku.empty:
        sku_name, sku_rev = top_sku.index[0], top_sku.iloc[0]
        pct = sku_rev/total_rev*100 if total_rev > 0 else 0
        with cols[i%2]: insight_card("‚ö°","–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è —Ä–∏—Å–∫–∞",f"<b>{sku_name}</b> = {pct:.0f}% (${sku_rev:,.0f}). –î–∏–≤–µ—Ä—Å–∏—Ñ–∏—Ü–∏—Ä—É–π.","#2b1a00")


def insights_reviews(df, asin=None):
    st.markdown("---")
    label = f"ASIN {asin}" if asin else "–≤—Å–µ–º ASIN–∞–º"
    st.markdown(f"### {t['insights_title']} –ø–æ {label}")
    total = len(df)
    if total == 0:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω—Å–∞–π—Ç–æ–≤.")
        return
    avg_rating = df['rating'].mean()
    neg_df     = df[df['rating'] <= 2]
    pos_df     = df[df['rating'] >= 4]
    neg_pct    = len(neg_df)/total*100
    pos_pct    = len(pos_df)/total*100
    cols = st.columns(2); i = 0
    if avg_rating >= 4.4:   txt, em, col = f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª <b>{avg_rating:.1f}‚òÖ</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ! –°–∏–ª—å–Ω–æ–µ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–µ –¥–æ–≤–µ—Ä–∏–µ.", "üü¢", "#0d2b1e"
    elif avg_rating >= 4.0: txt, em, col = f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª <b>{avg_rating:.1f}‚òÖ</b> ‚Äî –Ω–æ—Ä–º–∞, —Ä–∏—Å–∫ —É–ø–∞—Å—Ç—å –Ω–∏–∂–µ 4.0.", "üü°", "#2b2400"
    else:                   txt, em, col = f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª <b>{avg_rating:.1f}‚òÖ</b> ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ! –†–µ–∂–µ—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏—é –∏ —É–¥–æ—Ä–æ–∂–∞–µ—Ç PPC.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em,t["insight_rating_health"],txt,col); i+=1
    if neg_pct <= 10:  txt, em, col = f"–í—Å–µ–≥–æ <b>{neg_pct:.1f}%</b> –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö (1-2‚òÖ). –ü—Ä–æ–¥—É–∫—Ç –æ–ø—Ä–∞–≤–¥—ã–≤–∞–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è.", "üü¢", "#0d2b1e"
    elif neg_pct <= 20: txt, em, col = f"<b>{neg_pct:.1f}%</b> –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö ‚Äî —Å–∏—Å—Ç–µ–º–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞. –ß–∏—Ç–∞–π —Ç–µ–∫—Å—Ç—ã 1‚òÖ.", "üü°", "#2b2400"
    else:               txt, em, col = f"<b>{neg_pct:.1f}%</b> –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ! –°—Ä–æ—á–Ω–æ —Ñ–∏–∫—Å–∏ –ø—Ä–æ–¥—É–∫—Ç –∏–ª–∏ –ª–∏—Å—Ç–∏–Ω–≥.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em,"–£—Ä–æ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–∞",txt,col); i+=1
    with cols[i%2]: insight_card("üíö",t["insight_loyalty"],f"<b>{pos_pct:.1f}%</b> –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö (4-5‚òÖ)","#0d2b1e" if pos_pct>=70 else "#2b2400"); i+=1
    if 'is_verified' in df.columns:
        ver_pct = df['is_verified'].mean()*100
        with cols[i%2]: insight_card("‚úÖ","–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è",f"<b>{ver_pct:.1f}%</b> –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã {'‚Äî –≤—ã—Å–æ–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ —É Amazon.' if ver_pct>=80 else '‚Äî —Å–ª–µ–¥–∏ –∑–∞ –ø–æ–ª–∏—Ç–∏–∫–æ–π.'}","#1a1a2e"); i+=1
    if asin is None and not neg_df.empty and 'asin' in neg_df.columns:
        worst = neg_df['asin'].value_counts()
        if not worst.empty:
            with cols[i%2]: insight_card("‚ö†Ô∏è",t["insight_toxic"],f"<b>{worst.index[0]}</b> ‚Äî {worst.iloc[0]} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö. –ù–∞—á–Ω–∏ –∞–Ω–∞–ª–∏–∑ —Å –Ω–µ–≥–æ.","#2b0d0d")


# ============================================
# OVERVIEW CONSOLIDATED INSIGHTS
# ============================================

def show_overview_insights(df_inventory):
    st.markdown("---")
    st.markdown("## üß† Business Intelligence: –ó–≤–µ–¥–µ–Ω—ñ —ñ–Ω—Å–∞–π—Ç–∏")
    st.caption("–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –≤—Å—ñ—Ö –º–æ–¥—É–ª—ñ–≤")

    df_settlements = load_settlements()
    df_st          = load_sales_traffic()
    df_orders      = load_orders()
    df_ret_raw, df_ord_raw = load_returns()
    df_reviews     = load_reviews()

    df_returns  = pd.DataFrame()
    return_rate = 0
    if not df_ret_raw.empty:
        df_ret = df_ret_raw.copy()
        df_ret['Return Date'] = pd.to_datetime(df_ret['Return Date'], errors='coerce')
        if 'Price' not in df_ret.columns and not df_ord_raw.empty:
            for col in ['Item Price','item-price','item_price','price']:
                if col in df_ord_raw.columns:
                    df_ord_raw[col] = pd.to_numeric(df_ord_raw[col], errors='coerce')
                    df_ret['Price'] = df_ret['SKU'].map(df_ord_raw.groupby('SKU')[col].mean()).fillna(0)
                    break
        if 'Price' not in df_ret.columns: df_ret['Price'] = 0
        df_ret['Price']        = pd.to_numeric(df_ret['Price'], errors='coerce').fillna(0)
        df_ret['Quantity']     = pd.to_numeric(df_ret.get('Quantity',1), errors='coerce').fillna(1)
        df_ret['Return Value'] = df_ret['Price'] * df_ret['Quantity']
        df_returns = df_ret
        if not df_ord_raw.empty:
            for col in ['Order ID','order-id','order_id','OrderID']:
                if col in df_ord_raw.columns:
                    total_orders = df_ord_raw[col].nunique()
                    unique_ret   = df_returns['Order ID'].nunique() if 'Order ID' in df_returns.columns else 0
                    return_rate  = unique_ret/total_orders*100 if total_orders > 0 else 0
                    break

    tabs = st.tabs(["üí∞ Inventory","üè¶ Settlements","üìà Sales & Traffic","üõí Orders","üì¶ Returns","‚≠ê Reviews"])

    with tabs[0]:
        if not df_inventory.empty and 'Stock Value' in df_inventory.columns:
            insights_inventory(df_inventory)
        else: st.info("üì¶ –î–∞–Ω—ñ –ø–æ —ñ–Ω–≤–µ–Ω—Ç–∞—Ä—é –≤—ñ–¥—Å—É—Ç–Ω—ñ")

    with tabs[1]:
        if not df_settlements.empty:
            max_d  = df_settlements['Posted Date'].max()
            df_s30 = df_settlements[df_settlements['Posted Date'] >= max_d - dt.timedelta(days=30)]
            insights_settlements(df_s30 if not df_s30.empty else df_settlements)
        else: st.info("üè¶ –î–∞–Ω—ñ –ø–æ –≤–∏–ø–ª–∞—Ç–∞—Ö –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    with tabs[2]:
        if not df_st.empty:
            max_d   = df_st['report_date'].max()
            df_use  = df_st[df_st['report_date'] >= max_d - dt.timedelta(days=14)]
            df_use  = df_use if not df_use.empty else df_st
            asin_col = 'child_asin' if 'child_asin' in df_use.columns else df_use.columns[0]
            as_ = df_use.groupby(asin_col).agg({'sessions':'sum','units_ordered':'sum','ordered_product_sales':'sum','buy_box_percentage':'mean'}).reset_index()
            as_.columns = ['ASIN','Sessions','Units','Revenue','Buy Box %']
            as_['Conv %'] = (as_['Units']/as_['Sessions']*100).fillna(0)
            insights_sales_traffic(df_use, as_)
        else: st.info("üìà –î–∞–Ω—ñ Sales & Traffic –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    with tabs[3]:
        if not df_orders.empty:
            max_d  = df_orders['Order Date'].max()
            df_o30 = df_orders[df_orders['Order Date'] >= max_d - dt.timedelta(days=30)]
            insights_orders(df_o30 if not df_o30.empty else df_orders)
        else: st.info("üõí –î–∞–Ω—ñ –∑–∞–º–æ–≤–ª–µ–Ω—å –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    with tabs[4]:
        if not df_returns.empty:
            max_d  = df_returns['Return Date'].max()
            df_r30 = df_returns[df_returns['Return Date'] >= max_d - dt.timedelta(days=30)]
            insights_returns(df_r30 if not df_r30.empty else df_returns, return_rate)
        else: st.info("üì¶ –î–∞–Ω—ñ –ø–æ–≤–µ—Ä–Ω–µ–Ω—å –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    with tabs[5]:
        if not df_reviews.empty: insights_reviews(df_reviews, asin=None)
        else: st.info("‚≠ê –î–∞–Ω—ñ –≤—ñ–¥–≥—É–∫—ñ–≤ –≤—ñ–¥—Å—É—Ç–Ω—ñ.")


# ============================================
# ‚≠ê REVIEWS MODULE
# ============================================

def make_amazon_url(domain, asin):
    return f"https://www.amazon.{domain}/dp/{asin}"


def show_global_insights(df, has_domain):
    st.markdown(f"### {t['rev_auto_insights']}")

    asin_stats, dom_stats = None, None

    if 'asin' in df.columns:
        asin_stats = df.groupby('asin').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
        ).reset_index()
        asin_stats['Neg %'] = (asin_stats['Neg'] / asin_stats['Reviews'] * 100).round(1)
        asin_stats = asin_stats[asin_stats['Reviews'] >= 5]

    if has_domain and 'domain' in df.columns:
        dom_stats = df.groupby('domain').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
        ).reset_index()
        dom_stats['Neg %'] = (dom_stats['Neg'] / dom_stats['Reviews'] * 100).round(1)
        dom_stats = dom_stats[dom_stats['Reviews'] >= 5]

    col1, col2, col3, col4 = st.columns(4)

    if asin_stats is not None and not asin_stats.empty:
        worst_a = asin_stats.loc[asin_stats['Neg %'].idxmax()]
        best_a  = asin_stats.loc[asin_stats['Rating'].idxmax()]

        worst_asin_country = ""
        if has_domain and 'domain' in df.columns:
            asin_dom = df[df['asin'] == worst_a['asin']].groupby('domain')['rating'].count()
            if not asin_dom.empty:
                top_dom = asin_dom.idxmax()
                worst_asin_country = DOMAIN_LABELS.get(top_dom, top_dom)

        best_asin_country = ""
        if has_domain and 'domain' in df.columns:
            asin_dom2 = df[df['asin'] == best_a['asin']].groupby('domain')['rating'].count()
            if not asin_dom2.empty:
                top_dom2 = asin_dom2.idxmax()
                best_asin_country = DOMAIN_LABELS.get(top_dom2, top_dom2)

        neg_pct = worst_a['Neg %']
        bar_color = "#F44336" if neg_pct > 20 else "#FFC107"
        country_line = f"<div style='font-size:11px;color:#aaa;margin-top:2px'>üåç {worst_asin_country}</div>" if worst_asin_country else ""

        with col1:
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:5px solid {bar_color};border-radius:10px;padding:16px 20px;height:140px">
              <div style="font-size:11px;color:#888;margin-bottom:4px">üî¥ –ù–ê–ô–ì–Ü–†–®–ò–ô ASIN</div>
              <div style="font-size:20px;font-weight:800;color:#fff;letter-spacing:1px">{worst_a['asin']}</div>
              {country_line}
              <div style="display:flex;gap:12px;margin-top:8px;flex-wrap:wrap">
                <span style="color:#aaa;font-size:12px">‚≠ê {worst_a['Rating']:.2f}‚òÖ</span>
                <span style="color:{bar_color};font-size:12px;font-weight:700">üî¥ {neg_pct:.1f}% neg</span>
                <span style="color:#666;font-size:12px">{int(worst_a['Reviews'])} {t['rev_reviews_count']}</span>
              </div>
              <div style="margin-top:10px;background:#2a2a3e;border-radius:4px;height:5px">
                <div style="width:{min(neg_pct,100):.0f}%;background:{bar_color};border-radius:4px;height:5px"></div>
              </div>
            </div>""", unsafe_allow_html=True)

        rating_color = "#4CAF50" if best_a['Rating'] >= 4.4 else "#FFC107"
        country_line2 = f"<div style='font-size:11px;color:#aaa;margin-top:2px'>üåç {best_asin_country}</div>" if best_asin_country else ""
        with col2:
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:5px solid {rating_color};border-radius:10px;padding:16px 20px;height:140px">
              <div style="font-size:11px;color:#888;margin-bottom:4px">üü¢ –ù–ê–ô–ö–†–ê–©–ò–ô ASIN</div>
              <div style="font-size:20px;font-weight:800;color:#fff;letter-spacing:1px">{best_a['asin']}</div>
              {country_line2}
              <div style="display:flex;gap:12px;margin-top:8px;flex-wrap:wrap">
                <span style="color:{rating_color};font-size:12px;font-weight:700">‚≠ê {best_a['Rating']:.2f}‚òÖ</span>
                <span style="color:#aaa;font-size:12px">üî¥ {best_a['Neg %']:.1f}% neg</span>
                <span style="color:#666;font-size:12px">{int(best_a['Reviews'])} {t['rev_reviews_count']}</span>
              </div>
              <div style="margin-top:10px;background:#2a2a3e;border-radius:4px;height:5px">
                <div style="width:{((best_a['Rating']-1)/4*100):.0f}%;background:{rating_color};border-radius:4px;height:5px"></div>
              </div>
            </div>""", unsafe_allow_html=True)

    if dom_stats is not None and not dom_stats.empty:
        worst_d = dom_stats.loc[dom_stats['Neg %'].idxmax()]
        best_d  = dom_stats.loc[dom_stats['Rating'].idxmax()]
        worst_label = DOMAIN_LABELS.get(worst_d['domain'], worst_d['domain'])
        best_label  = DOMAIN_LABELS.get(best_d['domain'], best_d['domain'])

        worst_country_asin = ""
        if 'asin' in df.columns:
            df_wdom = df[df['domain'] == worst_d['domain']]
            if not df_wdom.empty:
                per_asin = df_wdom.groupby('asin').agg(
                    Neg=('rating', lambda x: (x<=2).sum()),
                    Reviews=('rating','count')
                ).reset_index()
                per_asin['Neg %'] = per_asin['Neg'] / per_asin['Reviews'] * 100
                per_asin = per_asin[per_asin['Reviews'] >= 3]
                if not per_asin.empty:
                    worst_country_asin = per_asin.loc[per_asin['Neg %'].idxmax(), 'asin']

        best_country_asin = ""
        if 'asin' in df.columns:
            df_bdom = df[df['domain'] == best_d['domain']]
            if not df_bdom.empty:
                per_asin2 = df_bdom.groupby('asin').agg(
                    Rating=('rating','mean'), Reviews=('rating','count')
                ).reset_index()
                per_asin2 = per_asin2[per_asin2['Reviews'] >= 3]
                if not per_asin2.empty:
                    best_country_asin = per_asin2.loc[per_asin2['Rating'].idxmax(), 'asin']

        neg_pct = worst_d['Neg %']
        bar_color = "#F44336" if neg_pct > 20 else "#FFC107"
        asin_line_w = f"<div style='font-size:11px;color:#aaa;margin-top:2px'>{t['rev_main_asin']} {worst_country_asin}</div>" if worst_country_asin else ""
        asin_line_b = f"<div style='font-size:11px;color:#aaa;margin-top:2px'>{t['rev_main_asin']} {best_country_asin}</div>" if best_country_asin else ""

        with col3:
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:5px solid {bar_color};border-radius:10px;padding:16px 20px;height:140px">
              <div style="font-size:11px;color:#888;margin-bottom:4px">üî¥ –ù–ê–ô–ì–Ü–†–®–ê –ö–†–ê–á–ù–ê</div>
              <div style="font-size:18px;font-weight:800;color:#fff">{worst_label}</div>
              {asin_line_w}
              <div style="display:flex;gap:12px;margin-top:8px;flex-wrap:wrap">
                <span style="color:#aaa;font-size:12px">‚≠ê {worst_d['Rating']:.2f}‚òÖ</span>
                <span style="color:{bar_color};font-size:12px;font-weight:700">üî¥ {neg_pct:.1f}% neg</span>
                <span style="color:#666;font-size:12px">{int(worst_d['Reviews'])} {t['rev_reviews_count']}</span>
              </div>
              <div style="margin-top:10px;background:#2a2a3e;border-radius:4px;height:5px">
                <div style="width:{min(neg_pct,100):.0f}%;background:{bar_color};border-radius:4px;height:5px"></div>
              </div>
            </div>""", unsafe_allow_html=True)

        rating_color = "#4CAF50" if best_d['Rating'] >= 4.4 else "#FFC107"
        with col4:
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:5px solid {rating_color};border-radius:10px;padding:16px 20px;height:140px">
              <div style="font-size:11px;color:#888;margin-bottom:4px">üü¢ –ù–ê–ô–ö–†–ê–©–ê –ö–†–ê–á–ù–ê</div>
              <div style="font-size:18px;font-weight:800;color:#fff">{best_label}</div>
              {asin_line_b}
              <div style="display:flex;gap:12px;margin-top:8px;flex-wrap:wrap">
                <span style="color:{rating_color};font-size:12px;font-weight:700">‚≠ê {best_d['Rating']:.2f}‚òÖ</span>
                <span style="color:#aaa;font-size:12px">üî¥ {best_d['Neg %']:.1f}% neg</span>
                <span style="color:#666;font-size:12px">{int(best_d['Reviews'])} {t['rev_reviews_count']}</span>
              </div>
              <div style="margin-top:10px;background:#2a2a3e;border-radius:4px;height:5px">
                <div style="width:{((best_d['Rating']-1)/4*100):.0f}%;background:{rating_color};border-radius:4px;height:5px"></div>
              </div>
            </div>""", unsafe_allow_html=True)


def show_single_asin_detail(df_asin, asin, has_domain):
    total = len(df_asin)
    if total == 0:
        st.info("–ù–µ–º–∞—î –≤—ñ–¥–≥—É–∫—ñ–≤ –ø–æ —Ü—å–æ–º—É ASIN.")
        return

    avg_r   = df_asin['rating'].mean()
    neg_cnt = int((df_asin['rating'] <= 2).sum())
    pos_cnt = int((df_asin['rating'] >= 4).sum())
    neg_pct = neg_cnt / total * 100

    r_color = "#4CAF50" if avg_r >= 4.4 else "#FFC107" if avg_r >= 4.0 else "#F44336"
    n_color = "#4CAF50" if neg_pct <= 10 else "#FFC107" if neg_pct <= 20 else "#F44336"

    st.markdown(f"""
    <div style="background:#1e1e2e;border-radius:12px;padding:18px 24px;margin-bottom:16px;display:flex;gap:40px;align-items:center">
      <div>
        <div style="font-size:11px;color:#888">ASIN</div>
        <div style="font-size:20px;font-weight:800;color:#fff;letter-spacing:1px">{asin}</div>
      </div>
      <div>
        <div style="font-size:11px;color:#888">–°–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥</div>
        <div style="font-size:28px;font-weight:800;color:{r_color}">{avg_r:.2f}‚òÖ</div>
      </div>
      <div>
        <div style="font-size:11px;color:#888">–í—Å—å–æ–≥–æ –≤—ñ–¥–≥—É–∫—ñ–≤</div>
        <div style="font-size:28px;font-weight:800;color:#fff">{total}</div>
      </div>
      <div>
        <div style="font-size:11px;color:#888">üî¥ –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö</div>
        <div style="font-size:28px;font-weight:800;color:{n_color}">{neg_pct:.1f}%</div>
      </div>
      <div>
        <div style="font-size:11px;color:#888">üü¢ –ü–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö</div>
        <div style="font-size:28px;font-weight:800;color:#4CAF50">{pos_cnt/total*100:.1f}%</div>
      </div>
    </div>""", unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ‚≠ê –†–æ–∑–ø–æ–¥—ñ–ª –∑—ñ—Ä–æ–∫")
        star_counts = df_asin['rating'].value_counts().reindex([5,4,3,2,1]).fillna(0).reset_index()
        star_counts.columns = ['Stars', 'Count']
        star_counts['Pct'] = (star_counts['Count'] / total * 100).round(1)
        star_counts['label'] = star_counts['Stars'].astype(str) + '‚òÖ'
        color_map = {5:'#4CAF50',4:'#8BC34A',3:'#FFC107',2:'#FF9800',1:'#F44336'}
        fig = go.Figure(go.Bar(
            x=star_counts['Count'], y=star_counts['label'], orientation='h',
            marker_color=[color_map.get(int(s),'#888') for s in star_counts['Stars']],
            text=[f"{c:.0f} ({p:.0f}%)" for c,p in zip(star_counts['Count'], star_counts['Pct'])],
            textposition='outside'
        ))
        fig.update_layout(
            yaxis=dict(categoryorder='array', categoryarray=['1‚òÖ','2‚òÖ','3‚òÖ','4‚òÖ','5‚òÖ']),
            height=260, margin=dict(l=5,r=60,t=10,b=10)
        )
        st.plotly_chart(fig, width="stretch")

    with col2:
        if has_domain and 'domain' in df_asin.columns and df_asin['domain'].nunique() > 1:
            st.markdown("#### üåç –†–µ–π—Ç–∏–Ω–≥ –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö –¥–ª—è —Ü—å–æ–≥–æ ASIN")
            dom_s = df_asin.groupby('domain').agg(
                Reviews=('rating','count'), Rating=('rating','mean'),
                Neg=('rating', lambda x: (x<=2).sum())
            ).reset_index()
            dom_s['Neg %'] = (dom_s['Neg']/dom_s['Reviews']*100).round(1)
            dom_s['Country'] = dom_s['domain'].map(lambda x: DOMAIN_LABELS.get(x, x))
            dom_s = dom_s.sort_values('Rating', ascending=True)
            colors = ['#F44336' if r<4.0 else '#FFC107' if r<4.4 else '#4CAF50' for r in dom_s['Rating']]
            fig2 = go.Figure(go.Bar(
                x=dom_s['Rating'], y=dom_s['Country'], orientation='h',
                marker_color=colors,
                text=[f"{r:.2f}‚òÖ  {n:.0f}% neg" for r,n in zip(dom_s['Rating'], dom_s['Neg %'])],
                textposition='outside'
            ))
            fig2.add_vline(x=4.0, line_dash="dash", line_color="orange")
            fig2.update_layout(height=260, xaxis_range=[1,5.8], margin=dict(l=5,r=80,t=10,b=10))
            st.plotly_chart(fig2, width="stretch")
        else:
            st.markdown("#### üìä –†–µ–π—Ç–∏–Ω–≥ –ø–æ —á–∞—Å—É")
            if 'review_date' in df_asin.columns:
                df_time = df_asin.dropna(subset=['review_date']).copy()
                df_time['month'] = df_time['review_date'].dt.to_period('M').astype(str)
                monthly = df_time.groupby('month')['rating'].mean().reset_index()
                fig_t = px.line(monthly, x='month', y='rating', markers=True)
                fig_t.add_hline(y=4.0, line_dash='dash', line_color='orange')
                fig_t.update_layout(height=260, yaxis_range=[1,5])
                st.plotly_chart(fig_t, width="stretch")

    st.markdown("#### üî¥ –û—Å—Ç–∞–Ω–Ω—ñ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ñ –≤—ñ–¥–≥—É–∫–∏ (1-2‚òÖ)")
    neg_df = df_asin[df_asin['rating'] <= 2].sort_values('review_date', ascending=False).head(5)
    if not neg_df.empty:
        for _, row in neg_df.iterrows():
            domain_str = f" ¬∑ {DOMAIN_LABELS.get(row.get('domain',''), row.get('domain',''))}" if 'domain' in neg_df.columns else ""
            date_str = str(row['review_date'])[:10] if pd.notna(row.get('review_date')) else ''
            stars = '‚òÖ' * int(row['rating']) + '‚òÜ' * (5 - int(row['rating']))
            title = row.get('title', '') or ''
            content = (row.get('content', '') or '')[:300]
            st.markdown(f"""
            <div style="background:#1e1e2e;border-left:4px solid #F44336;border-radius:8px;padding:12px 16px;margin-bottom:8px">
              <div style="display:flex;justify-content:space-between;margin-bottom:6px">
                <span style="color:#F44336;font-weight:700">{stars}</span>
                <span style="color:#666;font-size:12px">{date_str}{domain_str}</span>
              </div>
              <div style="color:#fff;font-weight:600;margin-bottom:4px">{title}</div>
              <div style="color:#aaa;font-size:13px;line-height:1.5">{content}{"..." if len(row.get("content","") or "") > 300 else ""}</div>
            </div>""", unsafe_allow_html=True)
    else:
        st.success("üéâ –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –≤—ñ–¥–≥—É–∫—ñ–≤ –Ω–µ–º–∞—î!")


def show_asin_links_table(df, has_domain):
    st.markdown("### üîó –í—Å—ñ ASIN–∏ ‚Äî –æ–≥–ª—è–¥ –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö")
    st.caption(t["rev_click_hint"])

    if 'asin' not in df.columns:
        st.info("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—Ä–æ ASIN–∏.")
        return None, None

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É –¥–∞—Ç–∏
    date_col = None
    for c in ['review_date', 'scraped_at', 'created_at', 'date']:
        if c in df.columns:
            date_col = c
            break

    if has_domain and 'domain' in df.columns:
        agg_dict = dict(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
        )
        if date_col:
            agg_dict['–û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞'] = (date_col, 'max')
        combos = df.groupby(['asin', 'domain']).agg(**agg_dict).reset_index()
        combos['Neg %'] = (combos['Neg'] / combos['Reviews'] * 100).round(1)
        combos['Country'] = combos['domain'].map(lambda x: DOMAIN_LABELS.get(x, f'üåç {x}'))
        combos['üîó Amazon'] = combos.apply(
            lambda r: f"https://www.amazon.{r['domain']}/dp/{r['asin']}", axis=1
        )
        combos = combos.sort_values(['Neg %'], ascending=False)
        cols_to_take = ['asin', 'Country', 'Reviews', 'Rating', 'Neg %']
        if date_col: cols_to_take.append('–û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞')
        cols_to_take += ['domain', 'üîó Amazon']
        table_df = combos[cols_to_take].rename(
            columns={'asin': 'ASIN', 'domain': '_domain'}
        ).reset_index(drop=True)
    else:
        agg_dict = dict(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
        )
        if date_col:
            agg_dict['–û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞'] = (date_col, 'max')
        asin_stats = df.groupby('asin').agg(**agg_dict).reset_index()
        asin_stats['Neg %'] = (asin_stats['Neg'] / asin_stats['Reviews'] * 100).round(1)
        asin_stats['üîó Amazon'] = asin_stats['asin'].apply(lambda a: f"https://www.amazon.com/dp/{a}")
        asin_stats['_domain'] = 'com'
        cols_to_take = ['asin', 'Reviews', 'Rating', 'Neg %']
        if date_col: cols_to_take.append('–û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞')
        cols_to_take += ['_domain', 'üîó Amazon']
        table_df = asin_stats[cols_to_take].rename(
            columns={'asin': 'ASIN'}
        ).reset_index(drop=True)

    table_df['Rating'] = table_df['Rating'].round(2)

    # –§–æ—Ä–º–∞—Ç—É—î–º–æ –¥–∞—Ç—É
    if '–û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞' in table_df.columns:
        table_df['–û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞'] = pd.to_datetime(table_df['–û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞'], errors='coerce').dt.strftime('%Y-%m-%d')

    st.dataframe(
        table_df.drop(columns=['_domain']),
        column_config={
            "üîó Amazon": st.column_config.LinkColumn("üîó Amazon", display_text="–í—ñ–¥–∫—Ä–∏—Ç–∏ ‚Üí"),
            "Rating": st.column_config.NumberColumn("‚≠ê Rating", format="%.2f ‚òÖ"),
            "–û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞": st.column_config.TextColumn("üìÖ –û—Å—Ç–∞–Ω–Ω—è –¥–∞—Ç–∞"),
            "Neg %": st.column_config.NumberColumn("üî¥ Neg %", format="%.1f%%"),
            "Reviews": st.column_config.NumberColumn("üìù –í—ñ–¥–≥—É–∫—ñ–≤"),
        },
        width="stretch",
        hide_index=True,
        height=min(400, 45 + len(table_df) * 35),
    )

    st.caption(t["rev_select_hint"])

    # ‚îÄ‚îÄ –§—ñ–ª—å—Ç—Ä –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö + –≤–∏–±—ñ—Ä ASIN ‚îÄ‚îÄ
    sel_col, country_col = st.columns([2, 2])

    with country_col:
        if '_domain' in table_df.columns:
            all_domains = sorted(table_df['_domain'].dropna().unique().tolist())
            domain_options = ["üåç " + t.get("all_countries", "All")] + [
                DOMAIN_LABELS.get(d, d) for d in all_domains
            ]
            sel_domain = st.selectbox("üåç –ö—Ä–∞—ó–Ω–∞:", domain_options, key="asin_jump_domain")
            # Filter table by selected domain
            if sel_domain != domain_options[0]:
                chosen_domain = all_domains[domain_options.index(sel_domain) - 1]
                filtered_for_select = table_df[table_df['_domain'] == chosen_domain]
            else:
                chosen_domain = None
                filtered_for_select = table_df
        else:
            filtered_for_select = table_df
            chosen_domain = None

    asin_list = filtered_for_select['ASIN'].unique().tolist()

    with sel_col:
        # Add country flag to each ASIN option
        def asin_label(asin):
            rows = filtered_for_select[filtered_for_select['ASIN'] == asin]
            if not rows.empty and '_domain' in rows.columns:
                dom = rows.iloc[0]['_domain']
                flag = DOMAIN_LABELS.get(dom, dom).split()[0] if dom else ""
                return f"{flag} {asin}" if flag else asin
            return asin

        asin_labels = [t["rev_not_selected"]] + [asin_label(a) for a in asin_list]
        asin_map    = {asin_label(a): a for a in asin_list}

        chosen_label = st.selectbox(t["rev_goto_asin"], asin_labels, key="asin_table_jump")

    not_selected_values = {"‚Äî –Ω–µ –≤–∏–±—Ä–∞–Ω–æ ‚Äî", "‚Äî not selected ‚Äî", "‚Äî –Ω–µ –≤—ã–±—Ä–∞–Ω–æ ‚Äî"}
    if chosen_label and chosen_label not in not_selected_values:
        chosen = asin_map.get(chosen_label, chosen_label)
        matched = table_df[table_df['ASIN'] == chosen]
        if chosen_domain:
            matched = matched[matched['_domain'] == chosen_domain]
        if matched.empty:
            matched = table_df[table_df['ASIN'] == chosen]
        if not matched.empty:
            row = matched.iloc[0]
            return chosen, row['_domain']

    return None, None


def show_reviews(t):
    df_all = load_reviews()
    if df_all.empty:
        st.warning("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–∏—Ö –ø—Ä–æ –≤—ñ–¥–≥—É–∫–∏. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ ETL-—Å–∫—Ä–∏–ø—Ç (Apify ‚Üí Postgres).")
        return

    has_domain = 'domain' in df_all.columns

    st.sidebar.markdown("---")
    st.sidebar.subheader(t["rev_filters"])

    selected_domains = []
    if has_domain:
        all_domains = sorted(df_all['domain'].dropna().unique().tolist())
        domain_display_list = [DOMAIN_LABELS.get(d, f'üåç {d}') for d in all_domains]
        display_to_code = {DOMAIN_LABELS.get(d, f'üåç {d}'): d for d in all_domains}
        sel_domain_display = st.sidebar.multiselect(
            t["rev_country_filter"], domain_display_list, default=[], key="rev_domain"
        )
        selected_domains = [display_to_code[d] for d in sel_domain_display if d in display_to_code]

    jumped_asin = st.session_state.pop('rev_asin_jump', None)

    df_for_asin = df_all.copy()
    if selected_domains:
        df_for_asin = df_for_asin[df_for_asin['domain'].isin(selected_domains)]
    asins = sorted(df_for_asin['asin'].dropna().unique().tolist()) if 'asin' in df_for_asin.columns else []
    asin_options = ['üåê –í—Å—ñ ASIN–∏'] + asins

    default_asin_idx = 0
    if jumped_asin and jumped_asin in asins:
        default_asin_idx = asin_options.index(jumped_asin)
        # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä–∏–π –∫–ª—é—á —â–æ–± index —Å–ø—Ä–∞—Ü—é–≤–∞–≤
        st.session_state.pop('rev_asin', None)

    sel_raw = st.sidebar.selectbox("üì¶ ASIN:", asin_options, index=default_asin_idx, key="rev_asin")
    selected_asin = None if sel_raw == 'üåê –í—Å—ñ ASIN–∏' else sel_raw

    star_filter = st.sidebar.multiselect(t["rev_star_filter"], [5, 4, 3, 2, 1], default=[], key="rev_stars")

    if selected_asin and has_domain:
        st.sidebar.markdown("---")
        st.sidebar.markdown("**üîó –í—ñ–¥–∫—Ä–∏—Ç–∏ –Ω–∞ Amazon:**")
        asin_domains = sorted(df_all[df_all['asin'] == selected_asin]['domain'].dropna().unique().tolist())
        for dom in asin_domains:
            url = make_amazon_url(dom, selected_asin)
            flag = DOMAIN_LABELS.get(dom, 'üåç').split(' ')[0]
            label = DOMAIN_LABELS.get(dom, dom).split('(')[0].strip()
            st.sidebar.markdown(f"[{flag} {label}]({url})")
        st.sidebar.markdown("---")
        if st.sidebar.button(t["rev_back"], width="stretch"):
            st.session_state['rev_asin_jump'] = None
            st.rerun()

    df = df_all.copy()
    if selected_domains:
        df = df[df['domain'].isin(selected_domains)]
    if selected_asin:
        df = df[df['asin'] == selected_asin]
    if star_filter:
        df = df[df['rating'].isin(star_filter)]

    if df.empty:
        st.warning("–ù–µ–º–∞—î –≤—ñ–¥–≥—É–∫—ñ–≤ –∑–∞ —Ü–∏–º–∏ —Ñ—ñ–ª—å—Ç—Ä–∞–º–∏.")
        return

    asin_label    = selected_asin if selected_asin else t["all_asins"]
    country_label = ", ".join([DOMAIN_LABELS.get(d, d) for d in selected_domains]) if selected_domains else t["all_countries"]

    # ‚îÄ‚îÄ –ö–Ω–æ–ø–∫–∞ –Ω–∞–∑–∞–¥ ‚Äî –æ–¥—Ä–∞–∑—É –ø–µ—Ä–µ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º ‚îÄ‚îÄ
    if selected_asin is not None:
        if st.button(t["rev_back"], key="back_top", type="secondary"):
            st.session_state.pop("rev_asin", None)
            st.rerun()

    if selected_asin:
        first_domain = df['domain'].dropna().iloc[0] if has_domain and not df.empty else 'com'
        amazon_url = make_amazon_url(first_domain, selected_asin)
        st.markdown(
            f"### {t['reviews_title']} ‚Äî "
            f"<a href='{amazon_url}' target='_blank' style='color:#5B9BD5'>{selected_asin} üîó</a>"
            f" | üåç {country_label}",
            unsafe_allow_html=True
        )
    else:
        st.markdown(f"### {t['reviews_title']} ‚Äî {asin_label} | üåç {country_label}")

    total_revs   = len(df)
    avg_rating   = df['rating'].mean()
    verified_pct = df['is_verified'].mean() * 100 if 'is_verified' in df.columns and total_revs > 0 else 0
    neg_count    = int((df['rating'] <= 2).sum())
    pos_count    = int((df['rating'] >= 4).sum())
    total_asins = df['asin'].nunique() if 'asin' in df.columns else 0
    total_asins_db = df_all['asin'].nunique() if 'asin' in df_all.columns else 0

    c1, c2, c3, c4, c5, c6 = st.columns(6)
    c1.metric(t["total_reviews"],     f"{total_revs:,}")
    c2.metric(t["rev_asins_in_filter"],  f"{total_asins:,}",
              delta=f"–∑ {total_asins_db} –≤ –±–∞–∑—ñ" if total_asins != total_asins_db else None,
              delta_color="off")
    c3.metric(t["avg_review_rating"], f"{avg_rating:.2f} ‚≠ê")
    c4.metric(t["verified_pct"],      f"{verified_pct:.1f}%")
    c5.metric("üî¥ –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö (1-2‚òÖ)", f"{neg_count:,}")
    c6.metric("üü¢ –ü–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö (4-5‚òÖ)", f"{pos_count:,}")

    st.markdown("---")
    show_global_insights(df_all if selected_asin is None else df, has_domain)
    st.markdown("---")

    if selected_asin is not None:
        show_single_asin_detail(df, selected_asin, has_domain)
        st.markdown("---")
        if st.button(t["rev_back"], key="back_bottom", type="secondary"):
            st.session_state.pop("rev_asin", None)
            st.rerun()

    if has_domain and selected_asin is None:
        st.markdown(f"### {t['rev_country_analysis']}")

        domain_stats = df.groupby('domain').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
            Pos=('rating', lambda x: (x >= 4).sum()),
        ).reset_index()
        domain_stats['Neg %'] = (domain_stats['Neg'] / domain_stats['Reviews'] * 100).round(1)
        domain_stats['Pos %'] = (domain_stats['Pos'] / domain_stats['Reviews'] * 100).round(1)
        domain_stats['Country'] = domain_stats['domain'].map(lambda x: DOMAIN_LABELS.get(x, f'üåç {x}'))

        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown(f"#### {t['rev_rating_by_country']}")
            ds_sort = domain_stats.sort_values('Rating', ascending=True)
            colors = ['#F44336' if r < 4.0 else '#FFC107' if r < 4.4 else '#4CAF50' for r in ds_sort['Rating']]
            fig = go.Figure(go.Bar(
                x=ds_sort['Rating'], y=ds_sort['Country'], orientation='h',
                marker_color=colors,
                text=[f"{v:.2f}‚òÖ" for v in ds_sort['Rating']], textposition='outside'
            ))
            fig.add_vline(x=4.0, line_dash="dash", line_color="orange", annotation_text="4.0")
            fig.update_layout(height=max(280, len(ds_sort) * 50), xaxis_range=[1, 5.5],
                              margin=dict(l=10, r=60, t=20, b=20))
            st.plotly_chart(fig, width="stretch")

        with col2:
            st.markdown(f"#### {t['rev_neg_by_country']}")
            ds_neg = domain_stats.sort_values('Neg %', ascending=False)
            neg_colors = ['#F44336' if v > 20 else '#FFC107' if v > 10 else '#4CAF50' for v in ds_neg['Neg %']]
            fig2 = go.Figure(go.Bar(
                x=ds_neg['Neg %'], y=ds_neg['Country'], orientation='h',
                marker_color=neg_colors,
                text=[f"{v:.1f}%" for v in ds_neg['Neg %']], textposition='outside'
            ))
            fig2.update_layout(height=max(280, len(ds_neg) * 50), margin=dict(l=10, r=60, t=20, b=20))
            st.plotly_chart(fig2, width="stretch")

        with col3:
            st.markdown(f"#### {t['rev_count_by_country']}")
            fig3 = px.pie(domain_stats, values='Reviews', names='Country', hole=0.4,
                          color_discrete_sequence=px.colors.qualitative.Set3)
            fig3.update_layout(height=max(280, len(domain_stats) * 50))
            st.plotly_chart(fig3, width="stretch")

        st.markdown(f"#### {t['rev_table_by_country']}")
        disp = domain_stats[['Country', 'Reviews', 'Rating', 'Neg %', 'Pos %']].sort_values('Rating', ascending=False)
        st.dataframe(
            disp.style
                .format({'Rating': '{:.2f}', 'Neg %': '{:.1f}%', 'Pos %': '{:.1f}%'})
                .background_gradient(subset=['Rating'], cmap='RdYlGn')
                .background_gradient(subset=['Neg %'], cmap='RdYlGn_r'),
            width="stretch"
        )

        if 'asin' in df.columns and df['domain'].nunique() > 1:
            st.markdown("---")
            st.markdown(t["rev_heatmap"])
            st.caption(t["rev_heatmap_hint"])

            pivot = df.groupby(['asin', 'domain'])['rating'].mean().reset_index()
            pivot_table = pivot.pivot(index='asin', columns='domain', values='rating')
            pivot_table.columns = [DOMAIN_LABELS.get(c, f'üåç {c}') for c in pivot_table.columns]

            fig_heat = go.Figure(data=go.Heatmap(
                z=pivot_table.values,
                x=list(pivot_table.columns),
                y=list(pivot_table.index),
                colorscale='RdYlGn',
                zmin=1, zmax=5,
                text=[[f"{v:.2f}" if not pd.isna(v) else "‚Äî" for v in row] for row in pivot_table.values],
                texttemplate="%{text}",
                colorbar=dict(title="‚òÖ –†–µ–π—Ç–∏–Ω–≥"),
            ))
            fig_heat.update_layout(
                height=max(350, len(pivot_table) * 45 + 100),
                xaxis_title="–ö—Ä–∞—ó–Ω–∞", yaxis_title="ASIN",
                margin=dict(l=20, r=20, t=30, b=20)
            )
            st.plotly_chart(fig_heat, width="stretch")
            st.caption("üü¢ ‚â•4.4‚òÖ –≤—ñ–¥–º—ñ–Ω–Ω–æ ¬∑ üü° 4.0‚Äì4.4‚òÖ –Ω–æ—Ä–º–∞ ¬∑ üî¥ <4.0‚òÖ –ø—Ä–æ–±–ª–µ–º–∞")

        st.markdown("---")

    if selected_asin is None:
        clicked_asin, clicked_domain = show_asin_links_table(df, has_domain)
        if clicked_asin:
            st.session_state['rev_asin_jump'] = clicked_asin
            st.rerun()
        st.markdown("---")

    if selected_asin is None and 'asin' in df.columns:
        st.markdown(t["rev_asin_compare"])

        asin_stats = df.groupby('asin').agg(
            Reviews=('rating', 'count'),
            Rating=('rating', 'mean'),
            Neg=('rating', lambda x: (x <= 2).sum()),
            Pos=('rating', lambda x: (x >= 4).sum()),
        ).reset_index()
        asin_stats.columns = ['ASIN', '–í—ñ–¥–≥—É–∫—ñ–≤', '–†–µ–π—Ç–∏–Ω–≥', '–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö', '–ü–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö']
        asin_stats['Neg %'] = (asin_stats['–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö'] / asin_stats['–í—ñ–¥–≥—É–∫—ñ–≤'] * 100).round(1)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### ‚≠ê –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ ASIN–∞—Ö")
            asin_sort = asin_stats.sort_values('–†–µ–π—Ç–∏–Ω–≥', ascending=True)
            colors = ['#F44336' if r < 4.0 else '#FFC107' if r < 4.4 else '#4CAF50' for r in asin_sort['–†–µ–π—Ç–∏–Ω–≥']]
            fig = go.Figure(go.Bar(
                x=asin_sort['–†–µ–π—Ç–∏–Ω–≥'], y=asin_sort['ASIN'], orientation='h',
                marker_color=colors,
                text=[f"{v:.2f}‚òÖ" for v in asin_sort['–†–µ–π—Ç–∏–Ω–≥']], textposition='outside'
            ))
            fig.add_vline(x=4.0, line_dash="dash", line_color="orange", annotation_text="–ü–æ—Ä—ñ–≥ 4.0")
            fig.update_layout(height=max(300, len(asin_sort) * 38), xaxis_range=[1, 5.5])
            st.plotly_chart(fig, width="stretch")

        with col2:
            st.markdown("#### üî¥ % –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –ø–æ ASIN–∞—Ö")
            asin_neg = asin_stats.sort_values('Neg %', ascending=False)
            neg_colors = ['#F44336' if v > 20 else '#FFC107' if v > 10 else '#4CAF50' for v in asin_neg['Neg %']]
            fig2 = go.Figure(go.Bar(
                x=asin_neg['Neg %'], y=asin_neg['ASIN'], orientation='h',
                marker_color=neg_colors,
                text=[f"{v:.1f}%" for v in asin_neg['Neg %']], textposition='outside'
            ))
            fig2.update_layout(height=max(300, len(asin_neg) * 38))
            st.plotly_chart(fig2, width="stretch")

        st.markdown("#### üìã –ó–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –ø–æ ASIN–∞—Ö")
        st.dataframe(
            asin_stats.sort_values('–†–µ–π—Ç–∏–Ω–≥').style
                .format({'–†–µ–π—Ç–∏–Ω–≥': '{:.2f}', 'Neg %': '{:.1f}%'})
                .background_gradient(subset=['–†–µ–π—Ç–∏–Ω–≥'], cmap='RdYlGn')
                .background_gradient(subset=['Neg %'], cmap='RdYlGn_r'),
            width="stretch"
        )

        if 'product_attributes' in df.columns:
            st.markdown("---")
            st.markdown("### üé® –Ø–∫—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ (Size / Color) –∑–±–∏—Ä–∞—é—Ç—å –Ω–µ–≥–∞—Ç–∏–≤?")

            df_attr = df.copy()
            df_attr['product_attributes'] = df_attr['product_attributes'].fillna('').astype(str)

            def parse_attr(s):
                size, color = None, None
                for part in s.split(','):
                    part = part.strip()
                    if part.lower().startswith('size:'):
                        size = part.split(':', 1)[1].strip()
                    elif part.lower().startswith('color:'):
                        color = part.split(':', 1)[1].strip()
                return pd.Series({'Size': size or 'N/A', 'Color': color or 'N/A'})

            parsed = df_attr['product_attributes'].apply(parse_attr)
            df_attr = pd.concat([df_attr.reset_index(drop=True), parsed], axis=1)

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### üìè –†–µ–π—Ç–∏–Ω–≥ –ø–æ Size")
                size_stats = df_attr[df_attr['Size'] != 'N/A'].groupby('Size').agg(
                    –í—ñ–¥–≥—É–∫—ñ–≤=('rating', 'count'),
                    –†–µ–π—Ç–∏–Ω–≥=('rating', 'mean'),
                    Neg=('rating', lambda x: (x <= 2).sum()),
                ).reset_index()
                size_stats['Neg %'] = (size_stats['Neg'] / size_stats['–í—ñ–¥–≥—É–∫—ñ–≤'] * 100).round(1)
                size_stats = size_stats[size_stats['–í—ñ–¥–≥—É–∫—ñ–≤'] >= 3].sort_values('–†–µ–π—Ç–∏–Ω–≥', ascending=True)
                if not size_stats.empty:
                    colors_s = ['#F44336' if r < 3.5 else '#FFC107' if r < 4.2 else '#4CAF50' for r in size_stats['–†–µ–π—Ç–∏–Ω–≥']]
                    fig_s = go.Figure(go.Bar(
                        x=size_stats['–†–µ–π—Ç–∏–Ω–≥'], y=size_stats['Size'], orientation='h',
                        marker_color=colors_s,
                        text=[f"{r:.2f}‚òÖ ({n:.0f}% neg)" for r, n in zip(size_stats['–†–µ–π—Ç–∏–Ω–≥'], size_stats['Neg %'])],
                        textposition='outside',
                    ))
                    fig_s.add_vline(x=4.0, line_dash="dash", line_color="orange")
                    fig_s.update_layout(height=max(280, len(size_stats) * 40), xaxis_range=[1, 5.8])
                    st.plotly_chart(fig_s, width="stretch")
                else:
                    st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö")

            with col2:
                st.markdown("#### üé® –†–µ–π—Ç–∏–Ω–≥ –ø–æ Color")
                color_stats = df_attr[df_attr['Color'] != 'N/A'].groupby('Color').agg(
                    –í—ñ–¥–≥—É–∫—ñ–≤=('rating', 'count'),
                    –†–µ–π—Ç–∏–Ω–≥=('rating', 'mean'),
                    Neg=('rating', lambda x: (x <= 2).sum()),
                ).reset_index()
                color_stats['Neg %'] = (color_stats['Neg'] / color_stats['–í—ñ–¥–≥—É–∫—ñ–≤'] * 100).round(1)
                color_stats = color_stats[color_stats['–í—ñ–¥–≥—É–∫—ñ–≤'] >= 3].sort_values('–†–µ–π—Ç–∏–Ω–≥', ascending=True)
                if not color_stats.empty:
                    colors_c = ['#F44336' if r < 3.5 else '#FFC107' if r < 4.2 else '#4CAF50' for r in color_stats['–†–µ–π—Ç–∏–Ω–≥']]
                    fig_c = go.Figure(go.Bar(
                        x=color_stats['–†–µ–π—Ç–∏–Ω–≥'], y=color_stats['Color'], orientation='h',
                        marker_color=colors_c,
                        text=[f"{r:.2f}‚òÖ ({n:.0f}% neg)" for r, n in zip(color_stats['–†–µ–π—Ç–∏–Ω–≥'], color_stats['Neg %'])],
                        textposition='outside',
                    ))
                    fig_c.add_vline(x=4.0, line_dash="dash", line_color="orange")
                    fig_c.update_layout(height=max(280, len(color_stats) * 40), xaxis_range=[1, 5.8])
                    st.plotly_chart(fig_c, width="stretch")
                else:
                    st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –ø–æ –∫–æ–ª—å–æ—Ä–∞—Ö")

            st.markdown("#### ‚ö†Ô∏è –¢–æ–ø –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ (—Ä–µ–π—Ç–∏–Ω–≥ < 4.0, –º—ñ–Ω. 3 –≤—ñ–¥–≥—É–∫–∏)")
            df_v = df_attr[df_attr['Size'] != 'N/A'].copy()
            group_cols = ['asin', 'Size', 'Color'] if 'asin' in df_v.columns else ['Size', 'Color']
            var_group = df_v.groupby(group_cols).agg(
                –í—ñ–¥–≥—É–∫—ñ–≤=('rating', 'count'),
                –†–µ–π—Ç–∏–Ω–≥=('rating', 'mean'),
                Neg=('rating', lambda x: (x <= 2).sum()),
            ).reset_index()
            var_group['Neg %'] = (var_group['Neg'] / var_group['–í—ñ–¥–≥—É–∫—ñ–≤'] * 100).round(1)
            problem = var_group[(var_group['–†–µ–π—Ç–∏–Ω–≥'] < 4.0) & (var_group['–í—ñ–¥–≥—É–∫—ñ–≤'] >= 3)].sort_values('Neg %', ascending=False).head(20)
            if not problem.empty:
                st.dataframe(
                    problem.style
                        .format({'–†–µ–π—Ç–∏–Ω–≥': '{:.2f}', 'Neg %': '{:.1f}%'})
                        .background_gradient(subset=['–†–µ–π—Ç–∏–Ω–≥'], cmap='RdYlGn')
                        .background_gradient(subset=['Neg %'], cmap='RdYlGn_r'),
                    width="stretch"
                )
            else:
                st.success("üéâ –í—Å—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –º–∞—é—Ç—å —Ä–µ–π—Ç–∏–Ω–≥ ‚â• 4.0")

        st.markdown("---")
        st.markdown(t["rev_star_dist"])

    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"#### {t['star_dist']}")
        star_counts = df['rating'].value_counts().reindex([5, 4, 3, 2, 1]).fillna(0).reset_index()
        star_counts.columns = ['–ó—ñ—Ä–∫–∏', '–ö—ñ–ª—å–∫—ñ—Å—Ç—å']
        star_counts['label'] = star_counts['–ó—ñ—Ä–∫–∏'].astype(str) + '‚òÖ'
        color_map = {5: '#4CAF50', 4: '#8BC34A', 3: '#FFC107', 2: '#FF9800', 1: '#F44336'}
        fig_stars = go.Figure(go.Bar(
            x=star_counts['–ö—ñ–ª—å–∫—ñ—Å—Ç—å'], y=star_counts['label'], orientation='h',
            marker_color=[color_map.get(int(s), '#888') for s in star_counts['–ó—ñ—Ä–∫–∏']],
            text=star_counts['–ö—ñ–ª—å–∫—ñ—Å—Ç—å'], textposition='outside'
        ))
        fig_stars.update_layout(
            yaxis=dict(categoryorder='array', categoryarray=['1‚òÖ', '2‚òÖ', '3‚òÖ', '4‚òÖ', '5‚òÖ']),
            height=300, margin=dict(l=10, r=40, t=20, b=20)
        )
        st.plotly_chart(fig_stars, width="stretch")

    with col2:
        st.markdown(f"#### {t['worst_asin']}")
        bad = df_all[df_all['rating'] <= 2]
        if selected_domains and has_domain:
            bad = bad[bad['domain'].isin(selected_domains)]
        if 'asin' in bad.columns and not bad.empty:
            bad_asins = bad['asin'].value_counts().head(8).reset_index()
            bad_asins.columns = ['ASIN', '–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö']
            fig_bad = px.bar(bad_asins, x='ASIN', y='–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö', text='–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö',
                             color='–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö', color_continuous_scale='Reds')
            fig_bad.update_layout(height=300, showlegend=False)
            st.plotly_chart(fig_bad, width="stretch")
        else:
            st.success("üéâ –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –≤—ñ–¥–≥—É–∫—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!")

    insights_reviews(df, asin=selected_asin)

    # ‚îÄ‚îÄ AI Chat ‚îÄ‚îÄ
    neg_examples = df[df['rating'] <= 2][['asin','domain','rating','title','content']].head(10).to_string() if not df.empty else ""
    ctx_rev = f"""Amazon Reviews –∞–Ω–∞–ª—ñ–∑:
- –í—Å—å–æ–≥–æ –≤—ñ–¥–≥—É–∫—ñ–≤: {len(df)} | –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥: {df['rating'].mean():.2f}‚òÖ
- –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö (1-2‚òÖ): {int((df['rating']<=2).sum())} | –ü–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö (4-5‚òÖ): {int((df['rating']>=4).sum())}
- ASIN: {selected_asin or '–≤—Å—ñ'} | –ö—Ä–∞—ó–Ω–∏: {', '.join(selected_domains) if selected_domains else '–≤—Å—ñ'}
–ü—Ä–∏–∫–ª–∞–¥–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –≤—ñ–¥–≥—É–∫—ñ–≤:
{neg_examples}"""
    show_ai_chat(ctx_rev, [
        "üî¥ –Ø–∫—ñ –≥–æ–ª–æ–≤–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏ –ø—Ä–æ–¥—É–∫—Ç—É –∑ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –≤—ñ–¥–≥—É–∫—ñ–≤?",
        "üí° –Ø–∫ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ —Ä–µ–π—Ç–∏–Ω–≥? –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –¥—ñ—ó",
        "üìù –ù–∞–ø–∏—à–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ø–æ–∫—É–ø—Ü—é –Ω–∞ –≥–æ–ª–æ–≤–Ω—É —Å–∫–∞—Ä–≥—É",
    ], "reviews")

    st.markdown("---")
    st.markdown(t["rev_texts"])
    st.caption(t["rev_sort_hint"])

    display_cols = ['review_date', 'asin', 'domain', 'rating', 'title', 'content', 'product_attributes', 'author', 'is_verified']

    # ‚îÄ‚îÄ –§—ñ–ª—å—Ç—Ä–∏ –Ω–∞–¥ —Ç–∞–±–ª–∏—Ü–µ—é ‚îÄ‚îÄ
    fa, fb, fc = st.columns([2, 2, 1])

    with fb:
        if has_domain:
            dl_domains_raw = sorted(df['domain'].dropna().unique().tolist())
            dl_domain_opts = ["üåç " + t.get("all_countries", "All")] + [DOMAIN_LABELS.get(d, d) for d in dl_domains_raw]
            dl_domain_label = st.selectbox("üåç –ö—Ä–∞—ó–Ω–∞:", dl_domain_opts, key="dl_domain_filter")
            dl_domain_idx = dl_domain_opts.index(dl_domain_label) - 1
            dl_domain = dl_domains_raw[dl_domain_idx] if dl_domain_idx >= 0 else None
        else:
            dl_domain = None

    with fa:
        if 'asin' in df.columns:
            df_for_asin = df[df['domain'] == dl_domain] if dl_domain else df
            asin_opts = sorted(df_for_asin['asin'].dropna().unique().tolist())
            dl_asins = ["‚úÖ " + t.get("all_asins", "All")] + asin_opts
            dl_asin = st.selectbox("üì¶ ASIN:", dl_asins, key="dl_asin_filter")
        else:
            dl_asin = None

    # ‚îÄ‚îÄ –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ñ—ñ–ª—å—Ç—Ä–∏ ‚îÄ‚îÄ
    df_dl = df.copy()
    if dl_domain:
        df_dl = df_dl[df_dl['domain'] == dl_domain]
    if dl_asin and not dl_asin.startswith("‚úÖ"):
        df_dl = df_dl[df_dl['asin'] == dl_asin]

    with fc:
        st.markdown("<div style='margin-top:28px'></div>", unsafe_allow_html=True)
        st.caption(f"üìä {len(df_dl)} –≤—ñ–¥–≥—É–∫—ñ–≤")

    # ‚îÄ‚îÄ –¢–∞–±–ª–∏—Ü—è —Ä–µ–∞–≥—É—î –Ω–∞ —Ñ—ñ–ª—å—Ç—Ä–∏ ‚îÄ‚îÄ
    df_table = balanced_reviews(df_dl, max_per_star=100).sort_values('rating', ascending=True)
    available_cols = [c for c in display_cols if c in df_table.columns]
    dl_cols = [c for c in display_cols if c in df_dl.columns]

    st.dataframe(df_table[available_cols], width="stretch", height=450)

    star_summary = df_table['rating'].value_counts().sort_index(ascending=False)
    summary_str  = " | ".join([f"{s}‚òÖ: {c}" for s, c in star_summary.items()])
    st.caption(t["rev_shown"].format(n=len(df_table), total=len(df_dl)) + f" ¬∑ {summary_str}")

    # ‚îÄ‚îÄ –ö–Ω–æ–ø–∫–∏ —Å–∫–∞—á—É–≤–∞–Ω–Ω—è ‚îÄ‚îÄ
    col1, col2 = st.columns(2)
    with col1:
        st.download_button(t["rev_dl_balanced"],
            df_table[available_cols].to_csv(index=False).encode('utf-8'),
            f"reviews_balanced_{asin_label}.csv", "text/csv")
        st.caption(t["rev_dl_balanced_hint"])
    with col2:
        st.download_button(t["rev_dl_all"],
            df_all[dl_cols].to_csv(index=False).encode('utf-8'),
            f"reviews_full_{asin_label}.csv", "text/csv")
        st.caption(t["rev_dl_all_hint"])


# ============================================
# OTHER REPORT FUNCTIONS
# ============================================


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# AI CHAT BLOCK ‚Äî –≤—Å—Ç–∞–≤–ª—è—î—Ç—å—Å—è –≤ –∫–æ–∂–µ–Ω —Ä–æ–∑–¥—ñ–ª
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def show_ai_chat(context: str, preset_questions: list, section_key: str):
    """–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π AI-—á–∞—Ç –±–ª–æ–∫ –∑ Gemini –¥–ª—è –±—É–¥—å-—è–∫–æ–≥–æ —Ä–æ–∑–¥—ñ–ª—É."""
    st.markdown("---")
    st.markdown("### ü§ñ AI –Ü–Ω—Å–∞–π—Ç–∏")

    # ‚îÄ‚îÄ –ö–ª—é—á Gemini ‚îÄ‚îÄ
    gemini_key = os.environ.get("GEMINI_API_KEY", "")
    if not gemini_key:
        gemini_key = st.secrets.get("GEMINI_API_KEY", "") if hasattr(st, "secrets") else ""
    if not gemini_key:
        st.info("üí° –î–æ–¥–∞–π GEMINI_API_KEY –≤ Streamlit Secrets —â–æ–± –∞–∫—Ç–∏–≤—É–≤–∞—Ç–∏ AI-—á–∞—Ç")
        return

    if not GEMINI_OK:
        st.warning("pip install google-generativeai")
        return

    genai.configure(api_key=gemini_key)

    # –ú–æ–¥–µ–ª—å –∑ secrets –∞–±–æ –¥–µ—Ñ–æ–ª—Ç
    gemini_model = os.environ.get("GEMINI_MODEL", "")
    if not gemini_model:
        gemini_model = st.secrets.get("GEMINI_MODEL", "gemini-2.5-flash") if hasattr(st, "secrets") else "gemini-2.5-flash"

    # ‚îÄ‚îÄ –®–≤–∏–¥–∫—ñ –∫–Ω–æ–ø–∫–∏ ‚îÄ‚îÄ
    ai_cols = st.columns(len(preset_questions))
    clicked_q = None
    for i, (col, q) in enumerate(zip(ai_cols, preset_questions)):
        if col.button(q, key=f"ai_btn_{section_key}_{i}", use_container_width=True):
            clicked_q = q

    # ‚îÄ‚îÄ –ü–æ–ª–µ –≤–≤–æ–¥—É ‚îÄ‚îÄ
    user_q = st.text_input(
        "üí¨ –ó–∞–¥–∞–π—Ç–µ –ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ –≤–∞—à—ñ –¥–∞–Ω—ñ",
        value=clicked_q or "",
        placeholder="–ß–æ–º—É –≤–ø–∞–ª–∏ –ø—Ä–æ–¥–∞–∂—ñ? –Ø–∫—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –¥–ª—è –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è?",
        key=f"ai_input_{section_key}"
    )

    if st.button("üöÄ –°–ø–∏—Ç–∞—Ç–∏ AI", key=f"ai_submit_{section_key}", type="primary"):
        if user_q:
            with st.spinner("AI –∞–Ω–∞–ª—ñ–∑—É—î –¥–∞–Ω—ñ..."):
                try:
                    model = genai.GenerativeModel(gemini_model)
                    prompt = f"""–¢–∏ ‚Äî –µ–∫—Å–ø–µ—Ä—Ç –∑ Amazon FBA –±—ñ–∑–Ω–µ—Å—É. 
–ê–Ω–∞–ª—ñ–∑—É–π —Ç—ñ–ª—å–∫–∏ –Ω–∞–¥–∞–Ω—ñ –¥–∞–Ω—ñ, –Ω–µ –≤–∏–≥–∞–¥—É–π —Ñ–∞–∫—Ç–∏.
–î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ actionable —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó.

–î–ê–ù–Ü:
{context}

–ü–ò–¢–ê–ù–ù–Ø: {user_q}

–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —Å—Ç–∏—Å–ª–æ, –ø–æ —Å—É—Ç—ñ, –∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–º–∏ —á–∏—Å–ª–∞–º–∏ –∑ –¥–∞–Ω–∏—Ö."""
                    response = model.generate_content(prompt)
                    st.markdown("#### üß† –í—ñ–¥–ø–æ–≤—ñ–¥—å AI:")
                    st.markdown(response.text)
                except Exception as e:
                    st.error(f"–ü–æ–º–∏–ª–∫–∞ Gemini: {e}")
        else:
            st.warning("–í–≤–µ–¥—ñ—Ç—å –ø–∏—Ç–∞–Ω–Ω—è")



def show_about():
    st.markdown("""
<style>
/* –ê–¥–∞–ø—Ç–∏–≤–Ω—ñ –∫–æ–ª—å–æ—Ä–∏ –¥–ª—è —Å–≤—ñ—Ç–ª–æ—ó —ñ —Ç–µ–º–Ω–æ—ó —Ç–µ–º–∏ */
:root {
  --ab-bg: #f8fafc;
  --ab-border: #e2e8f0;
  --ab-text: #1e293b;
  --ab-muted: #64748b;
  --ab-accent: #d97706;
  --ab-card: #ffffff;
}
@media (prefers-color-scheme: dark) {
  :root { --ab-bg:#0f1218; --ab-border:#1e2330; --ab-text:#e2e8f0; --ab-muted:#64748b; --ab-accent:#e8b84b; --ab-card:#161b24; }
}
[data-theme="dark"] {
  --ab-bg:#0f1218; --ab-border:#1e2330; --ab-text:#e2e8f0; --ab-muted:#64748b; --ab-accent:#e8b84b; --ab-card:#161b24;
}

.about-grid { display:grid; grid-template-columns:repeat(4,1fr); gap:1px; background:var(--ab-border); border:1px solid var(--ab-border); margin:24px 0; }
.about-stat { background:var(--ab-card); padding:20px; text-align:center; }
.about-stat-num { font-size:28px; font-weight:800; color:var(--ab-accent); font-family:monospace; }
.about-stat-lbl { font-size:11px; color:var(--ab-muted); text-transform:uppercase; letter-spacing:1px; margin-top:4px; }
.module-grid { display:grid; grid-template-columns:repeat(3,1fr); gap:12px; margin:16px 0 32px; }
.mod { background:var(--ab-card); border:1px solid var(--ab-border); border-top:3px solid var(--c,#e8b84b); padding:16px; border-radius:4px; }
.mod-icon { font-size:20px; margin-bottom:8px; }
.mod-name { font-size:13px; font-weight:700; margin-bottom:4px; color:var(--ab-text); }
.mod-desc { font-size:12px; color:var(--ab-muted); line-height:1.5; }
.pipe { display:flex; align-items:center; flex-wrap:wrap; gap:4px; margin:16px 0 32px; }
.pipe-step { background:var(--ab-card); border:1px solid var(--ab-border); padding:8px 14px; font-size:12px; font-family:monospace; color:var(--ab-text); border-radius:3px; }
.pipe-arr { color:var(--ab-accent); padding:0 4px; font-weight:bold; }
</style>
""", unsafe_allow_html=True)

    st.markdown(t["about_title"])
    st.caption(t["about_caption"])
    st.markdown("---")

    # Stats
    st.markdown("""
<div class="about-grid">
  <div class="about-stat"><div class="about-stat-num">30+</div><div class="about-stat-lbl">–¢–∏–ø—ñ–≤ –∑–≤—ñ—Ç—ñ–≤</div></div>
  <div class="about-stat"><div class="about-stat-num">36√ó</div><div class="about-stat-lbl">–û–Ω–æ–≤–ª–µ–Ω—å/–¥–µ–Ω—å</div></div>
  <div class="about-stat"><div class="about-stat-num">9</div><div class="about-stat-lbl">–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ñ–≤</div></div>
  <div class="about-stat"><div class="about-stat-num">3</div><div class="about-stat-lbl">–ú–æ–≤–∏ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É</div></div>
</div>""", unsafe_allow_html=True)

    # Modules
    st.markdown(t["about_modules"])
    st.markdown("""
<div class="module-grid">
  <div class="mod" style="--c:#5b9bd5"><div class="mod-icon">üìà</div><div class="mod-name">Sales & Traffic</div><div class="mod-desc">–°–µ—Å—ñ—ó, –∫–æ–Ω–≤–µ—Ä—Å—ñ—è, Buy Box, –¥–æ—Ö—ñ–¥ –ø–æ ASIN —ñ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—É —â–æ–¥–Ω—è</div></div>
  <div class="mod" style="--c:#e8b84b"><div class="mod-icon">‚≠ê</div><div class="mod-name">Amazon Reviews</div><div class="mod-desc">2500+ –≤—ñ–¥–≥—É–∫—ñ–≤, –∞–Ω–∞–ª—ñ–∑ –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö, –Ω–µ–≥–∞—Ç–∏–≤, AI-–∞–Ω–∞–ª—ñ–∑ –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–¥—É–∫—Ç—É</div></div>
  <div class="mod" style="--c:#4caf82"><div class="mod-icon">üí∞</div><div class="mod-name">Settlements</div><div class="mod-desc">Net Payout, –∫–æ–º—ñ—Å—ñ—ó Amazon, —Ä–µ—Ñ–∞–Ω–¥–∏, P&L –ø–æ –≤–∞–ª—é—Ç–∞—Ö —ñ –¥–∞—Ç–∞—Ö</div></div>
  <div class="mod" style="--c:#e05252"><div class="mod-icon">üì¶</div><div class="mod-name">Inventory Health</div><div class="mod-desc">–ó–∞–ª–∏—à–∫–∏, velocity, aging-–∞–Ω–∞–ª—ñ–∑, –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ñ –∫–æ—à—Ç–∏ –ø–æ SKU</div></div>
  <div class="mod" style="--c:#a78bfa"><div class="mod-icon">üõí</div><div class="mod-name">Orders Analytics</div><div class="mod-desc">–¢—Ä–µ–Ω–¥–∏ –∑–∞–º–æ–≤–ª–µ–Ω—å, —Ç–æ–ø SKU, —Å–µ–∑–æ–Ω–Ω—ñ—Å—Ç—å, –¥–∏–Ω–∞–º—ñ–∫–∞ –ø—Ä–æ–¥–∞–∂—ñ–≤</div></div>
  <div class="mod" style="--c:#f97316"><div class="mod-icon">ü§ñ</div><div class="mod-name">AI Insights</div><div class="mod-desc">Gemini AI –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É –∫–æ–∂–Ω–æ–º—É —Ä–æ–∑–¥—ñ–ª—ñ</div></div>
</div>""", unsafe_allow_html=True)

    # Pipeline
    st.markdown(t["about_pipeline"])
    st.markdown("""
<div class="pipe">
  <span class="pipe-step">Amazon SP-API</span><span class="pipe-arr">‚Üí</span>
  <span class="pipe-step">12 ETL Loaders</span><span class="pipe-arr">‚Üí</span>
  <span class="pipe-step">PostgreSQL</span><span class="pipe-arr">‚Üí</span>
  <span class="pipe-step">Streamlit Cloud</span><span class="pipe-arr">‚Üí</span>
  <span class="pipe-step">Gemini AI</span><span class="pipe-arr">‚Üí</span>
  <span class="pipe-step">Insights & Actions</span>
</div>""", unsafe_allow_html=True)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown(t["about_features"])
        st.markdown("""
- –†–æ–ª–µ–≤–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è: admin / user –∑ –ø—Ä–∞–≤–∞–º–∏ –ø–æ –∑–≤—ñ—Ç–∞—Ö  
- –ú—É–ª—å—Ç–∏–º–æ–≤–Ω—ñ—Å—Ç—å: üá∫üá¶ UA / üá∫üá∏ EN / üåç RU  
- –§—ñ–ª—å—Ç—Ä–∏ ASIN √ó –ö—Ä–∞—ó–Ω–∞ —É –≤—Å—ñ—Ö —Ä–æ–∑–¥—ñ–ª–∞—Ö  
- CSV-–µ–∫—Å–ø–æ—Ä—Ç: balanced –≤–∏–±—ñ—Ä–∫–∞ –∞–±–æ –ø–æ–≤–Ω–∏–π –¥–∞–º–ø –ë–î  
- –î–∞—Ç–∞ –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –∑–±–æ—Ä—É –≤—ñ–¥–≥—É–∫—ñ–≤ –ø–æ –∫–æ–∂–Ω–æ–º—É ASIN  
""")
    with col2:
        st.markdown(t["about_stack"])
        st.markdown("""
- **Backend**: Python, PostgreSQL, SQLAlchemy  
- **Frontend**: Streamlit, Plotly  
- **APIs**: Amazon SP-API, Advertising API, Apify  
- **AI**: Google Gemini 1.5 Flash  
- **Deploy**: Streamlit Cloud  
""")

    st.markdown("---")
    st.caption(t["about_footer"])


def show_overview(df_filtered, t, selected_date):
    st.markdown(f"### {t['ov_title']}")
    st.caption(f"Data snapshot: {selected_date}")
    col1,col2,col3,col4 = st.columns(4)
    with col1: st.metric(t["total_sku"], len(df_filtered))
    with col2: st.metric(t["total_avail"], f"{int(df_filtered['Available'].sum()):,}")
    with col3: st.metric(t["total_value"], f"${df_filtered['Stock Value'].sum():,.0f}")
    with col4: st.metric(t["velocity_30"], f"{int(df_filtered['Velocity'].sum()*30):,} units")
    st.markdown("---")
    col1,col2,col3,col4 = st.columns(4)
    btns = [
        (col1, f"#### {t['settlements_title']}", "Payouts, Net Profit, Fees", "üè¶ View Finance ‚Üí","btn_s","üè¶ Settlements (Payouts)"),
        (col2, "#### üìà Sales & Traffic","Sessions, Conversions, Buy Box","üìà View Traffic ‚Üí","btn_st","üìà Sales & Traffic"),
        (col3, "#### üõí Orders Analytics","Sales Trends, Top Products","üìä View Orders ‚Üí","btn_o","üõí Orders Analytics"),
        (col4, "#### üì¶ Returns Analytics","Return rates, Problem SKUs","üì¶ View Returns ‚Üí","btn_r","üì¶ Returns Analytics"),
    ]
    for c,hdr,sub,btn_lbl,key,dest in btns:
        with c:
            with st.container(border=True):
                st.markdown(hdr); st.markdown(sub)
                if st.button(btn_lbl, key=key, width="stretch", type="primary"):
                    st.session_state.report_choice = dest; st.rerun()
    st.markdown("")
    col1,col2,col3,col4 = st.columns(4)
    btns2 = [
        (col1,"#### üí∞ Inventory Value","Money map, Pricing","üí∞ View Inventory ‚Üí","btn_f","üí∞ Inventory Value (CFO)"),
        (col2,"#### üß† AI Forecast","Sold-out predictions","üß† View AI Forecast ‚Üí","btn_a","üß† AI Forecast"),
        (col3,"#### üê¢ Inventory Health","Aging analysis","üê¢ View Health ‚Üí","btn_h","üê¢ Inventory Health (Aging)"),
        (col4,"#### ‚≠ê Amazon Reviews","Ratings, problem ASINs","‚≠ê View Reviews ‚Üí","btn_rev","‚≠ê Amazon Reviews"),
    ]
    for c,hdr,sub,btn_lbl,key,dest in btns2:
        with c:
            with st.container(border=True):
                st.markdown(hdr); st.markdown(sub)
                if st.button(btn_lbl, key=key, width="stretch", type="primary"):
                    st.session_state.report_choice = dest; st.rerun()
    st.markdown("---")
    st.markdown(t["ov_top_sku"])
    if not df_filtered.empty:
        df_top = df_filtered.nlargest(15,'Available')
        fig = px.bar(df_top, x='Available', y='SKU', orientation='h',
                     text='Available', color='Available', color_continuous_scale='Blues')
        fig.update_layout(yaxis={'categoryorder':'total ascending'}, height=400)
        st.plotly_chart(fig, width="stretch")
    show_overview_insights(df_filtered)


def show_sales_traffic(t):
    df_st = load_sales_traffic()
    if df_st.empty:
        st.warning("‚ö†Ô∏è No Sales & Traffic data found."); return
    st.sidebar.markdown("---"); st.sidebar.subheader(t["st_filters"])
    min_date = df_st['report_date'].min().date()
    max_date = df_st['report_date'].max().date()
    date_range = st.sidebar.date_input(t["st_date_range"],
        value=(max(min_date, max_date-dt.timedelta(days=14)), max_date),
        min_value=min_date, max_value=max_date, key="st_date_range")
    if len(date_range)==2:
        mask = (df_st['report_date'].dt.date>=date_range[0])&(df_st['report_date'].dt.date<=date_range[1])
        df_filtered = df_st[mask]
    else:
        df_filtered = df_st
    if df_filtered.empty:
        st.warning("No data for selected period"); return
    st.markdown(f"### {t['sales_traffic_title']}")
    ts = int(df_filtered['sessions'].sum()); tpv = int(df_filtered['page_views'].sum())
    tu = int(df_filtered['units_ordered'].sum()); tr = df_filtered['ordered_product_sales'].sum()
    ac = tu/ts*100 if ts>0 else 0; ab = df_filtered['buy_box_percentage'].mean()
    c1,c2,c3,c4,c5,c6 = st.columns(6)
    c1.metric(t["st_sessions"],f"{ts:,}"); c2.metric(t["st_page_views"],f"{tpv:,}")
    c3.metric(t["st_units"],f"{tu:,}"); c4.metric(t["st_revenue"],f"${tr:,.2f}")
    c5.metric(t["st_conversion"],f"{ac:.2f}%"); c6.metric(t["st_buy_box"],f"{ab:.1f}%")
    st.markdown("---"); st.markdown(t["st_daily_trends"])
    daily = df_filtered.groupby(df_filtered['report_date'].dt.date).agg(
        {'sessions':'sum','page_views':'sum','units_ordered':'sum','ordered_product_sales':'sum'}).reset_index()
    daily.columns = ['Date','Sessions','Page Views','Units','Revenue']
    daily['Conversion %'] = (daily['Units']/daily['Sessions']*100).fillna(0)
    col1,col2 = st.columns(2)
    with col1:
        st.markdown(t["st_sessions_views"])
        fig = go.Figure()
        fig.add_trace(go.Bar(x=daily['Date'],y=daily['Sessions'],name='Sessions',marker_color='#4472C4'))
        fig.add_trace(go.Scatter(x=daily['Date'],y=daily['Page Views'],name='Page Views',mode='lines+markers',line=dict(color='#ED7D31',width=2),yaxis='y2'))
        fig.update_layout(yaxis=dict(title='Sessions'),yaxis2=dict(title='Page Views',overlaying='y',side='right'),height=380,legend=dict(orientation='h',y=1.12))
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.markdown(t["st_revenue_units"])
        fig = go.Figure()
        fig.add_trace(go.Bar(x=daily['Date'],y=daily['Revenue'],name='Revenue $',marker_color='#70AD47'))
        fig.add_trace(go.Scatter(x=daily['Date'],y=daily['Units'],name='Units',mode='lines+markers',line=dict(color='#FFC000',width=2),yaxis='y2'))
        fig.update_layout(yaxis=dict(title='Revenue $'),yaxis2=dict(title='Units',overlaying='y',side='right'),height=380,legend=dict(orientation='h',y=1.12))
        st.plotly_chart(fig, width="stretch")
    fig_conv = go.Figure(go.Scatter(x=daily['Date'],y=daily['Conversion %'],mode='lines+markers+text',
        text=[f"{v:.1f}%" for v in daily['Conversion %']],textposition='top center',line=dict(color='#5B9BD5',width=3),marker=dict(size=8)))
    fig_conv.update_layout(height=300,yaxis_title='Conversion %')
    st.plotly_chart(fig_conv, width="stretch")
    st.markdown("---"); st.markdown(t["st_top_asins"])
    asin_col = 'child_asin' if 'child_asin' in df_filtered.columns else df_filtered.columns[0]
    as_ = df_filtered.groupby(asin_col).agg({'sessions':'sum','page_views':'sum','units_ordered':'sum','ordered_product_sales':'sum','buy_box_percentage':'mean'}).reset_index()
    as_.columns=['ASIN','Sessions','Page Views','Units','Revenue','Buy Box %']
    as_['Conv %'] = (as_['Units']/as_['Sessions']*100).fillna(0)
    col1,col2 = st.columns(2)
    with col1:
        st.markdown(t["st_top_revenue"])
        fig = px.bar(as_.nlargest(15,'Revenue'),x='Revenue',y='ASIN',orientation='h',text='Revenue',color='Revenue',color_continuous_scale='Greens')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450); fig.update_traces(texttemplate='$%{text:,.0f}',textposition='outside')
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.markdown(t["st_top_sessions"])
        fig = px.bar(as_.nlargest(15,'Sessions'),x='Sessions',y='ASIN',orientation='h',text='Sessions',color='Sessions',color_continuous_scale='Blues')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450)
        st.plotly_chart(fig, width="stretch")
    st.markdown("---"); st.markdown(t["st_full_data"])
    st.dataframe(as_.sort_values('Revenue',ascending=False).style.format({'Revenue':'${:,.2f}','Conv %':'{:.2f}%','Buy Box %':'{:.1f}%'}),width="stretch",height=500)
    csv = as_.to_csv(index=False).encode('utf-8')
    st.download_button(t["st_download"], csv, "sales_traffic.csv","text/csv")
    insights_sales_traffic(df_filtered, as_)

    # ‚îÄ‚îÄ AI Chat ‚îÄ‚îÄ
    ctx = f"""Sales & Traffic –∑–∞ –æ–±—Ä–∞–Ω–∏–π –ø–µ—Ä—ñ–æ–¥:
- –°–µ—Å—ñ—ó: {ts:,} | –ü–µ—Ä–µ–≥–ª—è–¥–∏: {tpv:,} | –ó–∞–º–æ–≤–ª–µ–Ω–Ω—è: {tu:,}
- –î–æ—Ö—ñ–¥: ${tr:,.2f} | –ö–æ–Ω–≤–µ—Ä—Å—ñ—è: {ac:.2f}% | Buy Box: {ab:.1f}%
- –¢–æ–ø ASIN –∑–∞ –¥–æ—Ö–æ–¥–æ–º: {as_.nlargest(3,'Revenue')[['ASIN','Revenue','Conv %']].to_string()}"""
    show_ai_chat(ctx, [
        "üìà –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ç—Ä–µ–Ω–¥–∏ –ø—Ä–æ–¥–∞–∂—ñ–≤ —ñ –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º",
        "üèÜ –Ø–∫—ñ ASIN –ø–æ–∫–∞–∑—É—é—Ç—å –Ω–∏–∑—å–∫–∏–π Buy Box —ñ —â–æ —Ä–æ–±–∏—Ç–∏?",
        "üéØ –î–µ –Ω–∞–π–≤–∏—â–∏–π CVR —ñ —á–æ–º—É? –î–∞–π –ø–æ—Ä–∞–¥–∏ –¥–ª—è —ñ–Ω—à–∏—Ö",
    ], "sales_traffic")


def show_settlements(t):
    df_settlements = load_settlements()
    if df_settlements.empty:
        st.warning("‚ö†Ô∏è No settlement data found."); return
    st.sidebar.markdown("---"); st.sidebar.subheader("üí∞ Settlement Filters")
    currencies = ['All'] + sorted(df_settlements['Currency'].dropna().unique().tolist())
    sel_cur = st.sidebar.selectbox(t["currency_select"], currencies, index=1 if "USD" in currencies else 0)
    min_date = df_settlements['Posted Date'].min().date()
    max_date = df_settlements['Posted Date'].max().date()
    date_range = st.sidebar.date_input("üìÖ Transaction Date:",value=(max_date-dt.timedelta(days=30),max_date),min_value=min_date,max_value=max_date)
    df_f = df_settlements.copy()
    if sel_cur != 'All': df_f = df_f[df_f['Currency']==sel_cur]
    if len(date_range)==2:
        df_f = df_f[(df_f['Posted Date'].dt.date>=date_range[0])&(df_f['Posted Date'].dt.date<=date_range[1])]
    if df_f.empty:
        st.warning("No data for selected filters"); return
    st.markdown(f"### {t['settlements_title']}")
    net = df_f['Amount'].sum()
    gross = df_f[(df_f['Transaction Type']=='Order')&(df_f['Amount']>0)]['Amount'].sum()
    refunds = df_f[df_f['Transaction Type']=='Refund']['Amount'].sum()
    fees = df_f[(df_f['Amount']<0)&(df_f['Transaction Type']!='Refund')]['Amount'].sum()
    sym = "$" if sel_cur in ['USD','CAD','All'] else ""
    c1,c2,c3,c4 = st.columns(4)
    c1.metric(t['net_payout'],f"{sym}{net:,.2f}"); c2.metric(t['gross_sales'],f"{sym}{gross:,.2f}")
    c3.metric(t['total_refunds'],f"{sym}{refunds:,.2f}"); c4.metric(t['total_fees'],f"{sym}{fees:,.2f}")
    st.markdown("---")
    col1,col2 = st.columns([2,1])
    with col1:
        st.subheader(t['chart_payout_trend'])
        dt_ = df_f.groupby(df_f['Posted Date'].dt.date)['Amount'].sum().reset_index()
        dt_.columns=['Date','Net Amount']
        fig = go.Figure(go.Bar(x=dt_['Date'],y=dt_['Net Amount'],marker_color=dt_['Net Amount'].apply(lambda x:'green' if x>=0 else 'red')))
        fig.update_layout(height=400,yaxis_title=f"Net Amount ({sel_cur})")
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.subheader(t['chart_fee_breakdown'])
        df_costs = df_f[df_f['Amount']<0]
        if not df_costs.empty:
            cb = df_costs.groupby('Transaction Type')['Amount'].sum().abs().reset_index()
            fig = px.pie(cb,values='Amount',names='Transaction Type',hole=0.4)
            fig.update_layout(height=400)
            st.plotly_chart(fig, width="stretch")
        else: st.info("No costs in selected period")
    disp = ['Posted Date','Transaction Type','Order ID','Amount','Currency','Description']
    st.dataframe(df_f[[c for c in disp if c in df_f.columns]].sort_values('Posted Date',ascending=False).head(100),width="stretch")
    insights_settlements(df_f)

    # ‚îÄ‚îÄ AI Chat ‚îÄ‚îÄ
    ctx_set = f"""Settlement —Ñ—ñ–Ω–∞–Ω—Å–∏:
- Net Payout: {sym}{net:,.2f} | Gross Sales: {sym}{gross:,.2f}
- Refunds: {sym}{refunds:,.2f} | Fees: {sym}{fees:,.2f}
- –í–∞–ª—é—Ç–∞: {sel_cur} | –ö–æ–º—ñ—Å—ñ—è: {abs(fees)/gross*100:.1f}% –≤—ñ–¥ –ø—Ä–æ–¥–∞–∂—ñ–≤"""
    show_ai_chat(ctx_set, [
        "üí∞ –Ø–∫ –∑–Ω–∏–∑–∏—Ç–∏ –∫–æ–º—ñ—Å—ñ—ó Amazon —ñ –∑–±—ñ–ª—å—à–∏—Ç–∏ net payout?",
        "üìä –ß–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–∏–π —Ä—ñ–≤–µ–Ω—å —Ä–µ—Ñ–∞–Ω–¥—ñ–≤? –©–æ —Ä–æ–±–∏—Ç–∏?",
        "üéØ –î–µ –Ω–∞–π–±—ñ–ª—å—à—ñ –≤–∏—Ç—Ä–∞—Ç–∏ —ñ —è–∫ —ó—Ö –æ–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏?",
    ], "settlements")


def show_returns(t=None):
    if t is None: t = translations.get("UA", {})
    df_ret_raw, df_orders = load_returns()
    if df_ret_raw.empty:
        st.warning("‚ö†Ô∏è No returns data."); return
    df_r = df_ret_raw.copy()
    df_r['Return Date'] = pd.to_datetime(df_r['Return Date'], errors='coerce')
    if 'Price' not in df_r.columns and not df_orders.empty:
        try:
            for col in ['Item Price','item-price','item_price','price','Price']:
                if col in df_orders.columns:
                    df_orders[col] = pd.to_numeric(df_orders[col],errors='coerce')
                    df_r['Price'] = df_r['SKU'].map(df_orders.groupby('SKU')[col].mean()).fillna(0)
                    break
        except: df_r['Price'] = 0
    elif 'Price' not in df_r.columns: df_r['Price'] = 0
    df_r['Price']        = pd.to_numeric(df_r['Price'],errors='coerce').fillna(0)
    df_r['Quantity']     = pd.to_numeric(df_r['Quantity'],errors='coerce').fillna(1)
    df_r['Return Value'] = df_r['Price'] * df_r['Quantity']
    st.sidebar.markdown("---"); st.sidebar.subheader(t["ret_filters"])
    min_date = df_r['Return Date'].min().date(); max_date = df_r['Return Date'].max().date()
    date_range = st.sidebar.date_input(t["ret_date"],value=(max_date-dt.timedelta(days=30),max_date),min_value=min_date,max_value=max_date)
    sel_store = 'All'
    if 'Store Name' in df_r.columns:
        stores = ['All'] + sorted(df_r['Store Name'].dropna().unique().tolist())
        sel_store = st.sidebar.selectbox("üè™ Store:", stores)
    df_f = df_r[(df_r['Return Date'].dt.date>=date_range[0])&(df_r['Return Date'].dt.date<=date_range[1])] if len(date_range)==2 else df_r
    if sel_store != 'All': df_f = df_f[df_f['Store Name']==sel_store]
    st.markdown(t["ret_title"])
    rr = 0
    try:
        if not df_orders.empty:
            for col in ['Order ID','order-id','order_id','OrderID']:
                if col in df_orders.columns:
                    rr = df_f['Order ID'].nunique()/df_orders[col].nunique()*100 if df_orders[col].nunique()>0 else 0
                    break
    except: pass
    c1,c2,c3,c4,c5 = st.columns(5)
    c1.metric(t["ret_total"],f"{len(df_f):,}"); c2.metric(t["ret_unique_sku"],df_f['SKU'].nunique())
    c3.metric(t["ret_rate"],f"{rr:.1f}%"); c4.metric(t["ret_value"],f"${df_f['Return Value'].sum():,.2f}")
    c5.metric(t["ret_avg"],f"${df_f['Return Value'].mean():.2f}")
    st.markdown("---")
    col1,col2,col3 = st.columns(3)
    with col1:
        st.markdown(t["ret_by_sku"])
        tv = df_f.groupby('SKU')['Return Value'].sum().nlargest(10).reset_index()
        fig = px.bar(tv,x='Return Value',y='SKU',orientation='h',text='Return Value',color='Return Value',color_continuous_scale='Reds')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=350); fig.update_traces(texttemplate='$%{text:,.0f}',textposition='outside')
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.markdown(t["ret_daily"])
        dv = df_f.groupby(df_f['Return Date'].dt.date)['Return Value'].sum().reset_index(); dv.columns=['Date','Value']
        fig = px.area(dv,x='Date',y='Value',line_shape='spline',color_discrete_sequence=['#FF6B6B'])
        fig.update_layout(height=350); st.plotly_chart(fig, width="stretch")
    with col3:
        if 'Reason' in df_f.columns:
            st.markdown(t["ret_by_reason"])
            rv = df_f.groupby('Reason')['Return Value'].sum().nlargest(8).reset_index()
            fig = px.pie(rv,values='Return Value',names='Reason',hole=0.4,color_discrete_sequence=px.colors.sequential.RdBu)
            fig.update_layout(height=350); st.plotly_chart(fig, width="stretch")
    st.markdown("---")
    col1,col2 = st.columns(2)
    with col1:
        st.markdown(t["ret_top_sku"])
        ts = df_f['SKU'].value_counts().head(15).reset_index(); ts.columns=['SKU','Returns']
        fig = px.bar(ts,x='Returns',y='SKU',orientation='h',color='Returns',color_continuous_scale='Oranges',text='Returns')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450); st.plotly_chart(fig, width="stretch")
    with col2:
        if 'Reason' in df_f.columns:
            st.markdown(t["ret_reasons"])
            rs = df_f['Reason'].value_counts().head(10).reset_index(); rs.columns=['Reason','Count']
            fig = px.pie(rs,values='Count',names='Reason',hole=0.4,color_discrete_sequence=px.colors.sequential.RdBu)
            fig.update_layout(height=450); st.plotly_chart(fig, width="stretch")
    st.markdown("---")
    dc = ['Return Date','SKU','Product Name','Quantity','Price','Return Value','Reason','Status']
    st.dataframe(df_f[[c for c in dc if c in df_f.columns]].sort_values('Return Date',ascending=False).head(100).style.format({'Price':'${:.2f}','Return Value':'${:.2f}'}),width="stretch")
    st.download_button(t["ret_download"],df_f.to_csv(index=False).encode('utf-8'),"returns.csv","text/csv")
    insights_returns(df_f, rr)

    # ‚îÄ‚îÄ AI Chat ‚îÄ‚îÄ
    top_ret = df_f['SKU'].value_counts().head(5).to_string() if not df_f.empty else ""
    ctx_ret = f"""Returns –∞–Ω–∞–ª—ñ–∑:
- –í—Å—å–æ–≥–æ –ø–æ–≤–µ—Ä–Ω–µ–Ω—å: {len(df_f)} | Return Rate: {rr:.1f}%
- –í–∞—Ä—Ç—ñ—Å—Ç—å –ø–æ–≤–µ—Ä–Ω–µ–Ω—å: ${df_f['Return Value'].sum():,.2f}
- –¢–æ–ø SKU –∑–∞ –ø–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è–º–∏: {top_ret}"""
    show_ai_chat(ctx_ret, [
        "üî¥ –ß–æ–º—É —Ç–∞–∫ –±–∞–≥–∞—Ç–æ –ø–æ–≤–µ—Ä–Ω–µ–Ω—å? –ì–æ–ª–æ–≤–Ω—ñ –ø—Ä–∏—á–∏–Ω–∏",
        "üì¶ –Ø–∫—ñ SKU –Ω–∞–π–ø—Ä–æ–±–ª–µ–º–Ω—ñ—à—ñ —ñ —â–æ —Ä–æ–±–∏—Ç–∏?",
        "üí° –Ø–∫ –∑–Ω–∏–∑–∏—Ç–∏ Return Rate? –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –∫—Ä–æ–∫–∏",
    ], "returns")


def show_inventory_finance(df_filtered, t):
    tv = df_filtered['Stock Value'].sum(); tu = df_filtered['Available'].sum()
    ap = df_filtered[df_filtered['Price']>0]['Price'].mean()
    c1,c2,c3 = st.columns(3)
    c1.metric("üí∞ Total Inventory Value",f"${tv:,.2f}")
    c2.metric(t["avg_price"],f"${ap:,.2f}" if not pd.isna(ap) else "$0")
    c3.metric("üíµ Avg Value per Unit",f"${tv/tu:.2f}" if tu>0 else "$0")
    st.markdown("---"); st.subheader(t["chart_value_treemap"])
    dm = df_filtered[df_filtered['Stock Value']>0]
    if not dm.empty:
        fig = px.treemap(dm,path=['Store Name','SKU'],values='Stock Value',color='Stock Value',color_continuous_scale='RdYlGn_r')
        st.plotly_chart(fig, width="stretch")
    st.subheader(t["top_money_sku"])
    dt_ = df_filtered[['SKU','Product Name','Available','Price','Stock Value']].sort_values('Stock Value',ascending=False).head(10)
    st.dataframe(dt_.style.format({'Price':"${:.2f}",'Stock Value':"${:,.2f}"}),width="stretch")
    insights_inventory(df_filtered)


def show_aging(df_filtered, t):
    if df_filtered.empty: st.warning("No data"); return
    age_cols = ['Upto 90 Days','91 to 180 Days','181 to 270 Days','271 to 365 Days','More than 365 Days']
    valid    = [c for c in age_cols if c in df_filtered.columns]
    if not valid: st.warning("Aging data not available."); return
    da = df_filtered[valid].copy()
    for c in valid: da[c] = pd.to_numeric(da[c],errors='coerce').fillna(0)
    if da.sum().sum()==0: st.info("All inventory is fresh"); return
    as_ = da.sum().reset_index(); as_.columns=['Age Group','Units']; as_ = as_[as_['Units']>0]
    col1,col2 = st.columns(2)
    with col1:
        st.subheader(t["chart_age"])
        fig = px.pie(as_,values='Units',names='Age Group',hole=0.4); fig.update_layout(height=400)
        st.plotly_chart(fig, width="stretch")
    with col2:
        st.subheader(t["chart_velocity"])
        if all(c in df_filtered.columns for c in ['Available','Velocity','Stock Value']):
            ds = df_filtered[(df_filtered['Available']>0)&(df_filtered['Velocity']>=0)&(df_filtered['Stock Value']>0)].copy()
            if not ds.empty:
                fig = px.scatter(ds,x='Available',y='Velocity',size='Stock Value',color='Store Name' if 'Store Name' in ds.columns else None,hover_name='SKU',log_x=True)
                fig.update_layout(height=400); st.plotly_chart(fig, width="stretch")

    # ‚îÄ‚îÄ AI Chat ‚îÄ‚îÄ
    slow = df_filtered[df_filtered['Velocity'] < 0.1][['SKU','Available','Stock Value']].head(5).to_string() if 'Velocity' in df_filtered.columns else ""
    ctx_aging = f"""Inventory Health:
- SKU –≤—Å—å–æ–≥–æ: {len(df_filtered)} | –ó–∞–≥–∞–ª—å–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å: ${df_filtered['Stock Value'].sum():,.0f if 'Stock Value' in df_filtered.columns else 0}
- –ü–æ–≤—ñ–ª—å–Ω—ñ SKU (Velocity<0.1): {slow}"""
    show_ai_chat(ctx_aging, [
        "üê¢ –Ø–∫—ñ SKU –∑–∞—Å—Ç—Ä—è–ª–∏? –Ø–∫ –ø—Ä–∏—Å–∫–æ—Ä–∏—Ç–∏ —ó—Ö –ø—Ä–æ–¥–∞–∂?",
        "üí∏ –î–µ –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ñ –≥—Ä–æ—à—ñ? –©–æ –ª—ñ–∫–≤—ñ–¥—É–≤–∞—Ç–∏ –ø–µ—Ä—à–∏–º?",
        "üì¶ –Ø–∫ –æ–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ —Å–∫–ª–∞–¥ –¥–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è storage fees?",
    ], "aging")


def show_ai_forecast(df, t):
    st.markdown("### Select SKU for Forecast")
    skus = sorted(df['SKU'].unique())
    if not skus: st.info("No SKU available"); return
    col1,col2 = st.columns([2,1])
    target_sku    = col1.selectbox(t["ai_select"],skus)
    forecast_days = col2.slider(t["ai_days"],7,90,30)
    sd = df[df['SKU']==target_sku].copy().sort_values('created_at')
    sd['date_ordinal'] = sd['created_at'].map(dt.datetime.toordinal)
    if len(sd)>=3:
        model = LinearRegression().fit(sd[['date_ordinal']], sd['Available'])
        last  = sd['created_at'].max()
        fd    = [last+dt.timedelta(days=x) for x in range(1,forecast_days+1)]
        fo    = np.array([d.toordinal() for d in fd]).reshape(-1,1)
        preds = [max(0,int(p)) for p in model.predict(fo)]
        df_fc = pd.DataFrame({'date':fd,'Predicted':preds})
        so    = df_fc[df_fc['Predicted']==0]
        if not so.empty: st.error(f"{t['ai_result_date']} **{so.iloc[0]['date'].date()}**")
        else:             st.success(t['ai_ok'])
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=sd['created_at'],y=sd['Available'],name='Historical'))
        fig.add_trace(go.Scatter(x=df_fc['date'],y=df_fc['Predicted'],name='Forecast',line=dict(dash='dash',color='red')))
        st.plotly_chart(fig, width="stretch")
    else: st.warning(t["ai_error"])


def show_data_table(df_filtered, t, selected_date):
    st.markdown("### üìä FBA Inventory Dataset")
    st.download_button("üì• Download CSV",df_filtered.to_csv(index=False).encode('utf-8'),"fba_inventory.csv","text/csv")
    st.dataframe(df_filtered, width="stretch", height=600)


def show_orders(t=None):
    if t is None: t = translations.get("UA", {})
    df_orders = load_orders()
    if df_orders.empty: st.warning("‚ö†Ô∏è No orders data."); return
    st.sidebar.markdown("---"); st.sidebar.subheader("üõí Orders Filters")
    min_date = df_orders['Order Date'].min().date(); max_date = df_orders['Order Date'].max().date()
    date_range = st.sidebar.date_input(t["st_date_range"],value=(max_date-dt.timedelta(days=7),max_date),min_value=min_date,max_value=max_date)
    df_f = df_orders[(df_orders['Order Date'].dt.date>=date_range[0])&(df_orders['Order Date'].dt.date<=date_range[1])] if len(date_range)==2 else df_orders
    c1,c2,c3 = st.columns(3)
    c1.metric("üì¶ Orders",df_f['Order ID'].nunique()); c2.metric("üí∞ Revenue",f"${df_f['Total Price'].sum():,.2f}"); c3.metric("üì¶ Items",int(df_f['Quantity'].sum()))
    st.markdown("#### üìà Daily Revenue")
    daily = df_f.groupby(df_f['Order Date'].dt.date)['Total Price'].sum().reset_index()
    fig = px.bar(daily,x='Order Date',y='Total Price',title="Daily Revenue")
    st.plotly_chart(fig, width="stretch")
    col1,col2 = st.columns(2)
    with col1:
        st.markdown("#### üèÜ Top 10 SKU by Revenue")
        ts = df_f.groupby('SKU')['Total Price'].sum().nlargest(10).reset_index()
        fig2 = px.bar(ts,x='Total Price',y='SKU',orientation='h'); fig2.update_layout(yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig2, width="stretch")
    with col2:
        if 'Order Status' in df_f.columns:
            st.markdown("#### üìä Order Status")
            sc = df_f['Order Status'].value_counts().reset_index(); sc.columns=['Status','Count']
            fig3 = px.pie(sc,values='Count',names='Status',hole=0.4); st.plotly_chart(fig3, width="stretch")
    insights_orders(df_f)

    # ‚îÄ‚îÄ AI Chat ‚îÄ‚îÄ
    top_skus = df_f.groupby('SKU')['quantity'].sum().nlargest(5).to_string() if 'SKU' in df_f.columns and 'quantity' in df_f.columns else ""
    ctx_ord = f"""Orders –∞–Ω–∞–ª—ñ–∑: –∑–∞–º–æ–≤–ª–µ–Ω—å {len(df_f)}. –¢–æ–ø SKU: {top_skus}"""
    show_ai_chat(ctx_ord, [
        "üõí –Ø–∫—ñ SKU –Ω–∞–π–±—ñ–ª—å—à –ø—Ä–∏–±—É—Ç–∫–æ–≤—ñ? –î–µ –∑–±—ñ–ª—å—à–∏—Ç–∏ –∑–∞–ø–∞—Å?",
        "üìà –Ø–∫ –ø—Ä–∏—Å–∫–æ—Ä–∏—Ç–∏ –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è –ø—Ä–æ–¥–∞–∂—ñ–≤?",
        "üéØ –Ø–∫—ñ —Ç—Ä–µ–Ω–¥–∏ –≤ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è—Ö?",
    ], "orders")


# ============================================
# üï∑ SCRAPER MANAGER ‚Äî SIMPLIFIED
# ============================================

APIFY_TOKEN_DEFAULT = os.getenv("APIFY_TOKEN", "")
STARS_MAP = {5: "fiveStar", 4: "fourStar", 3: "threeStar", 2: "twoStar", 1: "oneStar"}
DOMAIN_FLAGS = {
    "com": "üá∫üá∏", "ca": "üá®üá¶", "de": "üá©üá™", "co.uk": "üá¨üáß",
    "it": "üáÆüáπ", "es": "üá™üá∏", "fr": "üá´üá∑", "co.jp": "üáØüáµ",
    "com.au": "üá¶üá∫", "com.mx": "üá≤üáΩ", "nl": "üá≥üá±", "pl": "üáµüá±", "se": "üá∏üá™",
}


def _scr_get_conn():
    from urllib.parse import urlparse
    r = urlparse(DATABASE_URL)
    return psycopg2.connect(
        database=r.path[1:], user=r.username, password=r.password,
        host=r.hostname, port=r.port, connect_timeout=10
    )


def _scr_ensure_table():
    conn = _scr_get_conn(); cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS amazon_reviews (
            id SERIAL PRIMARY KEY, asin VARCHAR(20), domain VARCHAR(20),
            review_id VARCHAR(100) UNIQUE, author VARCHAR(255), rating INTEGER,
            title TEXT, content TEXT, is_verified BOOLEAN,
            product_attributes TEXT, review_date TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
    """)
    conn.commit(); cur.close(); conn.close()


def _scr_save(reviews, asin, domain):
    conn = _scr_get_conn(); cur = conn.cursor(); inserted = 0
    for rev in reviews:
        url = rev.get("reviewUrl", "")
        rid = url.split("/")[-1] if url else f"{asin}_{domain}_{rev.get('position','?')}"
        try:
            cur.execute("""
                INSERT INTO amazon_reviews
                (asin,domain,review_id,author,rating,title,content,is_verified,product_attributes,review_date)
                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) ON CONFLICT (review_id) DO NOTHING
            """, (asin, domain, rid,
                  rev.get("author","Amazon User"), int(rev.get("ratingScore",0)),
                  rev.get("reviewTitle",""), rev.get("reviewDescription",""),
                  bool(rev.get("isVerified",False)), rev.get("variant",""), rev.get("date","")))
            if cur.rowcount > 0: inserted += 1
        except: pass
    conn.commit(); cur.close(); conn.close()
    return inserted


def _scr_count(asin, domain):
    try:
        conn = _scr_get_conn(); cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM amazon_reviews WHERE asin=%s AND domain=%s", (asin, domain))
        n = cur.fetchone()[0]; cur.close(); conn.close(); return n
    except: return 0


def _scr_parse_url(url):
    from urllib.parse import urlparse
    p = urlparse(url.strip())
    domain = p.netloc.replace("www.amazon.", "")
    m = re.search(r"([A-Z0-9]{10})", p.path)
    return domain, (m.group(1) if m else "UNKNOWN")


def _scr_worker(urls, max_per_star, log_q, progress_q, loop_mode, stop_event, apify_token):
    try:
        _scr_ensure_table()
    except Exception as e:
        log_q.put(f"‚ùå DB error: {e}"); progress_q.put({"done": True}); return

    endpoint = (
        f"https://api.apify.com/v2/acts/junglee~amazon-reviews-scraper"
        f"/run-sync-get-dataset-items?token={apify_token}"
    )
    cycle = 0
    while not stop_event.is_set():
        cycle += 1
        total_steps = len(urls) * 5
        step = 0
        cycle_total = 0

        if loop_mode:
            log_q.put(f"\n{'üîÑ'*20}")
            log_q.put(f"üîÑ  –¶–ò–ö–õ #{cycle} –†–û–ó–ü–û–ß–ê–¢–û")
            log_q.put(f"{'üîÑ'*20}")

        for url in urls:
            if stop_event.is_set(): break
            domain, asin = _scr_parse_url(url)
            flag = DOMAIN_FLAGS.get(domain, "üåç")
            log_q.put(f"\n{'='*50}")
            log_q.put(f"{flag}  {asin}  ¬∑  amazon.{domain}  (—Ü–∏–∫–ª #{cycle})")
            log_q.put(f"{'='*50}")

            url_new = 0
            for star_num, star_text in STARS_MAP.items():
                if stop_event.is_set(): break
                step += 1
                pct = int(step / total_steps * 100)
                log_q.put(f"  ‚è≥ {star_num}‚òÖ ‚Äî –∑–±–∏—Ä–∞—î–º–æ (max {max_per_star})...")
                progress_q.put({"pct": pct, "label": f"–¶–∏–∫–ª #{cycle} ¬∑ {asin} ¬∑ {star_num}‚òÖ"})
                payload = {
                    "productUrls": [{"url": url}],
                    "filterByRatings": [star_text],
                    "maxReviews": max_per_star,
                    "sort": "recent",
                }
                try:
                    res = requests.post(endpoint, json=payload, timeout=360)
                    if res.status_code in (200, 201):
                        data = res.json()
                        if data:
                            ins = _scr_save(data, asin, domain)
                            url_new   += ins
                            cycle_total += ins
                            log_q.put(f"  ‚úÖ {star_num}‚òÖ: –æ—Ç—Ä–∏–º–∞–Ω–æ {len(data)}, –Ω–æ–≤–∏—Ö: {ins}")
                        else:
                            log_q.put(f"  ‚ö†Ô∏è {star_num}‚òÖ: –≤—ñ–¥–≥—É–∫—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                    else:
                        log_q.put(f"  ‚ùå {star_num}‚òÖ: HTTP {res.status_code}")
                except Exception as e:
                    log_q.put(f"  ‚ùå {star_num}‚òÖ: {e}")
                time.sleep(1.5)

            in_db = _scr_count(asin, domain)
            log_q.put(f"üéØ {asin}/{domain}: +{url_new} –Ω–æ–≤–∏—Ö ¬∑ –≤ –ë–î: {in_db}")
            time.sleep(3)

        if loop_mode and not stop_event.is_set():
            pause_min = 30
            log_q.put(f"\nüèÅ –¶–∏–∫–ª #{cycle} –∑–∞–≤–µ—Ä—à–µ–Ω–æ! +{cycle_total} –Ω–æ–≤–∏—Ö.")
            log_q.put(f"‚è∏  –ü–∞—É–∑–∞ {pause_min} —Ö–≤ –ø–µ—Ä–µ–¥ –Ω–∞—Å—Ç—É–ø–Ω–∏–º —Ü–∏–∫–ª–æ–º...")
            progress_q.put({"pct": 100, "label": f"–¶–∏–∫–ª #{cycle} –≥–æ—Ç–æ–≤–æ, –ø–∞—É–∑–∞ {pause_min} —Ö–≤..."})
            for _ in range(pause_min * 12):
                if stop_event.is_set(): break
                time.sleep(5)
        else:
            break

    log_q.put(f"\nüèÅ –ó–ë–Ü–† –ó–£–ü–ò–ù–ï–ù–û –ø—ñ—Å–ª—è {cycle} —Ü–∏–∫–ª(—ñ–≤)")
    progress_q.put({"pct": 100, "label": "–ó—É–ø–∏–Ω–µ–Ω–æ", "done": True, "total": cycle})


def _scr_init():
    defaults = {
        "scr_running": False, "scr_logs": [], "scr_pct": 0,
        "scr_label": "", "scr_done": False, "scr_cycles": 0,
        "scr_log_q": None, "scr_prog_q": None,
        "scr_stop_event": None,
    }
    for k, v in defaults.items():
        if k not in st.session_state: st.session_state[k] = v


def _scr_flush():
    lq = st.session_state.scr_log_q
    pq = st.session_state.scr_prog_q
    if lq:
        while not lq.empty():
            try: st.session_state.scr_logs.append(lq.get_nowait())
            except: break
    if pq:
        while not pq.empty():
            try:
                msg = pq.get_nowait()
                if "pct"   in msg: st.session_state.scr_pct    = msg["pct"]
                if "label" in msg: st.session_state.scr_label  = msg["label"]
                if "done"  in msg and msg["done"]:
                    st.session_state.scr_done    = True
                    st.session_state.scr_running = False
                    st.session_state.scr_cycles  = msg.get("total", 0)
            except: break


def show_scraper_manager():
    _scr_init()
    _scr_flush()

    st.markdown("## üï∑ Scraper Reviews")

    # ‚îÄ‚îÄ –°—Ç–∞—Ç—É—Å ‚îÄ‚îÄ
    if st.session_state.scr_running:
        st.info(f"üîÑ {st.session_state.scr_label or '–ó–±—ñ—Ä –≤ –ø—Ä–æ—Ü–µ—Å—ñ...'}")
    elif st.session_state.scr_done:
        st.success(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –¶–∏–∫–ª—ñ–≤: **{st.session_state.scr_cycles}**")

    st.progress(st.session_state.scr_pct, text=st.session_state.scr_label or " ")
    st.markdown("---")

    # ‚îÄ‚îÄ –§–æ—Ä–º–∞ ‚îÄ‚îÄ
    urls_input = st.text_area(
        "üîó –ü–æ—Å–∏–ª–∞–Ω–Ω—è Amazon (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Ä—è–¥–æ–∫):",
        height=180,
        placeholder=(
            "https://www.amazon.com/dp/B08HR2131Z\n"
            "https://www.amazon.de/dp/B08HWCL2RY\n"
            "https://www.amazon.co.uk/dp/B07XCDPRGZ"
        ),
        disabled=st.session_state.scr_running,
        key="scr_urls_input"
    )

    max_per_star = 100  # Amazon limit
    c2, c3 = st.columns([3, 1])
    with c2:
        loop_mode = st.toggle(
            "üîÑ –ù–µ—Å–∫—ñ–Ω—á–µ–Ω–Ω–∏–π —Ü–∏–∫–ª (–ø–∞—É–∑–∞ 30 —Ö–≤ –º—ñ–∂ –ø—Ä–æ—Ö–æ–¥–∞–º–∏)",
            value=False,
            disabled=st.session_state.scr_running
        )
    with c3:
        st.markdown("<div style='margin-top:28px'>", unsafe_allow_html=True)
        if st.session_state.scr_running:
            if st.button("‚õî –ó—É–ø–∏–Ω–∏—Ç–∏", width="stretch", type="secondary"):
                if st.session_state.scr_stop_event:
                    st.session_state.scr_stop_event.set()
                st.session_state.scr_running = False
                st.session_state.scr_done    = True
                st.rerun()
        else:
            raw_lines = [u.strip() for u in (urls_input or "").splitlines() if u.strip()]
            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏", width="stretch", type="primary",
                         disabled=not raw_lines):
                lq      = queue.Queue()
                pq      = queue.Queue()
                stop_ev = threading.Event()

                st.session_state.scr_logs       = []
                st.session_state.scr_pct        = 0
                st.session_state.scr_label      = "–°—Ç–∞—Ä—Ç..."
                st.session_state.scr_done       = False
                st.session_state.scr_running    = True
                st.session_state.scr_cycles     = 0
                st.session_state.scr_log_q      = lq
                st.session_state.scr_prog_q     = pq
                st.session_state.scr_stop_event = stop_ev

                threading.Thread(
                    target=_scr_worker,
                    args=(raw_lines, max_per_star, lq, pq,
                          loop_mode, stop_ev, APIFY_TOKEN_DEFAULT),
                    daemon=True
                ).start()
                st.rerun()

    st.markdown("---")

    # ‚îÄ‚îÄ –õ–æ–≥–∏ ‚îÄ‚îÄ
    st.markdown("### üìú –õ–æ–≥–∏")
    logs = st.session_state.scr_logs
    if logs:
        colored = []
        for line in logs[-100:]:
            if "===" in line:
                colored.append(f'<span style="color:#5B9BD5;font-weight:700">{line}</span>')
            elif "üîÑ" in line and "–¶–ò–ö–õ" in line:
                colored.append(f'<span style="color:#AB47BC;font-weight:800;font-size:14px">{line}</span>')
            elif "‚úÖ" in line:
                colored.append(f'<span style="color:#4CAF50">{line}</span>')
            elif "‚ùå" in line:
                colored.append(f'<span style="color:#F44336">{line}</span>')
            elif "‚ö†Ô∏è" in line:
                colored.append(f'<span style="color:#FFC107">{line}</span>')
            elif "üèÅ" in line or "–ó–£–ü–ò–ù–ï–ù–û" in line:
                colored.append(f'<span style="color:#FFD700;font-weight:800">{line}</span>')
            elif "üéØ" in line:
                colored.append(f'<span style="color:#AB47BC">{line}</span>')
            elif "‚è∏" in line:
                colored.append(f'<span style="color:#888;font-style:italic">{line}</span>')
            else:
                colored.append(f'<span style="color:#ccc">{line}</span>')

        st.markdown(f"""
        <div style="background:#0d1117;border:1px solid #30363d;border-radius:10px;
                    padding:16px 20px;font-family:'Courier New',monospace;font-size:13px;
                    line-height:1.7;max-height:520px;overflow-y:auto">
          {"<br>".join(colored)}
        </div>""", unsafe_allow_html=True)

        c1, c2, _ = st.columns([1, 1, 3])
        with c1:
            if st.button("üóë –û—á–∏—Å—Ç–∏—Ç–∏ –ª–æ–≥–∏", width="stretch"):
                st.session_state.scr_logs = []
                st.session_state.scr_done = False
                st.rerun()
        with c2:
            st.download_button(
                "üì• –ó–±–µ—Ä–µ–≥—Ç–∏ –ª–æ–≥",
                "\n".join(logs).encode(),
                "scraper_log.txt", "text/plain", width="stretch"
            )
    else:
        st.markdown("""
        <div style="background:#0d1117;border:1px solid #30363d;border-radius:10px;
                    padding:24px;color:#555;font-family:monospace;text-align:center">
          –õ–æ–≥–∏ –∑'—è–≤–ª—è—Ç—å—Å—è –ø—ñ—Å–ª—è –∑–∞–ø—É—Å–∫—É...
        </div>""", unsafe_allow_html=True)

    # Auto-refresh –ø–æ–∫–∏ —ñ–¥–µ
    if st.session_state.scr_running:
        time.sleep(2)
        st.rerun()


# ============================================
# MAIN
# ============================================

from auth import (
    ensure_tables, create_admin_if_not_exists,
    show_login, logout, can_view,
    show_admin_panel, ALL_REPORTS
)

# ‚îÄ‚îÄ Init DB tables on first run ‚îÄ‚îÄ
try:
    ensure_tables()
    create_admin_if_not_exists()
except Exception as e:
    st.error(f"DB init error: {e}")
    st.stop()

# ‚îÄ‚îÄ Not logged in ‚Üí show login form ‚îÄ‚îÄ
if "user" not in st.session_state or not st.session_state.user:
    show_login()
    st.stop()

# ‚îÄ‚îÄ Logged in ‚îÄ‚îÄ
user = st.session_state.user

# Sidebar: user info + logout
st.sidebar.markdown(f"""
<div style="background:#1e1e2e;border-radius:8px;padding:10px 14px;margin-bottom:8px">
  <div style="font-size:14px;font-weight:700;color:#fff">{user['name'] or user['email']}</div>
  <div style="font-size:12px;color:#888">{user['email']}</div>
  <div style="font-size:11px;color:#AB47BC;margin-top:4px;font-weight:600">{user['role'].upper()}</div>
</div>""", unsafe_allow_html=True)
if st.sidebar.button("üö™ –í–∏–π—Ç–∏", width="stretch"):
    logout()

if 'report_choice' not in st.session_state:
    st.session_state.report_choice = "üè† Overview"

lang_option = st.sidebar.selectbox("üåç Language", ["UA üá∫üá¶","EN üá∫üá∏","RU üåç"], index=0)
lang = "UA" if "UA" in lang_option else "EN" if "EN" in lang_option else "RU"
t    = translations[lang]

if st.sidebar.button(t["update_btn"], width="stretch"):
    st.cache_data.clear(); st.rerun()

df = load_data()

if not df.empty:
    for col in ['Available','Price','Velocity','Stock Value']:
        if col not in df.columns: df[col] = 0
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    df['Stock Value'] = df['Available'] * df['Price']
    df['created_at']  = pd.to_datetime(df['created_at'])
    df['date']        = df['created_at'].dt.date
    st.sidebar.header(t["sidebar_title"])
    dates         = sorted(df['date'].unique(), reverse=True)
    selected_date = st.sidebar.selectbox(t["date_label"], dates) if dates else None
    stores        = [t["all_stores"]] + list(df['Store Name'].unique()) if 'Store Name' in df.columns else [t["all_stores"]]
    selected_store = st.sidebar.selectbox(t["store_label"], stores)
    df_filtered    = df[df['date']==selected_date] if selected_date else df
    if selected_store != t["all_stores"]:
        df_filtered = df_filtered[df_filtered['Store Name']==selected_store]
else:
    df_filtered = pd.DataFrame(); selected_date = None

st.sidebar.markdown("---")
st.sidebar.header("üìä Reports")

# –§–æ—Ä–º—É—î–º–æ —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –∑–≤—ñ—Ç—ñ–≤ –¥–ª—è —Ü—å–æ–≥–æ —é–∑–µ—Ä–∞
all_nav = [
    "üè† Overview","üìà Sales & Traffic","üè¶ Settlements (Payouts)",
    "üí∞ Inventory Value (CFO)","üõí Orders Analytics","üì¶ Returns Analytics",
    "‚≠ê Amazon Reviews","üê¢ Inventory Health (Aging)","üß† AI Forecast",
    "üìã FBA Inventory Table","üï∑ Scraper Reviews",
]
# –ê–¥–º—ñ–Ω –±–∞—á–∏—Ç—å –≤—Å–µ + –∞–¥–º—ñ–Ω–∫—É
if user["role"] == "admin":
    report_options = all_nav + ["üëë User Management", "‚ÑπÔ∏è –ü—Ä–æ –¥–æ–¥–∞—Ç–æ–∫"]
else:
    report_options = [r for r in all_nav if can_view(r)] + ["‚ÑπÔ∏è –ü—Ä–æ –¥–æ–¥–∞—Ç–æ–∫"]

if not report_options:
    st.warning("–£ –≤–∞—Å –Ω–µ–º–∞—î –¥–æ—Å—Ç—É–ø—É –¥–æ –∂–æ–¥–Ω–æ–≥–æ —Ä–æ–∑–¥—ñ–ª—É. –ó–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞.")
    st.stop()

if st.session_state.report_choice not in report_options:
    st.session_state.report_choice = report_options[0]

current_index = report_options.index(st.session_state.report_choice)
report_choice = st.sidebar.radio("Select Report:", report_options, index=current_index)
st.session_state.report_choice = report_choice

if   report_choice == "üè† Overview":                show_overview(df_filtered, t, selected_date)
elif report_choice == "üìà Sales & Traffic":          show_sales_traffic(t)
elif report_choice == "üè¶ Settlements (Payouts)":   show_settlements(t)
elif report_choice == "üí∞ Inventory Value (CFO)":   show_inventory_finance(df_filtered, t)
elif report_choice == "üõí Orders Analytics":         show_orders(t)
elif report_choice == "üì¶ Returns Analytics":        show_returns(t)
elif report_choice == "‚≠ê Amazon Reviews":           show_reviews(t)
elif report_choice == "üê¢ Inventory Health (Aging)":show_aging(df_filtered, t)
elif report_choice == "üß† AI Forecast":              show_ai_forecast(df, t)
elif report_choice == "üìã FBA Inventory Table":      show_data_table(df_filtered, t, selected_date)
elif report_choice == "üï∑ Scraper Reviews":          show_scraper_manager()
elif report_choice == "üëë User Management":          show_admin_panel()
elif report_choice == "‚ÑπÔ∏è –ü—Ä–æ –¥–æ–¥–∞—Ç–æ–∫":              show_about()

st.sidebar.markdown("---")
st.sidebar.caption("üì¶ Amazon FBA BI System v5.0 üåç")
